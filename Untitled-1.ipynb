{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc531bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.39.3)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: py2neo in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2021.2.4)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (2.4.1+cu118)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (0.26.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from py2neo) (2024.7.4)\n",
      "Requirement already satisfied: interchange~=2021.0.4 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from py2neo) (2021.0.4)\n",
      "Requirement already satisfied: monotonic in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from py2neo) (1.6)\n",
      "Requirement already satisfied: pansi>=2020.7.3 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from py2neo) (2024.11.0)\n",
      "Requirement already satisfied: pygments>=2.0.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from py2neo) (2.18.0)\n",
      "Requirement already satisfied: six>=1.15.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from py2neo) (1.16.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from py2neo) (2.2.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas sentence-transformers transformers faiss-cpu py2neo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d04647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "from py2neo import Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4060f861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\kathi\\AppData\\Local\\Temp\\ipykernel_20752\\2770397488.py:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  df = pd.read_csv(\"unified_hybrid_bert_gpt_for_bibliometric\\papers_enriched.csv\")\n",
      "C:\\Users\\kathi\\AppData\\Local\\Temp\\ipykernel_20752\\2770397488.py:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  index = faiss.read_index(\"unified_hybrid_bert_gpt_for_bibliometric\\semantic_index.faiss\")\n",
      "C:\\Users\\kathi\\AppData\\Local\\Temp\\ipykernel_20752\\2770397488.py:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  with open(\"unified_hybrid_bert_gpt_for_bibliometric\\semantic_titles.pkl\", \"rb\") as f:\n",
      "c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a52e393ed66427e97754ff72479ea1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kathi\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7daffd58684712a216017c660766ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b872222caa4ce88c053832eab55c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916ce32e334e4ca9a18a5d90167eb6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bdc8e5d5154e109f923ebd8dfb192f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79eb05a7fbc14cdfbc36b516ca4932a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load your data and FAISS index\n",
    "df = pd.read_csv(\"unified_hybrid_bert_gpt_for_bibliometric\\papers_enriched.csv\")\n",
    "index = faiss.read_index(\"unified_hybrid_bert_gpt_for_bibliometric\\semantic_index.faiss\")\n",
    "\n",
    "# Load titles\n",
    "with open(\"unified_hybrid_bert_gpt_for_bibliometric\\semantic_titles.pkl\", \"rb\") as f:\n",
    "    titles = pickle.load(f)\n",
    "\n",
    "# Load sentence embedding model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba66a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_doc(query, k=1):\n",
    "    vec = embedder.encode([query])\n",
    "    D, I = index.search(np.array(vec), k)\n",
    "\n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        title = df.iloc[idx][\"title\"]\n",
    "        abstract = df.iloc[idx][\"clean_abstract\"]\n",
    "        results.append({\n",
    "            \"title\": title,\n",
    "            \"abstract\": abstract\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14144ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Neo4j\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"qwertyuiop\"))\n",
    "\n",
    "def get_graph_info(title):\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Paper {title: $title})\n",
    "    OPTIONAL MATCH (p)<-[:WROTE]-(a:Author)\n",
    "    OPTIONAL MATCH (p)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "    OPTIONAL MATCH (p)-[:MENTIONS]->(e:Entity)\n",
    "    RETURN \n",
    "        collect(DISTINCT a.name) AS authors,\n",
    "        collect(DISTINCT k.name) AS keywords,\n",
    "        collect(DISTINCT e.name) AS entities\n",
    "    \"\"\"\n",
    "    result = graph.run(query, title=title).data()\n",
    "    if result:\n",
    "        return result[0]\n",
    "    return {\"authors\": [], \"keywords\": [], \"entities\": []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240fed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "def generate_summary_with_graph(doc, graph_data):\n",
    "    graph_context = \"\"\n",
    "    if graph_data[\"authors\"]:\n",
    "        graph_context += \"Authors: \" + \", \".join(graph_data[\"authors\"]) + \"\\n\"\n",
    "    if graph_data[\"keywords\"]:\n",
    "        graph_context += \"Keywords: \" + \", \".join(graph_data[\"keywords\"]) + \"\\n\"\n",
    "    if graph_data[\"entities\"]:\n",
    "        graph_context += \"Entities: \" + \", \".join(graph_data[\"entities\"]) + \"\\n\"\n",
    "\n",
    "    full_input = graph_context + \"\\n\" + doc[\"abstract\"]\n",
    "    input_trimmed = full_input[:2000]\n",
    "\n",
    "    summary = summarizer(input_trimmed, max_length=150, min_length=40, do_sample=False)\n",
    "    return summary[0][\"summary_text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "629865b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Title: A Survey of Large Language Models\n",
      "📄 Abstract: language is essentially a complex intricate system of human expressions governed by grammatical rules it poses a significant challenge to develop capable ai algorithms for comprehending and grasping a language as a major approach language modeling has been widely studied for language understanding and generation in the past two decades evolving from statistical language models to neural language models recently pretrained language models plms have been proposed by pretraining transformer models over largescale corpora showing strong capabilities in solving various nlp tasks since researchers have found that model scaling can lead to performance improvement they further study the scaling effect by increasing the model size to an even larger size interestingly when the parameter scale exceeds a certain level these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in smallscale language models to discriminate the difference in parameter scale the research community has coined the term large language models llm for the plms of significant size recently the research on llms has been largely advanced by both academia and industry and a remarkable progress is the launch of chatgpt which has attracted widespread attention from society the technical evolution of llms has been making an important impact on the entire ai community which would revolutionize the way how we develop and use ai algorithms in this survey we review the recent advances of llms by introducing the background key findings and mainstream techniques in particular we focus on four major aspects of llms namely pretraining adaptation tuning utilization and capacity evaluation besides we also summarize the available resources for developing llms and discuss the remaining issues for future directions\n",
      "\n",
      "📊 Graph Facts: {'authors': ['Wayne Xin Zhao', 'Kun Zhou', 'Junyi Li', 'Tianyi Tang', 'Xiaolei Wang', 'Yupeng Hou', 'Yingqian Min', 'Beichen Zhang', 'Junjie Zhang', 'Zican Dong', 'Yifan Du', 'Yang Chen', 'Yushuo Chen', 'Zhipeng Chen', 'Jinhao Jiang', 'Ruiyang Ren', 'Yifan Li', 'Xinyu Tang', 'Zikang Liu', 'Peiyu Liu', 'Jian‐Yun Nie', 'Ji-Rong Wen'], 'keywords': ['language models', 'large language', 'language modeling', 'smallscale language', 'enlarged language'], 'entities': ['models', 'model', 'performance', 'complex', 'abilities', 'language', 'tasks', 'adaptation', 'level', 'chatgpt', 'research', 'evaluation', 'human', 'capabilities', 'llms', 'study', 'improvement', 'coined', 'findings', 'directions', 'expressions', 'parameter scale', 'discriminate', 'community', 'impact', 'enlarged', 'smallscale', 'comprehending', 'capacity', 'significant', 'largescale corpora', 'grasping', 'plms', 'grammatical rules', 'launch', 'neural language', 'survey', 'evolution', 'modeling', 'generation', 'nlp', 'decades', 'progress', 'evolving', 'significant size', 'pretraining', 'utilization', 'statistical language', 'mainstream techniques', 'technical', 'industry', 'researchers', 'society', 'academia', 'size', 'transformer models', 'scaling', 'scaling effect', 'resources', 'increasing', 'algorithms']}\n",
      "\n",
      "🧠 Enriched Summary:\n",
      " language is essentially a complex intricate system of human expressions governed by grammatical rules it poses a significant challenge to develop capable ai algorithms for comprehending and grasping a language. Language modeling has been widely studied for language understanding and generation in the past two decades evolving from statistical language models to neural language models recently pretrained language models plms have been proposed by pretraining transformer models over largescale corpora.\n"
     ]
    }
   ],
   "source": [
    "query = input(\"🔍 Enter a research topic: \")\n",
    "\n",
    "# Step 1: Retrieve paper\n",
    "top_doc = retrieve_top_doc(query, k=1)[0]\n",
    "print(\"\\n📄 Title:\", top_doc[\"title\"])\n",
    "print(\"📄 Abstract:\", top_doc[\"abstract\"])\n",
    "\n",
    "# Step 2: Get graph info\n",
    "facts = get_graph_info(top_doc[\"title\"])\n",
    "print(\"\\n📊 Graph Facts:\", facts)\n",
    "\n",
    "# Step 3: Generate enriched summary\n",
    "summary = generate_summary_with_graph(top_doc, facts)\n",
    "print(\"\\n🧠 Enriched Summary:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d6e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
