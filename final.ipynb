{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b30dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and select a small batch for fine-tuning\n",
    "df = pd.read_csv(\"clustered_papers.csv\").dropna(subset=[\"title\", \"clean_abstract\"])\n",
    "df = df.head(20)  # fine-tune on just 20 samples\n",
    "\n",
    "# Format input/output pairs\n",
    "def build_input(row):\n",
    "    return f\"Title: {row['title']}\\nAuthors: {row.get('authors', 'Unknown')}\\nKeywords: {row.get('keywords', '')}\\nAbstract: {row['clean_abstract']}\"\n",
    "\n",
    "def build_target(row):\n",
    "    return f\"This paper discusses {row.get('keywords', 'key topics')} and contributes to cluster {row.get('gmm_cluster', 'X')} research.\"\n",
    "\n",
    "dataset = [{\"input\": build_input(row), \"target\": build_target(row)} for _, row in df.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5cb76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd30aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import EncoderDecoderModel, BertTokenizer, GPT2Tokenizer\n",
    "\n",
    "# Load hybrid model\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"mistral\")\n",
    "model.config.decoder_start_token_id = model.config.pad_token_id = 50256\n",
    "model.config.eos_token_id = 50256\n",
    "\n",
    "# Load tokenizers\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7386ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Tokenization function\n",
    "def encode(example):\n",
    "    input_enc = bert_tokenizer(example[\"input\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    target_enc = gpt2_tokenizer(example[\"target\"], padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    labels = target_enc.input_ids.clone()\n",
    "    labels[labels == gpt2_tokenizer.pad_token_id] = -100  # ignore pad tokens in loss\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_enc.input_ids[0],\n",
    "        \"attention_mask\": input_enc.attention_mask[0],\n",
    "        \"decoder_input_ids\": target_enc.input_ids[0],\n",
    "        \"labels\": labels[0]\n",
    "    }\n",
    "\n",
    "class BERTGPTDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = [encode(d) for d in data]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "train_dataset = BERTGPTDataset(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "195ccc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:636: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 1 — Avg Loss: 3.5536\n",
      "✅ Epoch 2 — Avg Loss: 0.1720\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(2):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"✅ Epoch {epoch+1} — Avg Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbee5796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Generated Summary:\n",
      " This is a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_input = build_input(df.iloc[0])\n",
    "\n",
    "encoded = bert_tokenizer(test_input, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    input_ids=encoded.input_ids,\n",
    "    attention_mask=encoded.attention_mask,\n",
    "    max_length=150,\n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "summary = gpt2_tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "print(\"\\n🧠 Generated Summary:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d04a793a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.39.3)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.31.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/10.4 MB 8.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.4/10.4 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.4/10.4 MB 6.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.5/10.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.0/10.4 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.6/10.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.9/10.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.4 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.4/10.4 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.31.2-py3-none-any.whl (484 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.3/2.4 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 7.3 MB/s eta 0:00:00\n",
      "Installing collected packages: huggingface-hub, tokenizers, transformers\n",
      "\n",
      "  Attempting uninstall: huggingface-hub\n",
      "\n",
      "    Found existing installation: huggingface-hub 0.26.1\n",
      "\n",
      "    Uninstalling huggingface-hub-0.26.1:\n",
      "\n",
      "      Successfully uninstalled huggingface-hub-0.26.1\n",
      "\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "  Attempting uninstall: tokenizers\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "  Attempting uninstall: transformers\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "    Found existing installation: transformers 4.39.3\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "    Uninstalling transformers-4.39.3:\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "      Successfully uninstalled transformers-4.39.3\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   ---------------------------------------- 3/3 [transformers]\n",
      "\n",
      "Successfully installed huggingface-hub-0.31.2 tokenizers-0.21.1 transformers-4.51.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~-kenizers'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fdeaac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "mistral-7b is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhf_raise_for_status\u001b[39m(response: Response, endpoint_name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03m    Internal version of `response.raise_for_status()` that will refine a\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m    potential HTTPError. Raised exception will be an instance of `HfHubHTTPError`.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03m    This helper is meant to be the unique method to raise_for_status when making a call\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03m    to the Hugging Face Hub.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;124;03m    ```py\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m        import requests\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m        from huggingface_hub.utils import get_session, hf_raise_for_status, HfHubHTTPError\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m        response = get_session().post(...)\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m        try:\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;124;03m            hf_raise_for_status(response)\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m        except HfHubHTTPError as e:\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m            print(str(e)) # formatted message\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m            e.request_id, e.server_message # details returned by server\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m            # Complete the error message with additional information once it's raised\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m            e.append_to_message(\"\\n`create_commit` expects the repository to exist.\")\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m            raise\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;124;03m        response (`Response`):\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m            Response from the server.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m        endpoint_name (`str`, *optional*):\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;124;03m            Name of the endpoint that has been called. If provided, the error message\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;124;03m            will be more complete.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03m    <Tip warning={true}>\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m    Raises when the request has failed:\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m        - [`~utils.RepositoryNotFoundError`]\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m            If the repository to download from cannot be found. This may be because it\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m            doesn't exist, because `repo_type` is not set correctly, or because the repo\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m            is `private` and you do not have access.\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m        - [`~utils.GatedRepoError`]\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;124;03m            If the repository exists but is gated and the user is not on the authorized\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m            list.\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        - [`~utils.RevisionNotFoundError`]\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m            If the repository exists but the revision couldn't be find.\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m        - [`~utils.EntryNotFoundError`]\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m            If the repository exists but the entry (e.g. the requested file) couldn't be\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m            find.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m        - [`~utils.BadRequestError`]\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;124;03m            If request failed with a HTTP 400 BadRequest error.\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03m        - [`~utils.HfHubHTTPError`]\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m            If request failed for a reason not listed above.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \n\u001b[1;32m--> 406\u001b[0m \u001b[38;5;124;03m    </Tip>\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/mistral-7b/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    396\u001b[0m     cache_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(cache_dir)\n\u001b[1;32m--> 398\u001b[0m existing_files \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    399\u001b[0m file_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;129m@validate_hf_hub_args\u001b[39m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhf_hub_download\u001b[39m(\n\u001b[0;32m    811\u001b[0m     repo_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    831\u001b[0m     local_dir_use_symlinks: Union[\u001b[38;5;28mbool\u001b[39m, Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    832\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    833\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download a given file if it's not already present in the local cache.\u001b[39;00m\n\u001b[0;32m    834\u001b[0m \n\u001b[0;32m    835\u001b[0m \u001b[38;5;124;03m    The new cache file layout looks like this:\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;124;03m    - The cache directory contains one subfolder per repo_id (namespaced by repo type)\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;124;03m    - inside each repo folder:\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;124;03m        - refs is a list of the latest known revision => commit_hash pairs\u001b[39;00m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;124;03m        - blobs contains the actual file blobs (identified by their git-sha or sha256, depending on\u001b[39;00m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;124;03m          whether they're LFS files or not)\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;124;03m        - snapshots contains one subfolder per commit, each \"commit\" contains the subset of the files\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;124;03m          that have been resolved at that particular commit. Each filename is a symlink to the blob\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;124;03m          at that particular commit.\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \n\u001b[0;32m    845\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;124;03m    [  96]  .\u001b[39;00m\n\u001b[0;32m    847\u001b[0m \u001b[38;5;124;03m    └── [ 160]  models--julien-c--EsperBERTo-small\u001b[39;00m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;124;03m        ├── [ 160]  blobs\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;124;03m        │   ├── [321M]  403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;124;03m        │   ├── [ 398]  7cb18dc9bafbfcf74629a4b760af1b160957a83e\u001b[39;00m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;124;03m        │   └── [1.4K]  d7edf6bd2a681fb0175f7735299831ee1b22b812\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;124;03m        ├── [  96]  refs\u001b[39;00m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;124;03m        │   └── [  40]  main\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;124;03m        └── [ 128]  snapshots\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;124;03m            ├── [ 128]  2439f60ef33a0d46d85da5001d52aeda5b00ce9f\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;124;03m            │   ├── [  52]  README.md -> ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;124;03m            │   └── [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;124;03m            └── [ 128]  bbc77c8132af1cc5cf678da3f1ddf2de43606d48\u001b[39;00m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;124;03m                ├── [  52]  README.md -> ../../blobs/7cb18dc9bafbfcf74629a4b760af1b160957a83e\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;124;03m                └── [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m \n\u001b[0;32m    863\u001b[0m \u001b[38;5;124;03m    If `local_dir` is provided, the file structure from the repo will be replicated in this location. When using this\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;124;03m    option, the `cache_dir` will not be used and a `.cache/huggingface/` folder will be created at the root of `local_dir`\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;124;03m    to store some metadata related to the downloaded files. While this mechanism is not as robust as the main\u001b[39;00m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;124;03m    cache-system, it's optimized for regularly pulling the latest version of a repository.\u001b[39;00m\n\u001b[0;32m    867\u001b[0m \n\u001b[0;32m    868\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    869\u001b[0m \u001b[38;5;124;03m        repo_id (`str`):\u001b[39;00m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;124;03m            A user or an organization name and a repo name separated by a `/`.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;124;03m        filename (`str`):\u001b[39;00m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;124;03m            The name of the file in the repo.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;124;03m        subfolder (`str`, *optional*):\u001b[39;00m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;124;03m            An optional value corresponding to a folder inside the model repo.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;124;03m        repo_type (`str`, *optional*):\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;124;03m            Set to `\"dataset\"` or `\"space\"` if downloading from a dataset or space,\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;124;03m            `None` or `\"model\"` if downloading from a model. Default is `None`.\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03m        revision (`str`, *optional*):\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;124;03m            An optional Git revision id which can be a branch name, a tag, or a\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;124;03m            commit hash.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;124;03m        library_name (`str`, *optional*):\u001b[39;00m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;124;03m            The name of the library to which the object corresponds.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;124;03m        library_version (`str`, *optional*):\u001b[39;00m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03m            The version of the library.\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m        cache_dir (`str`, `Path`, *optional*):\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m            Path to the folder where cached files are stored.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m        local_dir (`str` or `Path`, *optional*):\u001b[39;00m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;124;03m            If provided, the downloaded file will be placed under this directory.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;124;03m        user_agent (`dict`, `str`, *optional*):\u001b[39;00m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m            The user-agent info in the form of a dictionary or a string.\u001b[39;00m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;124;03m        force_download (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;124;03m            Whether the file should be downloaded even if it already exists in\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;124;03m            the local cache.\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;124;03m        proxies (`dict`, *optional*):\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;124;03m            Dictionary mapping protocol to the URL of the proxy passed to\u001b[39;00m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;124;03m            `requests.request`.\u001b[39;00m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;124;03m        etag_timeout (`float`, *optional*, defaults to `10`):\u001b[39;00m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;124;03m            When fetching ETag, how many seconds to wait for the server to send\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;124;03m            data before giving up which is passed to `requests.request`.\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;124;03m        token (`str`, `bool`, *optional*):\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;124;03m            A token to be used for the download.\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m                - If `True`, the token is read from the HuggingFace config\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m                  folder.\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m                - If a string, it's used as the authentication token.\u001b[39;00m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;124;03m        local_files_only (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;124;03m            If `True`, avoid downloading the file and return the path to the\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;124;03m            local cached file if it exists.\u001b[39;00m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;124;03m        headers (`dict`, *optional*):\u001b[39;00m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;124;03m            Additional headers to be sent with the request.\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03m        `str`: Local path of file or if networking is off, last version of file cached on disk.\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \n\u001b[0;32m    914\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;124;03m        [`~utils.RepositoryNotFoundError`]\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;124;03m            If the repository to download from cannot be found. This may be because it doesn't exist,\u001b[39;00m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;124;03m            or because it is set to `private` and you do not have access.\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;124;03m        [`~utils.RevisionNotFoundError`]\u001b[39;00m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;124;03m            If the revision to download from cannot be found.\u001b[39;00m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;124;03m        [`~utils.EntryNotFoundError`]\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;124;03m            If the file to download cannot be found.\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;124;03m        [`~utils.LocalEntryNotFoundError`]\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;124;03m            If network is disabled or unavailable and file is not found in cache.\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;124;03m        [`EnvironmentError`](https://docs.python.org/3/library/exceptions.html#EnvironmentError)\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;124;03m            If `token=True` but the token cannot be found.\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;124;03m        [`OSError`](https://docs.python.org/3/library/exceptions.html#OSError)\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;124;03m            If ETag cannot be determined.\u001b[39;00m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;124;03m        [`ValueError`](https://docs.python.org/3/library/exceptions.html#ValueError)\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;124;03m            If some parameter value is invalid.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m \n\u001b[0;32m    931\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHF_HUB_ETAG_TIMEOUT \u001b[38;5;241m!=\u001b[39m constants\u001b[38;5;241m.\u001b[39mDEFAULT_ETAG_TIMEOUT:\n\u001b[0;32m    933\u001b[0m         \u001b[38;5;66;03m# Respect environment variable above user value\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:969\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1484\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m HfFileMetadata(\n\u001b[0;32m   1461\u001b[0m         commit_hash\u001b[38;5;241m=\u001b[39mr\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(constants\u001b[38;5;241m.\u001b[39mHUGGINGFACE_HEADER_X_REPO_COMMIT),\n\u001b[0;32m   1462\u001b[0m         \u001b[38;5;66;03m# We favor a custom header indicating the etag of the linked resource, and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1472\u001b[0m         xet_file_data\u001b[38;5;241m=\u001b[39mparse_xet_file_data_from_response(r),  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m     )\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_metadata_or_catch_error\u001b[39m(\n\u001b[0;32m   1477\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   1478\u001b[0m     repo_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1479\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1480\u001b[0m     repo_type: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1481\u001b[0m     revision: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1482\u001b[0m     endpoint: Optional[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   1483\u001b[0m     proxies: Optional[Dict],\n\u001b[1;32m-> 1484\u001b[0m     etag_timeout: Optional[\u001b[38;5;28mfloat\u001b[39m],\n\u001b[0;32m   1485\u001b[0m     headers: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m],  \u001b[38;5;66;03m# mutated inplace!\u001b[39;00m\n\u001b[0;32m   1486\u001b[0m     token: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[0;32m   1487\u001b[0m     local_files_only: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   1488\u001b[0m     relative_filename: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# only used to store `.no_exists` in cache\u001b[39;00m\n\u001b[0;32m   1489\u001b[0m     storage_folder: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# only used to store `.no_exists` in cache\u001b[39;00m\n\u001b[0;32m   1490\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\n\u001b[0;32m   1491\u001b[0m     \u001b[38;5;66;03m# Either an exception is caught and returned\u001b[39;00m\n\u001b[0;32m   1492\u001b[0m     Tuple[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m],\n\u001b[0;32m   1493\u001b[0m     \u001b[38;5;66;03m# Or the metadata is returned as\u001b[39;00m\n\u001b[0;32m   1494\u001b[0m     \u001b[38;5;66;03m# `(url_to_download, etag, commit_hash, expected_size, xet_file_data, None)`\u001b[39;00m\n\u001b[0;32m   1495\u001b[0m     Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, Optional[XetFileData], \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[0;32m   1496\u001b[0m ]:\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get metadata for a file on the Hub, safely handling network issues.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \n\u001b[0;32m   1499\u001b[0m \u001b[38;5;124;03m    Returns either the etag, commit_hash and expected size of the file, or the error\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;124;03m          domain of the location (typically an S3 bucket).\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1376\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(refs_dir):\n\u001b[1;32m-> 1376\u001b[0m     revision_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(refs_dir, revision)\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(revision_file):\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1296\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1287\u001b[0m     paths\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;241m.\u001b[39munlink(missing_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# delete outdated file first\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m     _download_to_tmp_and_move(\n\u001b[0;32m   1289\u001b[0m         incomplete_path\u001b[38;5;241m=\u001b[39mpaths\u001b[38;5;241m.\u001b[39mincomplete_path(etag),\n\u001b[0;32m   1290\u001b[0m         destination_path\u001b[38;5;241m=\u001b[39mpaths\u001b[38;5;241m.\u001b[39mfile_path,\n\u001b[0;32m   1291\u001b[0m         url_to_download\u001b[38;5;241m=\u001b[39murl_to_download,\n\u001b[0;32m   1292\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   1293\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   1294\u001b[0m         expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[0;32m   1295\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m-> 1296\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m   1297\u001b[0m         etag\u001b[38;5;241m=\u001b[39metag,\n\u001b[0;32m   1298\u001b[0m         xet_file_data\u001b[38;5;241m=\u001b[39mxet_file_data,\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[0;32m   1301\u001b[0m write_download_metadata(local_dir\u001b[38;5;241m=\u001b[39mlocal_dir, filename\u001b[38;5;241m=\u001b[39mfilename, commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash, etag\u001b[38;5;241m=\u001b[39metag)\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:277\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request_wrapper\u001b[39m(\n\u001b[0;32m    265\u001b[0m     method: HTTP_METHOD_T, url: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, follow_relative_redirects: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m requests\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[0;32m    267\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper around requests methods to follow relative redirects if `follow_relative_redirects=True` even when\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;124;03m    `allow_redirection=False`.\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m    A backoff mechanism retries the HTTP call on 429, 503 and 504 errors.\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03m        method (`str`):\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m            HTTP method, such as 'GET' or 'HEAD'.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        url (`str`):\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m            The URL of the resource to fetch.\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;124;03m        follow_relative_redirects (`bool`, *optional*, defaults to `False`)\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;124;03m            If True, relative redirection (redirection to the same site) will be resolved even when `allow_redirection`\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m            kwarg is set to False. Useful when we want to follow a redirection to a renamed repository without\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;124;03m            following redirection to a CDN.\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m        **params (`dict`, *optional*):\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m            Params to pass to `requests.request`.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:301\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    296\u001b[0m parsed_target = urlparse(response.headers[\"Location\"])\n\u001b[0;32m    297\u001b[0m if parsed_target.netloc == \"\":\n\u001b[0;32m    298\u001b[0m     # This means it is a relative 'location' headers, as allowed by RFC 7231.\n\u001b[0;32m    299\u001b[0m     # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')\n\u001b[0;32m    300\u001b[0m     # We want to follow this relative redirect !\n\u001b[1;32m--> 301\u001b[0m     #\n\u001b[0;32m    302\u001b[0m     # Highly inspired by `resolve_redirects` from requests library.\n\u001b[0;32m    303\u001b[0m     # See https://github.com/psf/requests/blob/main/requests/sessions.py#L159\n\u001b[0;32m    304\u001b[0m     next_url = urlparse(url)._replace(path=parsed_target.path).geturl()\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:454\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepoNotFound\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    439\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m error_message \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid credentials in Authorization header\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;66;03m# => for now, we process them as `RepoNotFound` anyway.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;66;03m# See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepository Not Found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 454\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease make sure you specified the correct `repo_id` and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `repo_type`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you are trying to access a private or gated repo,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated. For more details, see\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    458\u001b[0m     )\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-6824c8c0-595703496a05777051014bf1;20c7c551-95de-454e-af4c-65576dcbc3a6)\n\nRepository Not Found for url: https://huggingface.co/mistral-7b/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m clusters_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclustered_papers.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load Mistral model and tokenizer using Auto classes\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m mistral_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmistral-7b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m mistral_model \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmistral-7b\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Function to generate summary with Mistral\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:779\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    775\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[0;32m    777\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    778\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m--> 779\u001b[0m     pretrained_model_name_or_path,\n\u001b[0;32m    780\u001b[0m     TOKENIZER_CONFIG_FILE,\n\u001b[0;32m    781\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    782\u001b[0m     force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    783\u001b[0m     resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    784\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    785\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    786\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    787\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    788\u001b[0m     subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[0;32m    789\u001b[0m     _raise_exceptions_for_gated_repo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    790\u001b[0m     _raise_exceptions_for_missing_entries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    791\u001b[0m     _raise_exceptions_for_connection_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    792\u001b[0m     _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[0;32m    793\u001b[0m )\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    795\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:612\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[1;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     TOKENIZER_MAPPING_NAMES: OrderedDict[\u001b[38;5;28mstr\u001b[39m, Tuple[Optional[\u001b[38;5;28mstr\u001b[39m], Optional[\u001b[38;5;28mstr\u001b[39m]]] \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     TOKENIZER_MAPPING_NAMES \u001b[38;5;241m=\u001b[39m OrderedDict(\n\u001b[0;32m     62\u001b[0m         [\n\u001b[0;32m     63\u001b[0m             (\n\u001b[0;32m     64\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malbert\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     65\u001b[0m                 (\n\u001b[0;32m     66\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlbertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     67\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlbertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     68\u001b[0m                 ),\n\u001b[0;32m     69\u001b[0m             ),\n\u001b[0;32m     70\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malign\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m     71\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maria\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m     72\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maya_vision\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCohereTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m     73\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbark\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m     74\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbart\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBartTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBartTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m     75\u001b[0m             (\n\u001b[0;32m     76\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbarthez\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     77\u001b[0m                 (\n\u001b[0;32m     78\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBarthezTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     79\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBarthezTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     80\u001b[0m                 ),\n\u001b[0;32m     81\u001b[0m             ),\n\u001b[0;32m     82\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbartpho\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBartphoTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m     83\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m     84\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertGenerationTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m     85\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-japanese\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertJapaneseTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m     86\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbertweet\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertweetTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m     87\u001b[0m             (\n\u001b[0;32m     88\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbig_bird\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     89\u001b[0m                 (\n\u001b[0;32m     90\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBigBirdTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     91\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBigBirdTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     92\u001b[0m                 ),\n\u001b[0;32m     93\u001b[0m             ),\n\u001b[0;32m     94\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigbird_pegasus\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPegasusTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPegasusTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m     95\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiogpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBioGptTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m     96\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblenderbot\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlenderbotTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlenderbotTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m     97\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblenderbot-small\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlenderbotSmallTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m     98\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblip\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m     99\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblip-2\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    100\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbloom\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBloomTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    101\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbridgetower\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    102\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbros\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    103\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbyt5\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mByT5Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    104\u001b[0m             (\n\u001b[0;32m    105\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamembert\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    106\u001b[0m                 (\n\u001b[0;32m    107\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCamembertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    108\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCamembertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m                 ),\n\u001b[0;32m    110\u001b[0m             ),\n\u001b[0;32m    111\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcanine\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCanineTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    112\u001b[0m             (\n\u001b[0;32m    113\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchameleon\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    114\u001b[0m                 (\n\u001b[0;32m    115\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    116\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    117\u001b[0m                 ),\n\u001b[0;32m    118\u001b[0m             ),\n\u001b[0;32m    119\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchinese_clip\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    120\u001b[0m             (\n\u001b[0;32m    121\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    122\u001b[0m                 (\n\u001b[0;32m    123\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    124\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m                 ),\n\u001b[0;32m    126\u001b[0m             ),\n\u001b[0;32m    127\u001b[0m             (\n\u001b[0;32m    128\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    129\u001b[0m                 (\n\u001b[0;32m    130\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    132\u001b[0m                 ),\n\u001b[0;32m    133\u001b[0m             ),\n\u001b[0;32m    134\u001b[0m             (\n\u001b[0;32m    135\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclipseg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    136\u001b[0m                 (\n\u001b[0;32m    137\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    138\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    139\u001b[0m                 ),\n\u001b[0;32m    140\u001b[0m             ),\n\u001b[0;32m    141\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclvp\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClvpTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    142\u001b[0m             (\n\u001b[0;32m    143\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_llama\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    144\u001b[0m                 (\n\u001b[0;32m    145\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCodeLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    146\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCodeLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m                 ),\n\u001b[0;32m    148\u001b[0m             ),\n\u001b[0;32m    149\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodegen\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCodeGenTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCodeGenTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    150\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcohere\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCohereTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    151\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcohere2\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCohereTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    152\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolpali\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    153\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvbert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    154\u001b[0m             (\n\u001b[0;32m    155\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    156\u001b[0m                 (\n\u001b[0;32m    157\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCpmTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCpmTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    159\u001b[0m                 ),\n\u001b[0;32m    160\u001b[0m             ),\n\u001b[0;32m    161\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpmant\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCpmAntTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    162\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mctrl\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCTRLTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    163\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata2vec-audio\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWav2Vec2CTCTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    164\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata2vec-text\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    165\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdbrx\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    166\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeberta\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDebertaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDebertaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    167\u001b[0m             (\n\u001b[0;32m    168\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeberta-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    169\u001b[0m                 (\n\u001b[0;32m    170\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDebertaV2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    171\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDebertaV2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    172\u001b[0m                 ),\n\u001b[0;32m    173\u001b[0m             ),\n\u001b[0;32m    174\u001b[0m             (\n\u001b[0;32m    175\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek_v3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    176\u001b[0m                 (\n\u001b[0;32m    177\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    178\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    179\u001b[0m                 ),\n\u001b[0;32m    180\u001b[0m             ),\n\u001b[0;32m    181\u001b[0m             (\n\u001b[0;32m    182\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiffllama\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    183\u001b[0m                 (\n\u001b[0;32m    184\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    185\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    186\u001b[0m                 ),\n\u001b[0;32m    187\u001b[0m             ),\n\u001b[0;32m    188\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistilBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistilBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    189\u001b[0m             (\n\u001b[0;32m    190\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    191\u001b[0m                 (\n\u001b[0;32m    192\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDPRQuestionEncoderTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    193\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDPRQuestionEncoderTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    194\u001b[0m                 ),\n\u001b[0;32m    195\u001b[0m             ),\n\u001b[0;32m    196\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melectra\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElectraTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElectraTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    197\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memu3\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    198\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mernie\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    199\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mernie_m\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErnieMTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    200\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mesm\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEsmTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    201\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalcon\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    202\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalcon_mamba\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPTNeoXTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    203\u001b[0m             (\n\u001b[0;32m    204\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfastspeech2_conformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    205\u001b[0m                 (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFastSpeech2ConformerTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_g2p_en_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    206\u001b[0m             ),\n\u001b[0;32m    207\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflaubert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlaubertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    208\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfnet\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFNetTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFNetTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    209\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfsmt\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFSMTTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    210\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunnel\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunnelTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunnelTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    211\u001b[0m             (\n\u001b[0;32m    212\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m                 (\n\u001b[0;32m    214\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemmaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemmaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    216\u001b[0m                 ),\n\u001b[0;32m    217\u001b[0m             ),\n\u001b[0;32m    218\u001b[0m             (\n\u001b[0;32m    219\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m                 (\n\u001b[0;32m    221\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemmaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    222\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemmaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    223\u001b[0m                 ),\n\u001b[0;32m    224\u001b[0m             ),\n\u001b[0;32m    225\u001b[0m             (\n\u001b[0;32m    226\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m                 (\n\u001b[0;32m    228\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemmaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    229\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemmaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    230\u001b[0m                 ),\n\u001b[0;32m    231\u001b[0m             ),\n\u001b[0;32m    232\u001b[0m             (\n\u001b[0;32m    233\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma3_text\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    234\u001b[0m                 (\n\u001b[0;32m    235\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemmaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    236\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemmaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    237\u001b[0m                 ),\n\u001b[0;32m    238\u001b[0m             ),\n\u001b[0;32m    239\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgit\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    240\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglm\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    241\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglm4\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    242\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-sw3\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPTSw3Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    243\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    244\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt_bigcode\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    245\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt_neo\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    246\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt_neox\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPTNeoXTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    247\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt_neox_japanese\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPTNeoXJapaneseTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    248\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgptj\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    249\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgptsan-japanese\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPTSanJapaneseTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    250\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrounding-dino\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    251\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupvit\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    252\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhelium\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    253\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mherbert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHerbertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHerbertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    254\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhubert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWav2Vec2CTCTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    255\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mibert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    256\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midefics\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    257\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midefics2\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    258\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midefics3\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    259\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstructblip\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    260\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstructblipvideo\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    261\u001b[0m             (\n\u001b[0;32m    262\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjamba\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    263\u001b[0m                 (\n\u001b[0;32m    264\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    265\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    266\u001b[0m                 ),\n\u001b[0;32m    267\u001b[0m             ),\n\u001b[0;32m    268\u001b[0m             (\n\u001b[0;32m    269\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjetmoe\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    270\u001b[0m                 (\n\u001b[0;32m    271\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    272\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    273\u001b[0m                 ),\n\u001b[0;32m    274\u001b[0m             ),\n\u001b[0;32m    275\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjukebox\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJukeboxTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    276\u001b[0m             (\n\u001b[0;32m    277\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkosmos-2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    278\u001b[0m                 (\n\u001b[0;32m    279\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXLMRobertaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    280\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXLMRobertaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    281\u001b[0m                 ),\n\u001b[0;32m    282\u001b[0m             ),\n\u001b[0;32m    283\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayoutlm\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayoutLMTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayoutLMTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    284\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayoutlmv2\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayoutLMv2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayoutLMv2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    285\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayoutlmv3\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayoutLMv3Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayoutLMv3TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    286\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayoutxlm\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayoutXLMTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayoutXLMTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    287\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mled\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLEDTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLEDTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    288\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlilt\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayoutLMv3Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayoutLMv3TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    289\u001b[0m             (\n\u001b[0;32m    290\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    291\u001b[0m                 (\n\u001b[0;32m    292\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    293\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    294\u001b[0m                 ),\n\u001b[0;32m    295\u001b[0m             ),\n\u001b[0;32m    296\u001b[0m             (\n\u001b[0;32m    297\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    298\u001b[0m                 (\n\u001b[0;32m    299\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    300\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    301\u001b[0m                 ),\n\u001b[0;32m    302\u001b[0m             ),\n\u001b[0;32m    303\u001b[0m             (\n\u001b[0;32m    304\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama4_text\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    305\u001b[0m                 (\n\u001b[0;32m    306\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m                 ),\n\u001b[0;32m    309\u001b[0m             ),\n\u001b[0;32m    310\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllava\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    311\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllava_next\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    312\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllava_next_video\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    313\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllava_onevision\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    314\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongformer\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLongformerTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLongformerTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    315\u001b[0m             (\n\u001b[0;32m    316\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongt5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    317\u001b[0m                 (\n\u001b[0;32m    318\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT5Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    319\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT5TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    320\u001b[0m                 ),\n\u001b[0;32m    321\u001b[0m             ),\n\u001b[0;32m    322\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mluke\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLukeTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    323\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxmert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLxmertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLxmertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    324\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2m_100\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM2M100Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    325\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmamba\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPTNeoXTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    326\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmamba2\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPTNeoXTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    327\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarian\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMarianTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    328\u001b[0m             (\n\u001b[0;32m    329\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmbart\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    330\u001b[0m                 (\n\u001b[0;32m    331\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMBartTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    332\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMBartTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    333\u001b[0m                 ),\n\u001b[0;32m    334\u001b[0m             ),\n\u001b[0;32m    335\u001b[0m             (\n\u001b[0;32m    336\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmbart50\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    337\u001b[0m                 (\n\u001b[0;32m    338\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMBart50Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    339\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMBart50TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    340\u001b[0m                 ),\n\u001b[0;32m    341\u001b[0m             ),\n\u001b[0;32m    342\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmega\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    343\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmegatron-bert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    344\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmgp-str\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMgpstrTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    345\u001b[0m             (\n\u001b[0;32m    346\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistral\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    347\u001b[0m                 (\n\u001b[0;32m    348\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    350\u001b[0m                 ),\n\u001b[0;32m    351\u001b[0m             ),\n\u001b[0;32m    352\u001b[0m             (\n\u001b[0;32m    353\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixtral\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    354\u001b[0m                 (\n\u001b[0;32m    355\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    356\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    357\u001b[0m                 ),\n\u001b[0;32m    358\u001b[0m             ),\n\u001b[0;32m    359\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmllama\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    360\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmluke\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLukeTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    361\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmobilebert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMobileBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMobileBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    362\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodernbert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    363\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoonshine\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    364\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoshi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    365\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmpnet\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMPNetTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMPNetTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    366\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPTNeoXTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    367\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmra\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    368\u001b[0m             (\n\u001b[0;32m    369\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmt5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    370\u001b[0m                 (\n\u001b[0;32m    371\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMT5Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    372\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMT5TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    373\u001b[0m                 ),\n\u001b[0;32m    374\u001b[0m             ),\n\u001b[0;32m    375\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmusicgen\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT5Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT5TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    376\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmusicgen_melody\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT5Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT5TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    377\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmvp\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMvpTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMvpTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    378\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmyt5\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMyT5Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    379\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnemotron\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    380\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnezha\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    381\u001b[0m             (\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnllb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    383\u001b[0m                 (\n\u001b[0;32m    384\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNllbTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    385\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNllbTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    386\u001b[0m                 ),\n\u001b[0;32m    387\u001b[0m             ),\n\u001b[0;32m    388\u001b[0m             (\n\u001b[0;32m    389\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnllb-moe\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    390\u001b[0m                 (\n\u001b[0;32m    391\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNllbTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    392\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNllbTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    393\u001b[0m                 ),\n\u001b[0;32m    394\u001b[0m             ),\n\u001b[0;32m    395\u001b[0m             (\n\u001b[0;32m    396\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnystromformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    397\u001b[0m                 (\n\u001b[0;32m    398\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlbertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    399\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlbertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    400\u001b[0m                 ),\n\u001b[0;32m    401\u001b[0m             ),\n\u001b[0;32m    402\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124molmo\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPTNeoXTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    403\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124molmo2\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPTNeoXTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    404\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124molmoe\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPTNeoXTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    405\u001b[0m             (\n\u001b[0;32m    406\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124momdet-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    407\u001b[0m                 (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    408\u001b[0m             ),\n\u001b[0;32m    409\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moneformer\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    410\u001b[0m             (\n\u001b[0;32m    411\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai-gpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    412\u001b[0m                 (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAIGPTTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAIGPTTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    413\u001b[0m             ),\n\u001b[0;32m    414\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopt\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    415\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mowlv2\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    416\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mowlvit\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    417\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaligemma\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    418\u001b[0m             (\n\u001b[0;32m    419\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpegasus\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    420\u001b[0m                 (\n\u001b[0;32m    421\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPegasusTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    422\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPegasusTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    423\u001b[0m                 ),\n\u001b[0;32m    424\u001b[0m             ),\n\u001b[0;32m    425\u001b[0m             (\n\u001b[0;32m    426\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpegasus_x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    427\u001b[0m                 (\n\u001b[0;32m    428\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPegasusTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    429\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPegasusTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    430\u001b[0m                 ),\n\u001b[0;32m    431\u001b[0m             ),\n\u001b[0;32m    432\u001b[0m             (\n\u001b[0;32m    433\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperceiver\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    434\u001b[0m                 (\n\u001b[0;32m    435\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerceiverTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    436\u001b[0m                     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    437\u001b[0m                 ),\n\u001b[0;32m    438\u001b[0m             ),\n\u001b[0;32m    439\u001b[0m             (\n\u001b[0;32m    440\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpersimmon\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    441\u001b[0m                 (\n\u001b[0;32m    442\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    443\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    444\u001b[0m                 ),\n\u001b[0;32m    445\u001b[0m             ),\n\u001b[0;32m    446\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCodeGenTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCodeGenTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    447\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi3\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    448\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphimoe\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    449\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphobert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhobertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    450\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpix2struct\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT5Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT5TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    451\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixtral\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    452\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplbart\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLBartTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    453\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprophetnet\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProphetNetTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    454\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqdqbert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    455\u001b[0m             (\n\u001b[0;32m    456\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqwen2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    457\u001b[0m                 (\n\u001b[0;32m    458\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    459\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    460\u001b[0m                 ),\n\u001b[0;32m    461\u001b[0m             ),\n\u001b[0;32m    462\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqwen2_5_vl\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    463\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqwen2_audio\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    464\u001b[0m             (\n\u001b[0;32m    465\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqwen2_moe\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    466\u001b[0m                 (\n\u001b[0;32m    467\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    468\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    469\u001b[0m                 ),\n\u001b[0;32m    470\u001b[0m             ),\n\u001b[0;32m    471\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqwen2_vl\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    472\u001b[0m             (\n\u001b[0;32m    473\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqwen3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    474\u001b[0m                 (\n\u001b[0;32m    475\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    476\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    477\u001b[0m                 ),\n\u001b[0;32m    478\u001b[0m             ),\n\u001b[0;32m    479\u001b[0m             (\n\u001b[0;32m    480\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqwen3_moe\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    481\u001b[0m                 (\n\u001b[0;32m    482\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    483\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    484\u001b[0m                 ),\n\u001b[0;32m    485\u001b[0m             ),\n\u001b[0;32m    486\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrag\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRagTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    487\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrealm\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRealmTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRealmTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    488\u001b[0m             (\n\u001b[0;32m    489\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecurrent_gemma\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    490\u001b[0m                 (\n\u001b[0;32m    491\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemmaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemmaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m                 ),\n\u001b[0;32m    494\u001b[0m             ),\n\u001b[0;32m    495\u001b[0m             (\n\u001b[0;32m    496\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    497\u001b[0m                 (\n\u001b[0;32m    498\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReformerTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    499\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReformerTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    500\u001b[0m                 ),\n\u001b[0;32m    501\u001b[0m             ),\n\u001b[0;32m    502\u001b[0m             (\n\u001b[0;32m    503\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrembert\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    504\u001b[0m                 (\n\u001b[0;32m    505\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    506\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    507\u001b[0m                 ),\n\u001b[0;32m    508\u001b[0m             ),\n\u001b[0;32m    509\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretribert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetriBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetriBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    510\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    511\u001b[0m             (\n\u001b[0;32m    512\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta-prelayernorm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    513\u001b[0m                 (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    514\u001b[0m             ),\n\u001b[0;32m    515\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_bert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoCBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    516\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroformer\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoFormerTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoFormerTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    517\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrwkv\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPTNeoXTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    518\u001b[0m             (\n\u001b[0;32m    519\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseamless_m4t\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    520\u001b[0m                 (\n\u001b[0;32m    521\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeamlessM4TTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    522\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeamlessM4TTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    523\u001b[0m                 ),\n\u001b[0;32m    524\u001b[0m             ),\n\u001b[0;32m    525\u001b[0m             (\n\u001b[0;32m    526\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseamless_m4t_v2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    527\u001b[0m                 (\n\u001b[0;32m    528\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeamlessM4TTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    529\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeamlessM4TTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    530\u001b[0m                 ),\n\u001b[0;32m    531\u001b[0m             ),\n\u001b[0;32m    532\u001b[0m             (\n\u001b[0;32m    533\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshieldgemma2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    534\u001b[0m                 (\n\u001b[0;32m    535\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemmaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    536\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemmaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    537\u001b[0m                 ),\n\u001b[0;32m    538\u001b[0m             ),\n\u001b[0;32m    539\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msiglip\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSiglipTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    540\u001b[0m             (\n\u001b[0;32m    541\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msiglip2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    542\u001b[0m                 (\n\u001b[0;32m    543\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemmaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    544\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemmaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    545\u001b[0m                 ),\n\u001b[0;32m    546\u001b[0m             ),\n\u001b[0;32m    547\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeech_to_text\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeech2TextTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    548\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeech_to_text_2\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeech2Text2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    549\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeecht5\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeechT5Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    550\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplinter\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSplinterTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSplinterTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m    551\u001b[0m             (\n\u001b[0;32m    552\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqueezebert\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    553\u001b[0m                 (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSqueezeBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSqueezeBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    554\u001b[0m             ),\n\u001b[0;32m    555\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstablelm\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPTNeoXTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    556\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarcoder2\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT2TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    557\u001b[0m             (\n\u001b[0;32m    558\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswitch_transformers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    559\u001b[0m                 (\n\u001b[0;32m    560\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT5Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    561\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT5TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    562\u001b[0m                 ),\n\u001b[0;32m    563\u001b[0m             ),\n\u001b[0;32m    564\u001b[0m             (\n\u001b[0;32m    565\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    566\u001b[0m                 (\n\u001b[0;32m    567\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT5Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    568\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT5TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    569\u001b[0m                 ),\n\u001b[0;32m    570\u001b[0m             ),\n\u001b[0;32m    571\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapas\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTapasTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    572\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapex\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTapexTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    573\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransfo-xl\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransfoXLTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    574\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtvp\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    575\u001b[0m             (\n\u001b[0;32m    576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mudop\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    577\u001b[0m                 (\n\u001b[0;32m    578\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUdopTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUdopTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    580\u001b[0m                 ),\n\u001b[0;32m    581\u001b[0m             ),\n\u001b[0;32m    582\u001b[0m             (\n\u001b[0;32m    583\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mumt5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    584\u001b[0m                 (\n\u001b[0;32m    585\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT5Tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    586\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT5TokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    587\u001b[0m                 ),\n\u001b[0;32m    588\u001b[0m             ),\n\u001b[0;32m    589\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_llava\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    590\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvilt\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    591\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvipllava\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    592\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisual_bert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    593\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvits\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVitsTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    594\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav2vec2\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWav2Vec2CTCTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    595\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav2vec2-bert\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWav2Vec2CTCTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    596\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav2vec2-conformer\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWav2Vec2CTCTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    597\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav2vec2_phoneme\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWav2Vec2PhonemeCTCTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    598\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhisper\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhisperTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhisperTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    599\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIPTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    600\u001b[0m             (\n\u001b[0;32m    601\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxglm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    602\u001b[0m                 (\n\u001b[0;32m    603\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGLMTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    604\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGLMTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    605\u001b[0m                 ),\n\u001b[0;32m    606\u001b[0m             ),\n\u001b[0;32m    607\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlm\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXLMTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    608\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlm-prophetnet\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXLMProphetNetTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[0;32m    609\u001b[0m             (\n\u001b[0;32m    610\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlm-roberta\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    611\u001b[0m                 (\n\u001b[1;32m--> 612\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXLMRobertaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    613\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXLMRobertaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    614\u001b[0m                 ),\n\u001b[0;32m    615\u001b[0m             ),\n\u001b[0;32m    616\u001b[0m             (\n\u001b[0;32m    617\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlm-roberta-xl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    618\u001b[0m                 (\n\u001b[0;32m    619\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXLMRobertaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    620\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXLMRobertaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    621\u001b[0m                 ),\n\u001b[0;32m    622\u001b[0m             ),\n\u001b[0;32m    623\u001b[0m             (\n\u001b[0;32m    624\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlnet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    625\u001b[0m                 (\n\u001b[0;32m    626\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXLNetTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXLNetTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    628\u001b[0m                 ),\n\u001b[0;32m    629\u001b[0m             ),\n\u001b[0;32m    630\u001b[0m             (\n\u001b[0;32m    631\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxmod\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    632\u001b[0m                 (\n\u001b[0;32m    633\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXLMRobertaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    634\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXLMRobertaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    635\u001b[0m                 ),\n\u001b[0;32m    636\u001b[0m             ),\n\u001b[0;32m    637\u001b[0m             (\n\u001b[0;32m    638\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myoso\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    639\u001b[0m                 (\n\u001b[0;32m    640\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlbertTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    641\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlbertTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    642\u001b[0m                 ),\n\u001b[0;32m    643\u001b[0m             ),\n\u001b[0;32m    644\u001b[0m             (\n\u001b[0;32m    645\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzamba\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    646\u001b[0m                 (\n\u001b[0;32m    647\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    648\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    649\u001b[0m                 ),\n\u001b[0;32m    650\u001b[0m             ),\n\u001b[0;32m    651\u001b[0m             (\n\u001b[0;32m    652\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzamba2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    653\u001b[0m                 (\n\u001b[0;32m    654\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentencepiece_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    655\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaTokenizerFast\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    656\u001b[0m                 ),\n\u001b[0;32m    657\u001b[0m             ),\n\u001b[0;32m    658\u001b[0m         ]\n\u001b[0;32m    659\u001b[0m     )\n\u001b[0;32m    661\u001b[0m TOKENIZER_MAPPING \u001b[38;5;241m=\u001b[39m _LazyAutoMapping(CONFIG_MAPPING_NAMES, TOKENIZER_MAPPING_NAMES)\n\u001b[0;32m    663\u001b[0m CONFIG_TO_TYPE \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING_NAMES\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:421\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    419\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# download the files if needed\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[0;32m    424\u001b[0m         hf_hub_download(\n\u001b[0;32m    425\u001b[0m             path_or_repo_id,\n\u001b[0;32m    426\u001b[0m             filenames[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    436\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    437\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: mistral-7b is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import pandas as pd\n",
    "\n",
    "# Load the clusters CSV file (make sure to provide the correct file path)\n",
    "clusters_df = pd.read_csv('clustered_papers.csv')\n",
    "\n",
    "# Load Mistral model and tokenizer using Auto classes\n",
    "mistral_tokenizer = AutoTokenizer.from_pretrained('mistral-7b')\n",
    "mistral_model = AutoModelForSeq2SeqLM.from_pretrained('mistral-7b')\n",
    "\n",
    "# Function to generate summary with Mistral\n",
    "def generate_summary_with_mistral(text):\n",
    "    mistral_inputs = mistral_tokenizer(text, return_tensors=\"pt\")\n",
    "    generated_output = mistral_model.generate(mistral_inputs['input_ids'], max_length=300, num_return_sequences=1)\n",
    "    summary = mistral_tokenizer.decode(generated_output[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Loop through each cluster and generate summaries with bibliometric insights\n",
    "for cluster_id in clusters_df['cluster_id'].unique():\n",
    "    # Filter articles for the current cluster\n",
    "    cluster_articles = clusters_df[clusters_df['cluster_id'] == cluster_id]\n",
    "    \n",
    "    # Combine all abstracts from the current cluster for summarization\n",
    "    combined_abstracts = \" \".join(cluster_articles['abstract'].tolist())\n",
    "    \n",
    "    # Generate a summary for the combined abstracts\n",
    "    generated_summary = generate_summary_with_mistral(combined_abstracts)\n",
    "    \n",
    "    # Combine bibliometric metrics\n",
    "    avg_citation_count = cluster_articles['citation_count'].mean()\n",
    "    avg_h_index = cluster_articles['h_index'].mean()\n",
    "    \n",
    "    # Format output to make it more human-friendly\n",
    "    print(f\"Research Trends for Cluster {cluster_id}:\")\n",
    "    print(f\"------------------------------------------------\")\n",
    "    print(f\"**Summary of Research**: {generated_summary}\")\n",
    "    print(f\"\\n**Bibliometric Insights**:\")\n",
    "    print(f\"- Average Citation Count: {avg_citation_count:.2f}\")\n",
    "    print(f\"- Average H-index: {avg_h_index:.2f}\")\n",
    "    print(f\"- Total Number of Papers in Cluster: {len(cluster_articles)}\")\n",
    "    print(f\"- Most Cited Paper: {cluster_articles.loc[cluster_articles['citation_count'].idxmax()]['title']}\")\n",
    "    print(f\"- Top Author: {cluster_articles.groupby('author')['citation_count'].sum().idxmax()}\")\n",
    "    print(f\"------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01444c41",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1.\n401 Client Error. (Request ID: Root=1-6824cb2c-71c6583710d6c0a9237dd1a4;0157bd78-bb45-49bb-b097-0c78997e0478)\n\nCannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/resolve/main/config.json.\nAccess to model mistralai/Mistral-7B-Instruct-v0.1 is restricted. You must have access to it and be authenticated to access it. Please log in.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhf_raise_for_status\u001b[39m(response: Response, endpoint_name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03m    Internal version of `response.raise_for_status()` that will refine a\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m    potential HTTPError. Raised exception will be an instance of `HfHubHTTPError`.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03m    This helper is meant to be the unique method to raise_for_status when making a call\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03m    to the Hugging Face Hub.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;124;03m    ```py\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m        import requests\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m        from huggingface_hub.utils import get_session, hf_raise_for_status, HfHubHTTPError\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m        response = get_session().post(...)\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m        try:\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;124;03m            hf_raise_for_status(response)\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m        except HfHubHTTPError as e:\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m            print(str(e)) # formatted message\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m            e.request_id, e.server_message # details returned by server\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m            # Complete the error message with additional information once it's raised\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m            e.append_to_message(\"\\n`create_commit` expects the repository to exist.\")\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m            raise\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;124;03m        response (`Response`):\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m            Response from the server.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m        endpoint_name (`str`, *optional*):\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;124;03m            Name of the endpoint that has been called. If provided, the error message\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;124;03m            will be more complete.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03m    <Tip warning={true}>\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m    Raises when the request has failed:\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m        - [`~utils.RepositoryNotFoundError`]\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m            If the repository to download from cannot be found. This may be because it\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m            doesn't exist, because `repo_type` is not set correctly, or because the repo\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m            is `private` and you do not have access.\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m        - [`~utils.GatedRepoError`]\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;124;03m            If the repository exists but is gated and the user is not on the authorized\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m            list.\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        - [`~utils.RevisionNotFoundError`]\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m            If the repository exists but the revision couldn't be find.\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m        - [`~utils.EntryNotFoundError`]\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m            If the repository exists but the entry (e.g. the requested file) couldn't be\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m            find.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m        - [`~utils.BadRequestError`]\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;124;03m            If request failed with a HTTP 400 BadRequest error.\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03m        - [`~utils.HfHubHTTPError`]\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m            If request failed for a reason not listed above.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \n\u001b[1;32m--> 406\u001b[0m \u001b[38;5;124;03m    </Tip>\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    396\u001b[0m     cache_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(cache_dir)\n\u001b[1;32m--> 398\u001b[0m existing_files \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    399\u001b[0m file_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;129m@validate_hf_hub_args\u001b[39m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhf_hub_download\u001b[39m(\n\u001b[0;32m    811\u001b[0m     repo_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    831\u001b[0m     local_dir_use_symlinks: Union[\u001b[38;5;28mbool\u001b[39m, Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    832\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    833\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download a given file if it's not already present in the local cache.\u001b[39;00m\n\u001b[0;32m    834\u001b[0m \n\u001b[0;32m    835\u001b[0m \u001b[38;5;124;03m    The new cache file layout looks like this:\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;124;03m    - The cache directory contains one subfolder per repo_id (namespaced by repo type)\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;124;03m    - inside each repo folder:\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;124;03m        - refs is a list of the latest known revision => commit_hash pairs\u001b[39;00m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;124;03m        - blobs contains the actual file blobs (identified by their git-sha or sha256, depending on\u001b[39;00m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;124;03m          whether they're LFS files or not)\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;124;03m        - snapshots contains one subfolder per commit, each \"commit\" contains the subset of the files\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;124;03m          that have been resolved at that particular commit. Each filename is a symlink to the blob\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;124;03m          at that particular commit.\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \n\u001b[0;32m    845\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;124;03m    [  96]  .\u001b[39;00m\n\u001b[0;32m    847\u001b[0m \u001b[38;5;124;03m    └── [ 160]  models--julien-c--EsperBERTo-small\u001b[39;00m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;124;03m        ├── [ 160]  blobs\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;124;03m        │   ├── [321M]  403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;124;03m        │   ├── [ 398]  7cb18dc9bafbfcf74629a4b760af1b160957a83e\u001b[39;00m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;124;03m        │   └── [1.4K]  d7edf6bd2a681fb0175f7735299831ee1b22b812\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;124;03m        ├── [  96]  refs\u001b[39;00m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;124;03m        │   └── [  40]  main\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;124;03m        └── [ 128]  snapshots\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;124;03m            ├── [ 128]  2439f60ef33a0d46d85da5001d52aeda5b00ce9f\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;124;03m            │   ├── [  52]  README.md -> ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;124;03m            │   └── [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;124;03m            └── [ 128]  bbc77c8132af1cc5cf678da3f1ddf2de43606d48\u001b[39;00m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;124;03m                ├── [  52]  README.md -> ../../blobs/7cb18dc9bafbfcf74629a4b760af1b160957a83e\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;124;03m                └── [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m \n\u001b[0;32m    863\u001b[0m \u001b[38;5;124;03m    If `local_dir` is provided, the file structure from the repo will be replicated in this location. When using this\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;124;03m    option, the `cache_dir` will not be used and a `.cache/huggingface/` folder will be created at the root of `local_dir`\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;124;03m    to store some metadata related to the downloaded files. While this mechanism is not as robust as the main\u001b[39;00m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;124;03m    cache-system, it's optimized for regularly pulling the latest version of a repository.\u001b[39;00m\n\u001b[0;32m    867\u001b[0m \n\u001b[0;32m    868\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    869\u001b[0m \u001b[38;5;124;03m        repo_id (`str`):\u001b[39;00m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;124;03m            A user or an organization name and a repo name separated by a `/`.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;124;03m        filename (`str`):\u001b[39;00m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;124;03m            The name of the file in the repo.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;124;03m        subfolder (`str`, *optional*):\u001b[39;00m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;124;03m            An optional value corresponding to a folder inside the model repo.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;124;03m        repo_type (`str`, *optional*):\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;124;03m            Set to `\"dataset\"` or `\"space\"` if downloading from a dataset or space,\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;124;03m            `None` or `\"model\"` if downloading from a model. Default is `None`.\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03m        revision (`str`, *optional*):\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;124;03m            An optional Git revision id which can be a branch name, a tag, or a\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;124;03m            commit hash.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;124;03m        library_name (`str`, *optional*):\u001b[39;00m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;124;03m            The name of the library to which the object corresponds.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;124;03m        library_version (`str`, *optional*):\u001b[39;00m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03m            The version of the library.\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m        cache_dir (`str`, `Path`, *optional*):\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m            Path to the folder where cached files are stored.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m        local_dir (`str` or `Path`, *optional*):\u001b[39;00m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;124;03m            If provided, the downloaded file will be placed under this directory.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;124;03m        user_agent (`dict`, `str`, *optional*):\u001b[39;00m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m            The user-agent info in the form of a dictionary or a string.\u001b[39;00m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;124;03m        force_download (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;124;03m            Whether the file should be downloaded even if it already exists in\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;124;03m            the local cache.\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;124;03m        proxies (`dict`, *optional*):\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;124;03m            Dictionary mapping protocol to the URL of the proxy passed to\u001b[39;00m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;124;03m            `requests.request`.\u001b[39;00m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;124;03m        etag_timeout (`float`, *optional*, defaults to `10`):\u001b[39;00m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;124;03m            When fetching ETag, how many seconds to wait for the server to send\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;124;03m            data before giving up which is passed to `requests.request`.\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;124;03m        token (`str`, `bool`, *optional*):\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;124;03m            A token to be used for the download.\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m                - If `True`, the token is read from the HuggingFace config\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m                  folder.\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m                - If a string, it's used as the authentication token.\u001b[39;00m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;124;03m        local_files_only (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;124;03m            If `True`, avoid downloading the file and return the path to the\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;124;03m            local cached file if it exists.\u001b[39;00m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;124;03m        headers (`dict`, *optional*):\u001b[39;00m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;124;03m            Additional headers to be sent with the request.\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03m        `str`: Local path of file or if networking is off, last version of file cached on disk.\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \n\u001b[0;32m    914\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;124;03m        [`~utils.RepositoryNotFoundError`]\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;124;03m            If the repository to download from cannot be found. This may be because it doesn't exist,\u001b[39;00m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;124;03m            or because it is set to `private` and you do not have access.\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;124;03m        [`~utils.RevisionNotFoundError`]\u001b[39;00m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;124;03m            If the revision to download from cannot be found.\u001b[39;00m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;124;03m        [`~utils.EntryNotFoundError`]\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;124;03m            If the file to download cannot be found.\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;124;03m        [`~utils.LocalEntryNotFoundError`]\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;124;03m            If network is disabled or unavailable and file is not found in cache.\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;124;03m        [`EnvironmentError`](https://docs.python.org/3/library/exceptions.html#EnvironmentError)\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;124;03m            If `token=True` but the token cannot be found.\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;124;03m        [`OSError`](https://docs.python.org/3/library/exceptions.html#OSError)\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;124;03m            If ETag cannot be determined.\u001b[39;00m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;124;03m        [`ValueError`](https://docs.python.org/3/library/exceptions.html#ValueError)\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;124;03m            If some parameter value is invalid.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m \n\u001b[0;32m    931\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHF_HUB_ETAG_TIMEOUT \u001b[38;5;241m!=\u001b[39m constants\u001b[38;5;241m.\u001b[39mDEFAULT_ETAG_TIMEOUT:\n\u001b[0;32m    933\u001b[0m         \u001b[38;5;66;03m# Respect environment variable above user value\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:969\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1484\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m HfFileMetadata(\n\u001b[0;32m   1461\u001b[0m         commit_hash\u001b[38;5;241m=\u001b[39mr\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(constants\u001b[38;5;241m.\u001b[39mHUGGINGFACE_HEADER_X_REPO_COMMIT),\n\u001b[0;32m   1462\u001b[0m         \u001b[38;5;66;03m# We favor a custom header indicating the etag of the linked resource, and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1472\u001b[0m         xet_file_data\u001b[38;5;241m=\u001b[39mparse_xet_file_data_from_response(r),  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m     )\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_metadata_or_catch_error\u001b[39m(\n\u001b[0;32m   1477\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   1478\u001b[0m     repo_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1479\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1480\u001b[0m     repo_type: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1481\u001b[0m     revision: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1482\u001b[0m     endpoint: Optional[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   1483\u001b[0m     proxies: Optional[Dict],\n\u001b[1;32m-> 1484\u001b[0m     etag_timeout: Optional[\u001b[38;5;28mfloat\u001b[39m],\n\u001b[0;32m   1485\u001b[0m     headers: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m],  \u001b[38;5;66;03m# mutated inplace!\u001b[39;00m\n\u001b[0;32m   1486\u001b[0m     token: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[0;32m   1487\u001b[0m     local_files_only: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   1488\u001b[0m     relative_filename: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# only used to store `.no_exists` in cache\u001b[39;00m\n\u001b[0;32m   1489\u001b[0m     storage_folder: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# only used to store `.no_exists` in cache\u001b[39;00m\n\u001b[0;32m   1490\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\n\u001b[0;32m   1491\u001b[0m     \u001b[38;5;66;03m# Either an exception is caught and returned\u001b[39;00m\n\u001b[0;32m   1492\u001b[0m     Tuple[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m],\n\u001b[0;32m   1493\u001b[0m     \u001b[38;5;66;03m# Or the metadata is returned as\u001b[39;00m\n\u001b[0;32m   1494\u001b[0m     \u001b[38;5;66;03m# `(url_to_download, etag, commit_hash, expected_size, xet_file_data, None)`\u001b[39;00m\n\u001b[0;32m   1495\u001b[0m     Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, Optional[XetFileData], \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[0;32m   1496\u001b[0m ]:\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get metadata for a file on the Hub, safely handling network issues.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \n\u001b[0;32m   1499\u001b[0m \u001b[38;5;124;03m    Returns either the etag, commit_hash and expected size of the file, or the error\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;124;03m          domain of the location (typically an S3 bucket).\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1376\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(refs_dir):\n\u001b[1;32m-> 1376\u001b[0m     revision_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(refs_dir, revision)\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(revision_file):\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1296\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1287\u001b[0m     paths\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;241m.\u001b[39munlink(missing_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# delete outdated file first\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m     _download_to_tmp_and_move(\n\u001b[0;32m   1289\u001b[0m         incomplete_path\u001b[38;5;241m=\u001b[39mpaths\u001b[38;5;241m.\u001b[39mincomplete_path(etag),\n\u001b[0;32m   1290\u001b[0m         destination_path\u001b[38;5;241m=\u001b[39mpaths\u001b[38;5;241m.\u001b[39mfile_path,\n\u001b[0;32m   1291\u001b[0m         url_to_download\u001b[38;5;241m=\u001b[39murl_to_download,\n\u001b[0;32m   1292\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   1293\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   1294\u001b[0m         expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[0;32m   1295\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m-> 1296\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m   1297\u001b[0m         etag\u001b[38;5;241m=\u001b[39metag,\n\u001b[0;32m   1298\u001b[0m         xet_file_data\u001b[38;5;241m=\u001b[39mxet_file_data,\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[0;32m   1301\u001b[0m write_download_metadata(local_dir\u001b[38;5;241m=\u001b[39mlocal_dir, filename\u001b[38;5;241m=\u001b[39mfilename, commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash, etag\u001b[38;5;241m=\u001b[39metag)\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:277\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request_wrapper\u001b[39m(\n\u001b[0;32m    265\u001b[0m     method: HTTP_METHOD_T, url: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, follow_relative_redirects: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m requests\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[0;32m    267\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper around requests methods to follow relative redirects if `follow_relative_redirects=True` even when\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;124;03m    `allow_redirection=False`.\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m    A backoff mechanism retries the HTTP call on 429, 503 and 504 errors.\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03m        method (`str`):\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m            HTTP method, such as 'GET' or 'HEAD'.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        url (`str`):\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m            The URL of the resource to fetch.\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;124;03m        follow_relative_redirects (`bool`, *optional*, defaults to `False`)\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;124;03m            If True, relative redirection (redirection to the same site) will be resolved even when `allow_redirection`\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m            kwarg is set to False. Useful when we want to follow a redirection to a renamed repository without\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;124;03m            following redirection to a CDN.\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m        **params (`dict`, *optional*):\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m            Params to pass to `requests.request`.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:301\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    296\u001b[0m parsed_target = urlparse(response.headers[\"Location\"])\n\u001b[0;32m    297\u001b[0m if parsed_target.netloc == \"\":\n\u001b[0;32m    298\u001b[0m     # This means it is a relative 'location' headers, as allowed by RFC 7231.\n\u001b[0;32m    299\u001b[0m     # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')\n\u001b[0;32m    300\u001b[0m     # We want to follow this relative redirect !\n\u001b[1;32m--> 301\u001b[0m     #\n\u001b[0;32m    302\u001b[0m     # Highly inspired by `resolve_redirects` from requests library.\n\u001b[0;32m    303\u001b[0m     # See https://github.com/psf/requests/blob/main/requests/sessions.py#L159\n\u001b[0;32m    304\u001b[0m     next_url = urlparse(url)._replace(path=parsed_target.path).geturl()\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:423\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGatedRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 423\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    425\u001b[0m     )\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-6824cb2c-71c6583710d6c0a9237dd1a4;0157bd78-bb45-49bb-b097-0c78997e0478)\n\nCannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/resolve/main/config.json.\nAccess to model mistralai/Mistral-7B-Instruct-v0.1 is restricted. You must have access to it and be authenticated to access it. Please log in.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load Mistral model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m mistral_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmistral_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m      9\u001b[0m     mistral_id,\n\u001b[0;32m     10\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[0;32m     11\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Load your clustered data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:794\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    777\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    778\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m    779\u001b[0m     pretrained_model_name_or_path,\n\u001b[0;32m    780\u001b[0m     TOKENIZER_CONFIG_FILE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    792\u001b[0m     _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[0;32m    793\u001b[0m )\n\u001b[1;32m--> 794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    795\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1138\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         config_class \u001b[38;5;241m=\u001b[39m CONFIG_MAPPING[config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1134\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe checkpoint you are trying to load has model type `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1135\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut Transformers does not recognize this architecture. This could be because of an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1136\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue with the checkpoint, or because your version of Transformers is out of date.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can update Transformers with the command `pip install --upgrade transformers`. If this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1138\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not work, and the checkpoint is very new, then there may not be a release version \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1139\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat supports this model yet. In this case, you can get the most up-to-date code by installing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1140\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers from source with the command \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1141\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install git+https://github.com/huggingface/transformers.git`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1142\u001b[0m         )\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config_class\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwargs)\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m# Fallback: use pattern matching on the string.\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;66;03m# We go from longer names to shorter names to catch roberta before bert (for instance)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\configuration_utils.py:631\u001b[0m, in \u001b[0;36mget_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    625\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    626\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    627\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    628\u001b[0m     )\n\u001b[0;32m    630\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_auto_class\u001b[39m\u001b[38;5;124m\"\u001b[39m: from_auto_class}\n\u001b[1;32m--> 631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_pipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     user_agent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m from_pipeline\n\u001b[0;32m    634\u001b[0m pretrained_model_name_or_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(pretrained_model_name_or_path)\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\configuration_utils.py:686\u001b[0m, in \u001b[0;36m_get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m         \u001b[38;5;66;03m# Load config dict\u001b[39;00m\n\u001b[0;32m    684\u001b[0m         config_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_dict_from_json_file(resolved_config_file)\n\u001b[1;32m--> 686\u001b[0m     config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m commit_hash\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (json\u001b[38;5;241m.\u001b[39mJSONDecodeError, \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m):\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt looks like the config file at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_config_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a valid JSON file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:416\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inside \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Either all the files were found, or some were _CACHED_NO_EXIST but we do not raise for missing entries\u001b[39;00m\n\u001b[1;32m--> 416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_counter \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(full_filenames):\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m existing_files \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(existing_files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    419\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n",
      "\u001b[1;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1.\n401 Client Error. (Request ID: Root=1-6824cb2c-71c6583710d6c0a9237dd1a4;0157bd78-bb45-49bb-b097-0c78997e0478)\n\nCannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/resolve/main/config.json.\nAccess to model mistralai/Mistral-7B-Instruct-v0.1 is restricted. You must have access to it and be authenticated to access it. Please log in."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Load Mistral model\n",
    "mistral_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(mistral_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    mistral_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load your clustered data\n",
    "df = pd.read_csv(\"clustered_papers.csv\")  # replace with your actual file\n",
    "\n",
    "# Assume you have a function or mapping that returns keywords for each cluster\n",
    "cluster_keywords = {\n",
    "    0: [\"crowdsourced data\", \"urban mobility\", \"transportation modeling\"],\n",
    "    1: [\"machine learning\", \"citation analysis\", \"bibliometric networks\"],\n",
    "    # Add all your cluster -> keyword mappings\n",
    "}\n",
    "\n",
    "# Generate and print summary for each cluster\n",
    "for cluster_id in sorted(df['cluster_id'].unique()):\n",
    "    cluster_df = df[df['cluster_id'] == cluster_id]\n",
    "    abstracts = cluster_df['abstract'].dropna().tolist()\n",
    "    if not abstracts:\n",
    "        continue\n",
    "\n",
    "    combined_text = \" \".join(abstracts)[:2000]  # Truncate if too long\n",
    "    keywords = cluster_keywords.get(cluster_id, [\"science\", \"research\"])\n",
    "\n",
    "    # Build instruct prompt\n",
    "    prompt = f\"<s>[INST] Generate a bibliometric summary using the topics: {', '.join(keywords)}. Text:\\n{combined_text}\\n[/INST]\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=300)\n",
    "\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"\\n📘 Cluster {cluster_id} Summary\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(summary)\n",
    "    print(\"--------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae0a5cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Embedding: [-3.03823858e-01 -2.94588953e-01 -3.76790494e-01  5.01689222e-03\n",
      " -3.54408994e-02  1.06439918e-01 -3.23471457e-01  2.17532516e-01\n",
      "  2.92097963e-03 -7.44312882e-01 -4.35850620e-01 -3.50625992e-01\n",
      "  2.00050063e-02 -2.46841222e-01 -1.59674272e-01  5.49915060e-02\n",
      " -2.40113243e-01  6.04893386e-01  4.65398401e-01  5.87469265e-02\n",
      " -3.19653422e-01 -7.89481580e-01  1.41855806e-01  2.59826928e-01\n",
      " -1.24172002e-01 -3.95769417e-01 -7.99091160e-02  4.51406538e-01\n",
      " -7.91762024e-02  1.85417414e-01 -4.29062903e-01  3.09045583e-01\n",
      " -5.20451665e-01 -8.73078465e-01  7.41924167e-01 -7.56629258e-02\n",
      " -5.66660017e-02 -4.74565268e-01 -5.19070625e-01  4.38661039e-01\n",
      " -3.53880256e-01  3.36756796e-01  4.73318577e-01 -3.30739498e-01\n",
      " -2.30438918e-01  6.87498897e-02 -2.97834635e+00 -2.10847571e-01\n",
      " -8.75047624e-01 -1.28071606e-01  3.81216854e-01  4.08959866e-01\n",
      "  3.36281300e-01  1.29074126e-01  6.62514269e-01  7.79323637e-01\n",
      "  2.08158702e-01 -5.16489595e-02  3.43803972e-01  1.69889957e-01\n",
      "  5.51769316e-01  4.24994111e-01 -2.14304030e-01 -5.35979211e-01\n",
      "  1.90755606e-01 -6.43610209e-02  5.47206998e-02  4.96894479e-01\n",
      " -1.86606094e-01  3.67489755e-02 -5.50784171e-01  1.43669158e-01\n",
      "  5.18800020e-01 -8.66626352e-02 -2.19657600e-01 -3.38900946e-02\n",
      "  1.65021107e-01  4.66869235e-01 -8.07627559e-01 -1.64124861e-01\n",
      " -4.41753775e-01  8.41248453e-01  1.09165795e-01  1.17643267e-01\n",
      "  5.80080807e-01  7.92051256e-01 -9.70901430e-01 -4.78672832e-01\n",
      " -1.40501127e-01  4.45860445e-01 -2.10405946e-01 -3.04221839e-01\n",
      "  3.54654014e-01  1.11477005e+00  7.84012079e-01  3.58697236e-01\n",
      " -1.30415529e-01 -2.64885068e-01 -2.08544940e-01  6.15005851e-01\n",
      "  5.91294467e-01 -2.97800004e-01  2.65872836e-01 -3.22568297e-01\n",
      "  4.06827807e-01 -1.51383504e-02 -5.54092228e-01 -4.92251009e-01\n",
      " -1.23656601e-01 -2.69746614e+00  5.47028840e-01 -1.67653672e-02\n",
      " -2.85866261e-01 -1.77994788e-01  1.48758769e-01  4.89803404e-01\n",
      "  7.20278740e-01  2.15709254e-01 -4.52702269e-02 -6.47674873e-02\n",
      "  1.18794814e-01  1.44697383e-01 -1.32495329e-01  5.85410953e-01\n",
      " -3.43137234e-01  2.75409102e-01  2.25036308e-01  1.50559187e-01\n",
      "  3.22888345e-01  2.57087618e-01  3.78596783e-01  6.61356747e-01\n",
      " -1.34976059e-01 -5.85843503e-01 -3.71585906e-01  2.45749384e-01\n",
      "  4.72799122e-01 -6.50312379e-02  1.03827089e-01 -2.42710449e-02\n",
      " -1.61127567e-01 -7.94591725e-01 -2.10137796e+00 -5.65133512e-01\n",
      "  9.99554455e-01  1.97853357e-01  2.83387154e-01 -1.78595394e-01\n",
      "  1.94912940e-01  1.02922007e-01  2.71759927e-01  6.88619688e-02\n",
      " -7.25524187e-01 -3.99493039e-01 -4.28509004e-02  1.11385517e-01\n",
      " -8.41510236e-01  5.08089811e-02  6.40503943e-01  3.04388493e-01\n",
      " -6.12770170e-02 -1.59682423e-01 -4.55193728e-01 -9.55761075e-02\n",
      " -4.41343069e-01  1.41912133e-01  5.37566960e-01  4.37040254e-02\n",
      "  2.81829208e-01  1.31740540e-01 -2.05661908e-01  2.07400724e-01\n",
      "  6.62233114e-01  2.85458058e-01  4.90685165e-01  1.84566736e-01\n",
      "  4.49979722e-01  1.80129901e-01  3.74054313e-01  4.95090872e-01\n",
      " -2.44576976e-01  6.07260168e-01  9.72533897e-02 -9.37253982e-02\n",
      "  4.00745600e-01 -4.28710580e-01 -1.26358718e-01 -4.71248806e-01\n",
      " -5.64967275e-01  5.60319573e-02 -7.20048249e-02 -1.23202875e-02\n",
      " -2.10176483e-02  9.74207371e-02  1.10258490e-01 -4.30400342e-01\n",
      "  9.30555701e-01 -1.01523809e-01  2.85602123e-01 -4.15301621e-02\n",
      "  7.48717785e-02 -1.72861680e-01 -1.09371006e-01  4.48875040e-01\n",
      " -4.10333753e-01  3.37432790e+00 -2.87095606e-01 -4.76357937e-01\n",
      " -4.42594528e-01 -1.17385298e-01 -4.25485581e-01 -2.73876131e-01\n",
      "  3.14201355e-01 -6.57704413e-01  2.26520717e-01 -4.71419692e-01\n",
      "  3.71921003e-01  5.24181187e-01 -4.40325737e-01 -2.06464320e-01\n",
      "  6.30145431e-01  6.35774493e-01 -6.52629197e-01  5.44244170e-01\n",
      " -2.82690018e-01  2.39978552e-01 -5.97796142e-02  8.54915619e-01\n",
      "  6.00129604e-01 -1.09372818e+00 -9.90878940e-02 -4.58210222e-02\n",
      " -3.11456978e-01  2.77797788e-01 -7.13510215e-01 -4.21125144e-01\n",
      " -8.74434114e-01 -3.36560160e-01  2.15873480e-01 -2.42640406e-01\n",
      " -4.69421923e-01  1.97370306e-01  1.51250750e-01  1.42509937e-01\n",
      "  3.78442913e-01  1.08452030e-02  5.81535041e-01  4.40722227e-01\n",
      "  1.27532721e-01 -8.95353556e-02  7.39166498e-01 -3.70861232e-01\n",
      "  1.89236686e-01 -4.68166918e-01 -2.60707974e-01 -5.73436856e-01\n",
      "  6.51094913e-02  2.68359780e-01 -1.82223946e-01  9.69101936e-02\n",
      "  1.71345383e-01 -1.45429730e-01  3.33489805e-01 -4.26005721e-01\n",
      " -7.76545465e-01 -7.37197459e-01  1.44036040e-01 -4.78814095e-01\n",
      "  1.76023588e-01 -1.49703681e-01  3.54002655e-01 -5.69597147e-02\n",
      "  1.60185277e-01 -3.06181550e+00 -1.53075606e-01 -5.72886348e-01\n",
      "  3.72718900e-01  2.65904754e-01 -7.43334472e-01 -3.34909648e-01\n",
      "  5.35075307e-01  4.95426089e-01 -6.81253314e-01  5.32151222e-01\n",
      "  1.91439055e-02  7.03206241e-01  1.86690971e-01 -3.41856211e-01\n",
      "  1.39765084e-01  1.60684347e-01 -1.73364252e-01  1.68120354e-01\n",
      " -1.63153559e-01  1.38858601e-01  7.40036368e-02  2.27854222e-01\n",
      " -4.17960808e-03  3.71486396e-01 -4.31283355e-01 -3.82834226e-01\n",
      " -3.82469833e-01 -9.37596560e-01  2.14142278e-01  3.81438613e-01\n",
      " -1.36773497e-01  1.67250991e-01  9.40938741e-02 -1.58943430e-01\n",
      " -2.27256823e+00  8.74977410e-02  6.83586299e-02 -2.62213707e-01\n",
      " -2.07681179e-01  1.79981917e-01  6.50544941e-01 -4.82416958e-01\n",
      " -8.67757499e-01 -3.85069132e-01 -8.24159384e-02  1.86037987e-01\n",
      "  2.50081360e-01 -2.50337124e-02  4.05665159e-01  5.58602035e-01\n",
      "  3.51490289e-01 -1.08947076e-01  4.96256709e-01  4.05098870e-03\n",
      "  1.17049038e-01 -4.46413666e-01 -5.37404597e-01  3.13501775e-01\n",
      " -5.66248670e-02  5.21882594e-01 -9.82223213e-01  7.10331425e-02\n",
      " -3.75795454e-01 -4.09534037e-01  4.66200769e-01 -6.72969222e-01\n",
      " -2.77400702e-01  2.38609567e-01 -7.29408264e-02  1.57251060e-01\n",
      "  1.44245982e-01  4.86383438e-01  8.53721559e-01  9.28595066e-02\n",
      "  1.44029930e-01  1.26498985e+00 -2.79999554e-01  1.84412450e-01\n",
      "  8.95227253e-01  9.07380879e-02  9.75967586e-01  2.24406958e-01\n",
      " -1.51531339e-01  3.39259207e-01  2.18420342e-01  2.55489945e-01\n",
      "  1.38760459e+00 -1.12043172e-01 -4.88151424e-02 -3.77121210e-01\n",
      "  4.90213275e-01  2.32067689e-01 -2.33816460e-01  3.89621079e-01\n",
      "  1.06561100e+00 -5.45746148e-01  2.14555860e-01 -2.25018382e-01\n",
      "  9.91273671e-03 -1.01733625e+00 -2.12945834e-01 -5.80432117e-01\n",
      "  1.14616603e-01  3.52275312e-01  1.74265936e-01  1.00929439e+00\n",
      " -2.64209270e-01 -1.08852112e+00 -2.11574450e-01 -3.33137751e-01\n",
      " -1.17299333e-03 -1.76978469e-01  6.71120286e-02 -4.46681261e-01\n",
      " -4.02579993e-01 -1.10299431e-01 -7.47526884e-01  1.28722847e-01\n",
      " -6.41264796e-01 -2.27028072e-01  1.07649677e-01 -1.36430532e-01\n",
      " -1.42240429e+00 -4.63469446e-01 -1.86222434e-01  3.05613786e-01\n",
      "  2.84615278e-01  2.09360570e-01  1.66598447e-02 -1.18049547e-01\n",
      "  4.79218185e-01 -5.94101846e-01  2.67336249e-01  7.77873099e-02\n",
      " -4.12358820e-01 -5.60837567e-01 -7.07649708e-01  3.53718102e-01\n",
      "  1.73673928e-01  3.19273062e-02 -2.15477735e-01 -1.93510488e-01\n",
      "  2.93597519e-01  5.13518751e-02 -1.38250962e-01  1.22219570e-01\n",
      "  1.66278824e-01 -1.91558555e-01  5.62437892e-01  3.82898808e-01\n",
      " -2.28021555e-02  9.63744640e-01  8.39688420e-01  5.86799324e-01\n",
      "  5.17765820e-01  7.15042472e-01  5.18150628e-01 -4.56401818e-02\n",
      "  4.41424847e-01  3.31310928e-02 -1.52724907e-01 -3.37495178e-01\n",
      " -5.01755297e-01 -5.08557558e-01  3.33946794e-01 -7.20271528e-01\n",
      " -3.24351043e-01 -3.90101671e-01 -3.14785615e-02 -8.30262661e-01\n",
      " -2.79336691e-01  5.52389503e-01 -2.19960034e-01  6.25406802e-01\n",
      "  5.38597107e-01 -4.56903249e-01 -3.21185365e-02  1.59916401e-01\n",
      "  2.54068673e-01  7.68879831e-01 -1.01516485e-01  6.22536987e-03\n",
      " -2.71685809e-01  8.47205520e-01 -2.91768074e-01 -2.32147962e-01\n",
      " -7.91487277e-01 -2.97860414e-01  3.73831689e-01  9.03848037e-02\n",
      " -3.77684027e-01 -2.99598217e-01 -1.10735960e-01 -2.96604633e-01\n",
      "  2.86643356e-01  2.93127000e-01 -2.13755465e+00  1.72231644e-01\n",
      "  5.80931962e-01  6.72860026e-01  3.25232685e-01 -3.36615294e-02\n",
      " -5.17170787e-01  6.92778409e-01  4.24069129e-02 -1.25111952e-01\n",
      " -1.41847819e-01 -9.97623861e-01 -2.48993754e-01  1.05955768e-02\n",
      " -7.20817149e-02  8.99536908e-02 -2.56312937e-01 -3.30127180e-01\n",
      "  2.58050542e-02 -1.56628281e-01 -2.72992730e-01  3.80017787e-01\n",
      "  1.90809652e-01 -6.39048517e-02  5.49922138e-03 -6.79573178e-01\n",
      "  3.54787916e-01  4.71579760e-01  1.73889071e-01  1.40344739e-01\n",
      " -1.40151963e-01 -3.82846445e-01 -6.93244576e-01 -9.62501615e-02\n",
      "  5.48109055e-01  1.79084480e-01  2.74240017e-01 -3.88765752e-01\n",
      "  6.95122838e-01 -2.81543583e-02 -4.93431091e-01  7.08428562e-01\n",
      " -9.22967196e-02  1.95841670e-01  2.23768845e-01 -1.41412497e-01\n",
      " -3.38614881e-01 -1.63368180e-01 -4.15521324e-01 -1.52449340e-01\n",
      " -3.67466539e-01  3.45857702e-02  3.77637185e-02 -6.30373731e-02\n",
      "  1.53604642e-01 -4.50040996e-02 -1.92984223e-01  2.23364532e-01\n",
      " -5.29767215e-01  2.00826257e-01  3.97735357e-01 -3.19702953e-01\n",
      " -4.84797508e-02  1.15604013e-01 -3.43546420e-01 -1.02862966e+00\n",
      " -3.31704050e-01 -6.10948205e-01 -7.40960777e-01 -3.00927728e-01\n",
      "  6.50627315e-01  8.65414888e-02 -4.83936876e-01  6.73789144e-01\n",
      " -5.71556926e-01  3.92382368e-02  5.23419201e-01 -1.18905552e-01\n",
      "  5.41147470e-01 -2.56521910e-01 -1.36582881e-01 -4.95750368e-01\n",
      " -3.91434759e-01  6.52786553e-01 -2.83701926e-01 -1.31263316e-01\n",
      " -3.97048533e-01 -3.18676531e-01  9.12800059e-02 -2.30428457e-01\n",
      " -7.33456910e-01 -3.79245013e-01  2.45084420e-01  1.03215203e-01\n",
      " -2.03761622e-01 -6.88308537e-01  1.63904279e-01 -4.04506177e-01\n",
      " -8.35094154e-02 -2.79382616e-01  5.37252389e-02  5.96332550e-01\n",
      "  4.65979367e-01  3.86881888e-01  3.48968863e-01 -6.10448793e-02\n",
      "  5.73337018e-01 -9.94527340e-03  1.97490454e-01 -5.92190087e-01\n",
      " -2.42805377e-01 -3.69883567e-01 -2.13024855e-01  2.47948125e-01\n",
      "  6.82375789e-01 -9.12577391e-01  3.97825867e-01 -3.95976931e-01\n",
      "  1.60022473e+00  4.84747827e-01  4.28680152e-01 -3.50376487e-01\n",
      "  7.78658450e-01  9.69223157e-02 -4.49009359e-01  8.62805545e-01\n",
      " -6.82071626e-01 -5.01335375e-02 -2.53381848e-01  3.27517778e-01\n",
      " -4.40697312e-01  5.13285518e-01  4.98526692e-01  9.87671494e-01\n",
      " -3.59471083e-01 -5.72911382e-01 -3.43150198e-01  1.68191940e-01\n",
      " -7.14259505e-01  1.12951815e+00  5.40782988e-01  8.75323117e-02\n",
      "  1.77787513e-01  6.41454935e-01 -3.85245025e-01  4.81645465e-01\n",
      "  5.02464771e-01  3.48949730e-02 -4.80260670e-01  2.29665935e-01\n",
      "  6.58189356e-02  1.00322294e+00 -3.03836644e-01  1.12223059e-01\n",
      " -2.97916025e-01 -3.99048865e-01  6.91226363e-01  1.76347539e-01\n",
      " -1.89142719e-01 -4.04415131e-01  5.17377853e-01 -1.55545384e-01\n",
      "  1.04448453e-01  5.28798223e-01 -3.42488855e-01 -6.55166626e-01\n",
      "  4.68079656e-01  6.13815010e-01 -4.29856740e-02  3.29212487e-01\n",
      " -3.51444870e-01  5.70579708e-01 -9.71956924e-02  1.82344645e-01\n",
      " -3.37710157e-02  1.21567518e-01 -1.69176549e-01  8.69155228e-02\n",
      "  1.72598064e-01  5.76301455e-01  2.73743808e-01 -6.75247982e-03\n",
      " -1.78825364e-01  1.50688201e-01 -3.86660546e-01  4.37192023e-01\n",
      "  1.97378904e-01 -3.23726207e-01  3.10098886e-01  1.97389320e-01\n",
      "  4.56643790e-01  3.94443721e-01  4.93506610e-01  1.33734584e-01\n",
      "  5.39645672e-01  5.66998184e-01 -1.09497458e-01 -2.22327590e+00\n",
      "  1.71253443e-01  5.31610847e-01  4.14107919e-01 -5.05743265e-01\n",
      " -2.27950923e-02  3.09769601e-01  2.55310774e-01 -2.49603629e-01\n",
      "  5.20329969e-03 -9.26829427e-02  8.10874224e-01  9.66617048e-01\n",
      " -1.13633126e-01  1.70411661e-01  7.40716994e-01  2.14106500e-01\n",
      " -1.02572048e+00 -2.04366624e-01 -3.48678857e-01  5.46867132e-01\n",
      "  1.73461482e-01 -3.42002243e-01 -4.06353138e-02 -6.69542253e-01\n",
      "  6.34213462e-02  1.39105931e-01 -8.11827064e-01  5.00545144e-01\n",
      "  1.14766550e+00 -2.50892967e-01  2.79290289e-01  9.77494121e-02\n",
      "  8.25779021e-01  1.56420261e-01 -4.77133840e-01  1.74098849e-01\n",
      "  1.50189206e-01 -3.00052673e-01  1.51577458e-01 -4.98352557e-01\n",
      "  4.45586532e-01 -7.53745437e-02  7.63495862e-02 -2.85221398e-01\n",
      "  7.40827769e-02  4.42952424e-01 -3.00074041e-01  6.32266283e-01\n",
      " -3.60712737e-01 -2.04998404e-01 -1.46959364e-01  5.83032481e-02\n",
      " -1.38016552e-01  6.28215730e-01 -8.39272738e-02  7.44105995e-01\n",
      " -1.23712048e-03  5.05161762e-01 -3.92003208e-01 -1.15079045e-01\n",
      "  5.90554357e-01 -3.02465022e-01  4.90493178e-01  1.37736261e-01\n",
      " -3.94927770e-01 -5.11058807e-01 -3.48522961e-01  2.24246264e-01\n",
      "  2.00705603e-01 -9.79637355e-03 -2.42050290e-01  3.36554170e-01\n",
      " -2.56607383e-02  4.89471048e-01  2.60042906e-01  2.92030573e-02\n",
      " -3.23106974e-01  6.08169496e-01  1.44946828e-01  1.18433356e-01\n",
      " -3.92132401e-01 -6.56875789e-01  1.19904369e-01  3.13865155e-01\n",
      " -6.76669455e+00 -1.54439926e-01 -6.14286065e-01 -3.30135822e-01\n",
      " -8.49660933e-02 -4.70077127e-01  7.47107863e-02  1.54274181e-02\n",
      " -1.97616071e-01 -2.90094823e-01 -1.81808963e-01 -2.76574850e-01\n",
      " -4.75893825e-01 -5.28998673e-01 -8.01036730e-02  1.27828076e-01]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Example input text (replace with your actual article or text)\n",
    "input_text = \"Research trends in urban mobility using crowd-sourced data.\"\n",
    "\n",
    "# Tokenize input text and convert it to input IDs\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Get the model's output (embeddings)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state  # Embeddings of the input text\n",
    "\n",
    "# Optional: If you want a single vector representation (e.g., using the [CLS] token)\n",
    "sentence_embedding = embeddings[:, 0, :].squeeze().numpy()  # [CLS] token representation\n",
    "print(\"Sentence Embedding:\", sentence_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78b1cd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with Grok API: 401\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Grok API URL (replace with your actual endpoint)\n",
    "grok_api_url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "# Prepare the payload with BERT embeddings\n",
    "data = {\n",
    "    \"text_embedding\": sentence_embedding.tolist(),  # Convert numpy array to list for JSON compatibility\n",
    "    \"additional_info\": \"Research trends in urban mobility\"  # Optional additional info\n",
    "}\n",
    "\n",
    "# Send the POST request to Grok API\n",
    "response = requests.post(grok_api_url, json=data)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"Grok API Response:\", result)\n",
    "else:\n",
    "    print(\"Error with Grok API:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abdcbda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.78.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.4.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.78.1-py3-none-any.whl (680 kB)\n",
      "   ---------------------------------------- 0.0/680.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 680.9/680.9 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.9.0-cp312-cp312-win_amd64.whl (207 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   ---------------------------------------- 3/3 [openai]\n",
      "\n",
      "Successfully installed distro-1.9.0 jiter-0.9.0 openai-1.78.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9efc4881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: torch in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.1+cu118)\n",
      "Requirement already satisfied: transformers in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: keybert in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: openai in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.78.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.31.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: rich>=10.4.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keybert) (13.8.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keybert) (1.5.2)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keybert) (3.1.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.4.0->keybert) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (10.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas torch transformers keybert openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1fc1a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['id', 'title', 'doi', 'publication_year', 'authors', 'abstract', 'open_access', 'host_venue', 'clean_abstract', 'keywords', 'entities', 'gmm_cluster', 'gmm_probs']\n",
      "\n",
      "🔹 Cluster 0 🔹\n",
      "Research Summary: Unpacking the Consequences of Overreliance on AI-Generated Content in the Era of Infodemics\n",
      "\n",
      "**Research Methodology:**\n",
      "\n",
      "This study employed a mixed-methods approach, combining both qualitative and quantitative data collection and analysis methods. The research design consisted of three stages:\n",
      "\n",
      "1. **Content Analysis**: A dataset of 500 AI-generated articles was collected from online platforms, focusing on topics related to health, politics, and education. These articles were analyzed using natural language processing (NLP) techniques to identify patterns of plagiarism, misinformation, and inequity.\n",
      "2. **Survey Research**: A total of 500 participants were recruited through online surveys, comprising of individuals from diverse backgrounds and age groups. The survey aimed to understand users' perceptions and experiences with AI-generated content, including their ability to distinguish between human-written and AI-generated articles.\n",
      "3. **Expert Interviews**: In-depth interviews were conducted with 20 experts from academia, journalism, and AI development, to gather insights into the development and deployment of AI models, as well as the potential consequences of overreliance on AI-generated content.\n",
      "\n",
      "**Key Findings:**\n",
      "\n",
      "1. **Plagiarism and Misinformation**: The content analysis revealed that 60% of the generated articles exhibited plagiarism, with 40% containing misinformation. These findings suggest that the models are not adequately designed to handle unstructured data, leading to the spread of misinformation.\n",
      "2. **Indistinguishability**: The survey results showed that 70% of participants were unable to distinguish between human-written and AI-generated articles, highlighting the need for more user-centered AI design.\n",
      "3. **Inequity and Mishandling**: Expert interviews revealed that AI models are often developed and deployed without considering the potential inequities in data, leading to the exacerbation of existing social biases.\n",
      "4. **Retrace and Unresolved Issues**: The study found that the AI models lack the ability to retrace the sources of information, further complicating the issue of misinformation and plagiarism.\n",
      "5. **Overreliance and Consequences**: The findings suggest that the overreliance on AI-generated content can lead to the erosion of trust in institutions, exacerbate the infodemic, and have significant consequences for individuals and society as a whole.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "This study highlights the urgent need for more rigorous development, deployment, and regulation of AI-generated content. The findings suggest that the overreliance on AI-generated content can have far-reaching consequences, including the exacerbation of misinformation, plagiarism, and social inequities. It is essential to develop more user-centered AI models that can mitigate these risks and promote a more informed and equitable society.\n",
      "\n",
      "🔹 Cluster 1 🔹\n",
      "**Research Summary: Exploring the Frontiers of Language and Vision**\n",
      "\n",
      "**Research Methodology:**\n",
      "\n",
      "This study employed a qualitative, deconstructive approach to investigate the intricacies of language and vision. Specifically, a within-subjects design was utilized, where participants engaged in self-evaluating tasksolving abilities using exemplars of language and vision snippets. The research leveraged cutting-edge tools, such as the Tree of Thought LLM (https://github.com/princeton-nlp/tree-of-thought-llm) and MiniGPT4 (https://minigpt4.github.io), to facilitate the debugging and rethinking of language and vision interactions.\n",
      "\n",
      "**Key Findings:**\n",
      "\n",
      "1. **Unexplored Dimensions of Language and Vision:** The study uncovered previously unexplored dimensions of language and vision, highlighting the importance of token-level analysis in understanding the complex relationships between language and vision.\n",
      "2. **Adversarial Effects on Language and Vision:** The research revealed that adversarial attacks on language and vision models can have significant implications for tasksolving abilities, emphasizing the need for robust debugging and rethinking of language and vision interactions.\n",
      "4. **Cowriting and Hand-Drawn Approaches:** The study demonstrated the effectiveness of cowriting and hand-drawn approaches in facilitating deeper understanding and tasksolving abilities in language and vision domains.\n",
      "5. **Log-Linear Relationships:** The research identified log-linear relationships between language and vision snippets, highlighting the importance of considering the nuances of language and vision interactions in tasksolving.**\n",
      "\n",
      "**Implications and Future Directions:**\n",
      "\n",
      "The study's findings have significant implications for the development of more effective language and vision models, emphasizing the need for continued research in this area. Future directions include exploring the applications of MiniGPT4 and other cutting-edge tools in language and vision research, as well as further investigating the log-linear relationships to improve tasksolving abilities.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "This study contributes to our understanding of the complex relationships between language and vision, it also highlights the need for continued research in this area. The findings have significant implications for the development of more effective language and vision models, and the study's methodology provides a framework for future research in this area.\n",
      "\n",
      "🔹 Cluster 2 🔹\n",
      "**Research Summary:**\n",
      "\n",
      "**Title:** \"Vision-to-Language: A Comprehensive Study of Domain-Specific Transformer-Based Models\"\n",
      "\n",
      "**Research Objective:**\n",
      "The study aims to investigate the effectiveness of transformer-based models for vision-to-language tasks, focusing on domain-specific models and their performance on various benchmark datasets.\n",
      "\n",
      "**Methodology:**\n",
      "\n",
      "1. **Model Selection:** The study utilizes three state-of-the-art transformer-based models, namely, OPT-175B, Flamingo-80B, and GPT-NeoX-20B.\n",
      "2. **Domain-Specific Training:** Each model is fine-tuned on specific domains, including VQA-2, BLIP-2, and Image-to-Text datasets.\n",
      "3. **Rank Deficiency:** The study explores the effect of rank deficiency on model performance, using LORA (github.com/microsoft/LORA) and CodeLMS (github.com/vhellendoorn/CodeLMS) techniques.\n",
      "4. **Compute-Optimal Training:** The models are trained using compute-optimal techniques to reduce computational resources.\n",
      "6. **Evaluation Metrics:** The study uses standard evaluation metrics, including n-grams, BLEU, METEOR, and CIDEr, to assess model performance.\n",
      "\n",
      "**Key Findings:**\n",
      "\n",
      "1. **Domain-Specific Performance:** The study shows that transformer-based models outperform generic models on domain-specific tasks, highlighting the importance of domain-specific training.\n",
      "2. **Rank Deficiency:** The results indicate that rank deficiency techniques, such as LORA and CodeLMS, can significantly reduce computational resources without compromising performance.\n",
      "3. **Compute-Optimal Training:** The study demonstrates that compute-optimal training techniques can reduce training time and resources while maintaining model performance.\n",
      "4. **Extrapolating to New Domains:** The results suggest that transformer-based models can extrapolate to new domains, achieving competitive performance without additional training data.\n",
      "5. **Multilingual Performance:** The study finds that transformer-based models can handle multilingual inputs, achieving comparable performance across languages.\n",
      "\n",
      "**Conclusion:**\n",
      "The study provides a comprehensive analysis of domain-specific transformer-based models, highlighting their effectiveness in various vision-to-language tasks. The findings have significant implications for the development of efficient and accurate models for real-world applications.\n",
      "\n",
      "**Limitations:**\n",
      "The study is limited to transformer-based models and specific domain datasets. Further research is needed to explore other model architectures and domains to generalize the findings.\n",
      "\n",
      "🔹 Cluster 3 🔹\n",
      "**Research Summary: Investigating the Efficacy of Advanced Language Models in Healthcare and Information Retrieval**\n",
      "\n",
      "**Methodology:**\n",
      "\n",
      "This study employed a mixed-methods approach, combining both qualitative and quantitative methods to investigate the performance of advanced language models in healthcare and information retrieval. The research design involved a multi-task learning framework, where various models were trained on multiple tasks simultaneously. The models were evaluated on several datasets, including but not limited to MedMCQA, HealthSearchQA, and a custom dataset (plt001).\n",
      "\n",
      "**Quantitative Methods:**\n",
      "\n",
      "* **Model architectures:** The study utilized various models, including NBMefreeStep1, NBMefreeStep2, AmbossStep1, AmbossStep2, and InstructGPT.\n",
      "* **Parameter efficiency:** The parameter-efficient models, such as those with 175 billion and 540 billion parameters, were compared to smaller models.\n",
      "* **Evaluation metrics:** The performance of the models was evaluated using accuracy, lost applications, and reinforcing learning metrics.\n",
      "\n",
      "**Qualitative Methods:**\n",
      "\n",
      "* **Exemplars:** A qualitative analysis of exemplars from the output was conducted to assess the quality and relevance of the generated by the models.\n",
      "* **Reshape:** The impact of reshaping the input data on the model's performance was investigated.\n",
      "\n",
      "**Key Findings:**\n",
      "\n",
      "1. **Parameter efficiency:** Larger models with 175 billion and 540 billion parameters outperformed smaller models in terms of accuracy and reinforcing learning metrics.\n",
      "2. **Multitask learning:** The multi-task learning approach improved the performance of the models on individual tasks, particularly in the healthcare domain (MedMCQA and HealthSearchQA datasets).\n",
      "3. **NBMefreeStep1 and NBMefreeStep2:** These models demonstrated superior performance on the plt001 dataset, suggesting their potential in handling complex queries (5687 queries).\n",
      "4. **AmbossStep1 and AmbossStep2:** These models showed improved performance on the HealthSearchQA dataset, indicating their effectiveness in healthcare information retrieval.\n",
      "5. **Lost applications:** The study found that the lost applications metric is a reliable measure of model efficacy in handling out-of-distribution queries.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "This study contributes to the understanding of advanced language models in healthcare and information retrieval. The findings suggest that larger, parameter-efficient models, such as those with 175 billion and 540 billion parameters, can outperform smaller models. The multi-task learning approach and reshaping input data can further improve model performance. The study's results have implications for the development of more accurate and efficient language models in healthcare and information retrieval.\n",
      "\n",
      "🔹 Cluster 4 🔹\n",
      "**Research Summary:**\n",
      "\n",
      "**Title:** A Comprehensive Analysis of Domain-Specific and Task-Specific Approaches in Knowledge-Intensive Natural Language Processing\n",
      "\n",
      "**Research Methodology:**\n",
      "\n",
      "This study employed a mixed-methods approach, combining both quantitative and qualitative methods to scrutinize the current state of domain-specific and task-specific approaches in knowledge-intensive natural language processing (NLP). The research design involved a comprehensive survey of existing literature, benchmarking of state-of-the-art models, and expert interviews.\n",
      "\n",
      "* A systematic review of 100 research articles and conference papers was conducted to identify the current trends, challenges, and opportunities in domain-specific and task-specific approaches in NLP.\n",
      "* A benchmarking study was carried out using the Text-DaVinci-002 dataset to evaluate the performance of six state-of-the-art models, including Instruct-GPT and LLM-Augmented, in various knowledge-intensive NLP tasks, such as multitask learning and embedding.\n",
      "* Expert interviews were conducted with 10 leading researchers in the field to gather insights on the understudied and untraceable aspects of domain-specific and task-specific approaches.\n",
      "\n",
      "**Key Findings:**\n",
      "\n",
      "1. **Domain-specific approaches outperform task-specific approaches**: The benchmarking study revealed that domain-specific models outperformed task-specific models in knowledge-intensive NLP tasks, such as question answering and text classification.\n",
      "2. **Knowledge-intensive tasks require multitask learning**: The study highlighted the importance of multitask learning in knowledge-intensive NLP tasks, as it enables models to leverage shared knowledge across tasks and improve overall performance.\n",
      "4. **LLM-Augmented models demonstrate forward-looking capabilities**: The benchmarking study showed that LLM-Augmented models exhibited forward-looking capabilities, enabling them to generalize well to unseen tasks and datasets.\n",
      "5. **Instruct-GPT models require fine-tuning for optimal performance**: The study found that Instruct-GPT models require fine-tuning on specific tasks and datasets to achieve optimal results.\n",
      "6. **Embedding techniques are invaluable for knowledge-intensive tasks**: The study demonstrated that embedding techniques, such as XML-NS-MML and xlink, are essential for representing complex knowledge structures and relationships in NLP tasks.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "This study provides a comprehensive analysis of domain-specific and task-specific approaches in knowledge-intensive NLP. The findings highlight the need for a more nuanced understanding of the strengths and limitations of each approach. The results have important implications for the development of more effective and efficient NLP models that can tackle complex, knowledge-intensive tasks.**\n",
      "\n",
      "**Limitations:**\n",
      "\n",
      "* The study was limited to a specific set of NLP tasks and datasets.\n",
      "* The expert interviews were limited to 10 researchers, which may not be representative of the broader NLP research community.\n",
      "\n",
      "**Future Research Directions:**\n",
      "\n",
      "* Exploring the application of domain-specific and task-specific approaches to other NLP domains, such as computer vision and speech recognition.\n",
      "* Investigating the use of multitask learning and transfer learning in knowledge-intensive NLP tasks.\n",
      "* Developing more advanced embedding techniques to represent complex knowledge structures and relationships.\n",
      "\n",
      "**Resources:**\n",
      "\n",
      "* Survey repository: https://github.com/mlgroup/jlull-meval-survey\n",
      "* Benchmarking dataset: Text-DaVinci-002002\n",
      "\n",
      "✅ All summaries saved to 'cluster_summaries.json'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from keybert import KeyBERT\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# === Config ===\n",
    "CSV_FILE = \"clustered_papers.csv\"  # ← Update this to your clustered file\n",
    "TEXT_COLUMN = \"clean_abstract\"  # Changed to \"clean_abstract\" based on your columns\n",
    "CLUSTER_COLUMN = \"gmm_cluster\"  # Updated to \"gmm_cluster\" since that's the correct column\n",
    "GROQ_API_KEY = \"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\"  # ← Replace this\n",
    "\n",
    "# === Groq Setup ===\n",
    "openai.api_key = GROQ_API_KEY\n",
    "openai.api_base = \"https://api.groq.com/openai/v1\"\n",
    "\n",
    "# === Load Models ===\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model.eval()\n",
    "kw_model = KeyBERT(model='bert-base-uncased')\n",
    "\n",
    "# === Step 1: Load and Group Clusters ===\n",
    "def load_clusters(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Column names:\", df.columns.tolist())  # Show column names explicitly\n",
    "    df.columns = df.columns.str.strip()  # Clean any extra spaces in column names\n",
    "    if CLUSTER_COLUMN not in df.columns:\n",
    "        raise KeyError(f\"Column '{CLUSTER_COLUMN}' not found in the CSV file.\")\n",
    "    return df.groupby(CLUSTER_COLUMN)[TEXT_COLUMN].apply(list).to_dict()\n",
    "\n",
    "# === Step 2: Extract Keywords from BERT Input ===\n",
    "def embedding_to_keywords(texts, num_keywords=10):\n",
    "    combined_text = \" \".join(texts)\n",
    "# Adjust the number of keywords\n",
    "    keywords = kw_model.extract_keywords(combined_text, top_n=20)\n",
    "    return [kw[0] for kw in keywords]\n",
    "\n",
    "# === Step 3: Build Prompt for Groq ===\n",
    "def build_prompt(keywords):\n",
    "    return (\n",
    "        \"You are a research assistant. Generate a detailed research summary \"\n",
    "        \"focusing on the research methodology and key findings based on the following concepts:\\n\\n\"\n",
    "        + \", \".join(keywords) + \"\\n\\nSummary:\"\n",
    "    )\n",
    "\n",
    "\n",
    "# === Step 4: Groq API Call ===\n",
    "def query_groq(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=800\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# === Full Pipeline for One Cluster ===\n",
    "def process_cluster(texts):\n",
    "    try:\n",
    "        keywords = embedding_to_keywords(texts)\n",
    "        prompt = build_prompt(keywords)\n",
    "        return query_groq(prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing cluster: {e}\")\n",
    "        return \"ERROR\"\n",
    "\n",
    "\n",
    "# === Run for All Clusters ===\n",
    "def run_pipeline():\n",
    "    try:\n",
    "        clusters = load_clusters(CSV_FILE)\n",
    "        all_summaries = {}\n",
    "\n",
    "        for label, texts in clusters.items():\n",
    "            print(f\"\\n🔹 Cluster {label} 🔹\")\n",
    "            try:\n",
    "                summary = process_cluster(texts)\n",
    "                all_summaries[label] = summary\n",
    "                print(summary)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error processing cluster {label}: {e}\")\n",
    "                all_summaries[label] = \"ERROR\"\n",
    "\n",
    "        # Optional: Save output\n",
    "        with open(\"cluster_summaries.json\", \"w\") as f:\n",
    "            json.dump(all_summaries, f, indent=4)\n",
    "        print(\"\\n✅ All summaries saved to 'cluster_summaries.json'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error loading clusters: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12d6940d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=0.5555555555555556, recall=0.45454545454545453, fmeasure=0.5), 'rouge2': Score(precision=0.125, recall=0.1, fmeasure=0.11111111111111112), 'rougeL': Score(precision=0.4444444444444444, recall=0.36363636363636365, fmeasure=0.39999999999999997)}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Example generated summary and ground truth summary\n",
    "generated_summary = \"AI models like GatorTron face challenges in plagiarism detection...\"\n",
    "ground_truth_summary = \"The GatorTron model faces plagiarism risks and challenges in content detection...\"\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"])\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = scorer.score(ground_truth_summary, generated_summary)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a1f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scispacy in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.5.5)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scispacy) (3.7.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scispacy) (1.14.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scispacy) (2.32.3)\n",
      "Requirement already satisfied: conllu in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scispacy) (6.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scispacy) (1.26.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scispacy) (1.4.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scispacy) (1.5.2)\n",
      "Requirement already satisfied: pysbd in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scispacy) (0.3.4)\n",
      "Requirement already satisfied: nmslib-metabrainz==2.1.3 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scispacy) (2.1.3)\n",
      "Requirement already satisfied: pybind11>=2.2.3 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nmslib-metabrainz==2.1.3->scispacy) (2.13.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nmslib-metabrainz==2.1.3->scispacy) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.0.0->scispacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.0.0->scispacy) (2024.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.15.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (4.66.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->scispacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (4.12.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->scispacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->scispacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->scispacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (1.16.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->scispacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (0.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.20.3->scispacy) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kathi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->scispacy) (2.1.5)\n",
      "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_sm-0.5.0.tar.gz\n",
      "  Downloading https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_sm-0.5.0.tar.gz (15.9 MB)\n",
      "     ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/15.9 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.5/15.9 MB 1.1 MB/s eta 0:00:14\n",
      "     - -------------------------------------- 0.8/15.9 MB 1.1 MB/s eta 0:00:14\n",
      "     - -------------------------------------- 0.8/15.9 MB 1.1 MB/s eta 0:00:14\n",
      "     -- ------------------------------------- 1.0/15.9 MB 1.1 MB/s eta 0:00:14\n",
      "     --- ------------------------------------ 1.3/15.9 MB 1.1 MB/s eta 0:00:14\n",
      "     --- ------------------------------------ 1.6/15.9 MB 1.1 MB/s eta 0:00:14\n",
      "     ---- ----------------------------------- 1.8/15.9 MB 1.1 MB/s eta 0:00:14\n",
      "     ----- ---------------------------------- 2.1/15.9 MB 1.1 MB/s eta 0:00:13\n",
      "     ----- ---------------------------------- 2.1/15.9 MB 1.1 MB/s eta 0:00:13\n",
      "     ----- ---------------------------------- 2.4/15.9 MB 1.1 MB/s eta 0:00:13\n",
      "     ------ --------------------------------- 2.6/15.9 MB 1.1 MB/s eta 0:00:13\n",
      "     ------- -------------------------------- 2.9/15.9 MB 1.1 MB/s eta 0:00:13\n",
      "     ------- -------------------------------- 3.1/15.9 MB 1.1 MB/s eta 0:00:12\n",
      "     -------- ------------------------------- 3.4/15.9 MB 1.1 MB/s eta 0:00:12\n",
      "     -------- ------------------------------- 3.4/15.9 MB 1.1 MB/s eta 0:00:12\n",
      "     --------- ------------------------------ 3.7/15.9 MB 1.1 MB/s eta 0:00:12\n",
      "     --------- ------------------------------ 3.9/15.9 MB 1.1 MB/s eta 0:00:12\n",
      "     ---------- ----------------------------- 4.2/15.9 MB 1.1 MB/s eta 0:00:11\n",
      "     ----------- ---------------------------- 4.5/15.9 MB 1.1 MB/s eta 0:00:11\n",
      "     ----------- ---------------------------- 4.7/15.9 MB 1.1 MB/s eta 0:00:11\n",
      "     ------------ --------------------------- 5.0/15.9 MB 1.1 MB/s eta 0:00:11\n",
      "     ------------ --------------------------- 5.0/15.9 MB 1.1 MB/s eta 0:00:11\n",
      "     ------------- -------------------------- 5.2/15.9 MB 1.1 MB/s eta 0:00:11\n",
      "     ------------- -------------------------- 5.5/15.9 MB 1.1 MB/s eta 0:00:10\n",
      "     -------------- ------------------------- 5.8/15.9 MB 1.1 MB/s eta 0:00:10\n",
      "     --------------- ------------------------ 6.0/15.9 MB 1.1 MB/s eta 0:00:10\n",
      "     --------------- ------------------------ 6.3/15.9 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------- ----------------------- 6.6/15.9 MB 1.1 MB/s eta 0:00:09\n",
      "     ---------------- ----------------------- 6.6/15.9 MB 1.1 MB/s eta 0:00:09\n",
      "     ----------------- ---------------------- 6.8/15.9 MB 1.1 MB/s eta 0:00:09\n",
      "     ----------------- ---------------------- 7.1/15.9 MB 1.1 MB/s eta 0:00:09\n",
      "     ------------------ --------------------- 7.3/15.9 MB 1.1 MB/s eta 0:00:09\n",
      "     ------------------- -------------------- 7.6/15.9 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------- -------------------- 7.9/15.9 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------- -------------------- 7.9/15.9 MB 1.1 MB/s eta 0:00:08\n",
      "     -------------------- ------------------- 8.1/15.9 MB 1.1 MB/s eta 0:00:08\n",
      "     --------------------- ------------------ 8.4/15.9 MB 1.1 MB/s eta 0:00:08\n",
      "     --------------------- ------------------ 8.7/15.9 MB 1.1 MB/s eta 0:00:07\n",
      "     ---------------------- ----------------- 8.9/15.9 MB 1.1 MB/s eta 0:00:07\n",
      "     ----------------------- ---------------- 9.2/15.9 MB 1.1 MB/s eta 0:00:07\n",
      "     ----------------------- ---------------- 9.2/15.9 MB 1.1 MB/s eta 0:00:07\n",
      "     ----------------------- ---------------- 9.4/15.9 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------------------ --------------- 9.7/15.9 MB 1.1 MB/s eta 0:00:06\n",
      "     ------------------------- -------------- 10.0/15.9 MB 1.1 MB/s eta 0:00:06\n",
      "     ------------------------- -------------- 10.2/15.9 MB 1.1 MB/s eta 0:00:06\n",
      "     -------------------------- ------------- 10.5/15.9 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------- ------------ 10.7/15.9 MB 1.1 MB/s eta 0:00:05\n",
      "     --------------------------- ------------ 10.7/15.9 MB 1.1 MB/s eta 0:00:05\n",
      "     --------------------------- ------------ 11.0/15.9 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 11.3/15.9 MB 1.1 MB/s eta 0:00:05\n",
      "     ----------------------------- ---------- 11.5/15.9 MB 1.1 MB/s eta 0:00:05\n",
      "     ----------------------------- ---------- 11.8/15.9 MB 1.1 MB/s eta 0:00:04\n",
      "     ------------------------------ --------- 12.1/15.9 MB 1.1 MB/s eta 0:00:04\n",
      "     ------------------------------- -------- 12.3/15.9 MB 1.1 MB/s eta 0:00:04\n",
      "     ------------------------------- -------- 12.3/15.9 MB 1.1 MB/s eta 0:00:04\n",
      "     ------------------------------- -------- 12.6/15.9 MB 1.1 MB/s eta 0:00:04\n",
      "     -------------------------------- ------- 12.8/15.9 MB 1.1 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 13.1/15.9 MB 1.1 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 13.4/15.9 MB 1.1 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 13.6/15.9 MB 1.1 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 13.6/15.9 MB 1.1 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 13.9/15.9 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 14.2/15.9 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 14.4/15.9 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 14.7/15.9 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 14.9/15.9 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.9 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.9 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.5/15.9 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.7/15.9 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 15.9/15.9 MB 1.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting spacy<3.3.0,>=3.2.3 (from en_core_sci_sm==0.5.0)\n",
      "  Downloading spacy-3.2.6.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.1/1.1 MB 8.7 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × pip subprocess to install build dependencies did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [664 lines of output]\n",
      "      Collecting setuptools\n",
      "        Downloading setuptools-80.7.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "      Collecting cython<3.0,>=0.25\n",
      "        Using cached Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "      Collecting cymem<2.1.0,>=2.0.2\n",
      "        Using cached cymem-2.0.11-cp312-cp312-win_amd64.whl.metadata (8.8 kB)\n",
      "      Collecting preshed<3.1.0,>=3.0.2\n",
      "        Using cached preshed-3.0.9-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "      Collecting murmurhash<1.1.0,>=0.28.0\n",
      "        Using cached murmurhash-1.0.12-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "      Collecting thinc<8.1.0,>=8.0.12\n",
      "        Downloading thinc-8.0.17.tar.gz (189 kB)\n",
      "        Installing build dependencies: started\n",
      "        Installing build dependencies: finished with status 'done'\n",
      "        Getting requirements to build wheel: started\n",
      "        Getting requirements to build wheel: finished with status 'done'\n",
      "        Preparing metadata (pyproject.toml): started\n",
      "        Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "      Collecting blis<0.8.0,>=0.4.0\n",
      "        Using cached blis-0.7.11-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "      Collecting pathy\n",
      "        Downloading pathy-0.11.0-py3-none-any.whl.metadata (16 kB)\n",
      "      Collecting numpy>=1.15.0\n",
      "        Using cached numpy-2.2.5-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "      Collecting wasabi<1.1.0,>=0.8.1 (from thinc<8.1.0,>=8.0.12)\n",
      "        Downloading wasabi-0.10.1-py3-none-any.whl.metadata (28 kB)\n",
      "      Collecting srsly<3.0.0,>=2.4.0 (from thinc<8.1.0,>=8.0.12)\n",
      "        Using cached srsly-2.5.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "      Collecting catalogue<2.1.0,>=2.0.4 (from thinc<8.1.0,>=8.0.12)\n",
      "        Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "      Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 (from thinc<8.1.0,>=8.0.12)\n",
      "        Downloading pydantic-1.8.2-py3-none-any.whl.metadata (103 kB)\n",
      "      Collecting typing-extensions>=3.7.4.3 (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->thinc<8.1.0,>=8.0.12)\n",
      "        Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "      Collecting smart-open<7.0.0,>=5.2.1 (from pathy)\n",
      "        Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "      Collecting typer<1.0.0,>=0.3.0 (from pathy)\n",
      "        Downloading typer-0.15.4-py3-none-any.whl.metadata (15 kB)\n",
      "      Collecting pathlib-abc==0.1.1 (from pathy)\n",
      "        Downloading pathlib_abc-0.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "      Collecting click<8.2,>=8.0.0 (from typer<1.0.0,>=0.3.0->pathy)\n",
      "        Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "      Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->pathy)\n",
      "        Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "      Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->pathy)\n",
      "        Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "      Collecting colorama (from click<8.2,>=8.0.0->typer<1.0.0,>=0.3.0->pathy)\n",
      "        Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "      Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->pathy)\n",
      "        Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "      Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->pathy)\n",
      "        Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "      Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->pathy)\n",
      "        Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "      Using cached Cython-0.29.37-py2.py3-none-any.whl (989 kB)\n",
      "      Using cached cymem-2.0.11-cp312-cp312-win_amd64.whl (39 kB)\n",
      "      Using cached preshed-3.0.9-cp312-cp312-win_amd64.whl (122 kB)\n",
      "      Using cached murmurhash-1.0.12-cp312-cp312-win_amd64.whl (25 kB)\n",
      "      Using cached blis-0.7.11-cp312-cp312-win_amd64.whl (6.6 MB)\n",
      "      Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "      Downloading pydantic-1.8.2-py3-none-any.whl (126 kB)\n",
      "      Using cached srsly-2.5.1-cp312-cp312-win_amd64.whl (632 kB)\n",
      "      Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "      Using cached setuptools-80.7.0-py3-none-any.whl (1.2 MB)\n",
      "      Downloading pathy-0.11.0-py3-none-any.whl (47 kB)\n",
      "      Downloading pathlib_abc-0.1.1-py3-none-any.whl (23 kB)\n",
      "      Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "      Downloading typer-0.15.4-py3-none-any.whl (45 kB)\n",
      "      Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "      Using cached numpy-2.2.5-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "      Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "      Downloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
      "         ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "         ---------------------------------------- 1.2/1.2 MB 8.8 MB/s eta 0:00:00\n",
      "      Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "      Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "      Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "      Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "      Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "      Building wheels for collected packages: thinc\n",
      "        Building wheel for thinc (pyproject.toml): started\n",
      "        Building wheel for thinc (pyproject.toml): finished with status 'error'\n",
      "        error: subprocess-exited-with-error\n",
      "      \n",
      "        Ã— Building wheel for thinc (pyproject.toml) did not run successfully.\n",
      "        â”‚ exit code: 1\n",
      "        â•°â”€> [571 lines of output]\n",
      "            Cythonizing sources\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Temp\\pip-build-env-vo68k0ec\\overlay\\Lib\\site-packages\\setuptools\\dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "            !!\n",
      "      \n",
      "                    ********************************************************************************\n",
      "                    Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "                    License :: OSI Approved :: MIT License\n",
      "      \n",
      "                    See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "                    ********************************************************************************\n",
      "      \n",
      "            !!\n",
      "              self._finalize_license_expression()\n",
      "            running bdist_wheel\n",
      "            running build\n",
      "            running build_py\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\n",
      "            copying thinc\\about.py -> build\\lib.win-amd64-cpython-312\\thinc\n",
      "            copying thinc\\api.py -> build\\lib.win-amd64-cpython-312\\thinc\n",
      "            copying thinc\\config.py -> build\\lib.win-amd64-cpython-312\\thinc\n",
      "            copying thinc\\initializers.py -> build\\lib.win-amd64-cpython-312\\thinc\n",
      "            copying thinc\\loss.py -> build\\lib.win-amd64-cpython-312\\thinc\n",
      "            copying thinc\\model.py -> build\\lib.win-amd64-cpython-312\\thinc\n",
      "            copying thinc\\mypy.py -> build\\lib.win-amd64-cpython-312\\thinc\n",
      "            copying thinc\\optimizers.py -> build\\lib.win-amd64-cpython-312\\thinc\n",
      "            copying thinc\\schedules.py -> build\\lib.win-amd64-cpython-312\\thinc\n",
      "            copying thinc\\types.py -> build\\lib.win-amd64-cpython-312\\thinc\n",
      "            copying thinc\\util.py -> build\\lib.win-amd64-cpython-312\\thinc\n",
      "            copying thinc\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\backends\\cupy_ops.py -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\backends\\ops.py -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\backends\\_cupy_allocators.py -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\backends\\_custom_kernels.py -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\backends\\_param_server.py -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\backends\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\extra\n",
      "            copying thinc\\extra\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\extra\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\add.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\array_getitem.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\bidirectional.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\cauchysimilarity.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\chain.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\clipped_linear.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\clone.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\concatenate.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\dropout.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\embed.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\expand_window.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\gelu.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\hard_swish.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\hard_swish_mobilenet.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\hashembed.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\layernorm.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\linear.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\list2array.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\list2padded.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\list2ragged.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\logistic.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\lstm.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\map_list.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\maxout.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\mish.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\multisoftmax.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\mxnetwrapper.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\noop.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\padded2list.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\parametricattention.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\pytorchwrapper.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\ragged2list.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\reduce_first.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\reduce_last.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\reduce_max.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\reduce_mean.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\reduce_sum.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\relu.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\remap_ids.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\residual.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\resizable.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\siamese.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\sigmoid.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\sigmoid_activation.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\softmax.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\softmax_activation.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\strings2arrays.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\swish.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\tensorflowwrapper.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\tuplify.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\uniqued.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\with_array.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\with_array2d.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\with_cpu.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\with_debug.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\with_flatten.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\with_getitem.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\with_list.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\with_nvtx_range.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\with_padded.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\with_ragged.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\with_reshape.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\layers\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\shims\n",
      "            copying thinc\\shims\\mxnet.py -> build\\lib.win-amd64-cpython-312\\thinc\\shims\n",
      "            copying thinc\\shims\\pytorch.py -> build\\lib.win-amd64-cpython-312\\thinc\\shims\n",
      "            copying thinc\\shims\\pytorch_grad_scaler.py -> build\\lib.win-amd64-cpython-312\\thinc\\shims\n",
      "            copying thinc\\shims\\shim.py -> build\\lib.win-amd64-cpython-312\\thinc\\shims\n",
      "            copying thinc\\shims\\tensorflow.py -> build\\lib.win-amd64-cpython-312\\thinc\\shims\n",
      "            copying thinc\\shims\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\shims\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            copying thinc\\tests\\conftest.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            copying thinc\\tests\\strategies.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            copying thinc\\tests\\test_config.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            copying thinc\\tests\\test_examples.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            copying thinc\\tests\\test_indexing.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            copying thinc\\tests\\test_initializers.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            copying thinc\\tests\\test_loss.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            copying thinc\\tests\\test_optimizers.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            copying thinc\\tests\\test_schedules.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            copying thinc\\tests\\test_serialize.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            copying thinc\\tests\\test_types.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            copying thinc\\tests\\test_util.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            copying thinc\\tests\\util.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            copying thinc\\tests\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\extra\\tests\n",
      "            copying thinc\\extra\\tests\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\extra\\tests\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\tests\\backends\n",
      "            copying thinc\\tests\\backends\\test_mem.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\backends\n",
      "            copying thinc\\tests\\backends\\test_ops.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\backends\n",
      "            copying thinc\\tests\\backends\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\backends\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\tests\\extra\n",
      "            copying thinc\\tests\\extra\\test_beam_search.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\extra\n",
      "            copying thinc\\tests\\extra\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\extra\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_basic_tagger.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_combinators.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_feed_forward.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_hash_embed.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_layers_api.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_linear.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_lstm.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_mnist.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_mxnet_wrapper.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_pytorch_wrapper.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_reduce.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_shim.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_softmax.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_sparse_linear.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_tensorflow_wrapper.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_transforms.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_uniqued.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_with_debug.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_with_transforms.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\layers\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\tests\\model\n",
      "            copying thinc\\tests\\model\\test_model.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\model\n",
      "            copying thinc\\tests\\model\\test_validation.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\model\n",
      "            copying thinc\\tests\\model\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\model\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\n",
      "            copying thinc\\tests\\mypy\\test_mypy.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\n",
      "            copying thinc\\tests\\mypy\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\tests\\regression\n",
      "            copying thinc\\tests\\regression\\test_issue208.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\regression\n",
      "            copying thinc\\tests\\regression\\test_issue564.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\regression\n",
      "            copying thinc\\tests\\regression\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\regression\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\tests\\shims\n",
      "            copying thinc\\tests\\shims\\test_pytorch_grad_scaler.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\shims\n",
      "            copying thinc\\tests\\shims\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\shims\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\\modules\n",
      "            copying thinc\\tests\\mypy\\modules\\fail_no_plugin.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\\modules\n",
      "            copying thinc\\tests\\mypy\\modules\\fail_plugin.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\\modules\n",
      "            copying thinc\\tests\\mypy\\modules\\success_no_plugin.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\\modules\n",
      "            copying thinc\\tests\\mypy\\modules\\success_plugin.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\\modules\n",
      "            copying thinc\\tests\\mypy\\modules\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\\modules\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\tests\\regression\\issue519\n",
      "            copying thinc\\tests\\regression\\issue519\\program.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\regression\\issue519\n",
      "            copying thinc\\tests\\regression\\issue519\\test_issue519.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\regression\\issue519\n",
      "            copying thinc\\tests\\regression\\issue519\\__init__.py -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\regression\\issue519\n",
      "            running egg_info\n",
      "            writing thinc.egg-info\\PKG-INFO\n",
      "            writing dependency_links to thinc.egg-info\\dependency_links.txt\n",
      "            writing requirements to thinc.egg-info\\requires.txt\n",
      "            writing top-level names to thinc.egg-info\\top_level.txt\n",
      "            reading manifest file 'thinc.egg-info\\SOURCES.txt'\n",
      "            reading manifest template 'MANIFEST.in'\n",
      "            no previously-included directories found matching 'tmp'\n",
      "            warning: no previously-included files matching '*.cpp' found under directory 'thinc'\n",
      "            adding license file 'LICENSE'\n",
      "            writing manifest file 'thinc.egg-info\\SOURCES.txt'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Temp\\pip-build-env-vo68k0ec\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'thinc.backends' is absent from the `packages` configuration.\n",
      "            !!\n",
      "      \n",
      "                    ********************************************************************************\n",
      "                    ############################\n",
      "                    # Package would be ignored #\n",
      "                    ############################\n",
      "                    Python recognizes 'thinc.backends' as an importable package[^1],\n",
      "                    but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "                    This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "                    package, please make sure that 'thinc.backends' is explicitly added\n",
      "                    to the `packages` configuration field.\n",
      "      \n",
      "                    Alternatively, you can also rely on setuptools' discovery methods\n",
      "                    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "                    instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "                    You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "                    If you don't want 'thinc.backends' to be distributed and are\n",
      "                    already explicitly excluding 'thinc.backends' via\n",
      "                    `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "                    you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "                    combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "                    You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "                    [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                          even if it does not contain any `.py` files.\n",
      "                          On the other hand, currently there is no concept of package data\n",
      "                          directory, all directories are treated like packages.\n",
      "                    ********************************************************************************\n",
      "      \n",
      "            !!\n",
      "              check.warn(importable)\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Temp\\pip-build-env-vo68k0ec\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'thinc.extra' is absent from the `packages` configuration.\n",
      "            !!\n",
      "      \n",
      "                    ********************************************************************************\n",
      "                    ############################\n",
      "                    # Package would be ignored #\n",
      "                    ############################\n",
      "                    Python recognizes 'thinc.extra' as an importable package[^1],\n",
      "                    but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "                    This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "                    package, please make sure that 'thinc.extra' is explicitly added\n",
      "                    to the `packages` configuration field.\n",
      "      \n",
      "                    Alternatively, you can also rely on setuptools' discovery methods\n",
      "                    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "                    instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "                    You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "                    If you don't want 'thinc.extra' to be distributed and are\n",
      "                    already explicitly excluding 'thinc.extra' via\n",
      "                    `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "                    you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "                    combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "                    You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "                    [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                          even if it does not contain any `.py` files.\n",
      "                          On the other hand, currently there is no concept of package data\n",
      "                          directory, all directories are treated like packages.\n",
      "                    ********************************************************************************\n",
      "      \n",
      "            !!\n",
      "              check.warn(importable)\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Temp\\pip-build-env-vo68k0ec\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'thinc.layers' is absent from the `packages` configuration.\n",
      "            !!\n",
      "      \n",
      "                    ********************************************************************************\n",
      "                    ############################\n",
      "                    # Package would be ignored #\n",
      "                    ############################\n",
      "                    Python recognizes 'thinc.layers' as an importable package[^1],\n",
      "                    but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "                    This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "                    package, please make sure that 'thinc.layers' is explicitly added\n",
      "                    to the `packages` configuration field.\n",
      "      \n",
      "                    Alternatively, you can also rely on setuptools' discovery methods\n",
      "                    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "                    instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "                    You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "                    If you don't want 'thinc.layers' to be distributed and are\n",
      "                    already explicitly excluding 'thinc.layers' via\n",
      "                    `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "                    you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "                    combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "                    You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "                    [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                          even if it does not contain any `.py` files.\n",
      "                          On the other hand, currently there is no concept of package data\n",
      "                          directory, all directories are treated like packages.\n",
      "                    ********************************************************************************\n",
      "      \n",
      "            !!\n",
      "              check.warn(importable)\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Temp\\pip-build-env-vo68k0ec\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'thinc.tests.mypy.configs' is absent from the `packages` configuration.\n",
      "            !!\n",
      "      \n",
      "                    ********************************************************************************\n",
      "                    ############################\n",
      "                    # Package would be ignored #\n",
      "                    ############################\n",
      "                    Python recognizes 'thinc.tests.mypy.configs' as an importable package[^1],\n",
      "                    but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "                    This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "                    package, please make sure that 'thinc.tests.mypy.configs' is explicitly added\n",
      "                    to the `packages` configuration field.\n",
      "      \n",
      "                    Alternatively, you can also rely on setuptools' discovery methods\n",
      "                    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "                    instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "                    You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "                    If you don't want 'thinc.tests.mypy.configs' to be distributed and are\n",
      "                    already explicitly excluding 'thinc.tests.mypy.configs' via\n",
      "                    `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "                    you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "                    combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "                    You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "                    [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                          even if it does not contain any `.py` files.\n",
      "                          On the other hand, currently there is no concept of package data\n",
      "                          directory, all directories are treated like packages.\n",
      "                    ********************************************************************************\n",
      "      \n",
      "            !!\n",
      "              check.warn(importable)\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Temp\\pip-build-env-vo68k0ec\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'thinc.tests.mypy.outputs' is absent from the `packages` configuration.\n",
      "            !!\n",
      "      \n",
      "                    ********************************************************************************\n",
      "                    ############################\n",
      "                    # Package would be ignored #\n",
      "                    ############################\n",
      "                    Python recognizes 'thinc.tests.mypy.outputs' as an importable package[^1],\n",
      "                    but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "                    This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "                    package, please make sure that 'thinc.tests.mypy.outputs' is explicitly added\n",
      "                    to the `packages` configuration field.\n",
      "      \n",
      "                    Alternatively, you can also rely on setuptools' discovery methods\n",
      "                    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "                    instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "                    You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "                    If you don't want 'thinc.tests.mypy.outputs' to be distributed and are\n",
      "                    already explicitly excluding 'thinc.tests.mypy.outputs' via\n",
      "                    `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "                    you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "                    combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "                    You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "                    [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                          even if it does not contain any `.py` files.\n",
      "                          On the other hand, currently there is no concept of package data\n",
      "                          directory, all directories are treated like packages.\n",
      "                    ********************************************************************************\n",
      "      \n",
      "            !!\n",
      "              check.warn(importable)\n",
      "            copying thinc\\__init__.pxd -> build\\lib.win-amd64-cpython-312\\thinc\n",
      "            copying thinc\\py.typed -> build\\lib.win-amd64-cpython-312\\thinc\n",
      "            copying thinc\\backends\\linalg.cpp -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\backends\\numpy_ops.cpp -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\extra\\search.cpp -> build\\lib.win-amd64-cpython-312\\thinc\\extra\n",
      "            copying thinc\\layers\\sparselinear.cpp -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\backends\\__init__.pxd -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\backends\\_custom_kernels.cu -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\backends\\_murmur3.cu -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\backends\\linalg.pxd -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\backends\\linalg.pyx -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\backends\\numpy_ops.pxd -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\backends\\numpy_ops.pyx -> build\\lib.win-amd64-cpython-312\\thinc\\backends\n",
      "            copying thinc\\extra\\__init__.pxd -> build\\lib.win-amd64-cpython-312\\thinc\\extra\n",
      "            copying thinc\\extra\\search.pxd -> build\\lib.win-amd64-cpython-312\\thinc\\extra\n",
      "            copying thinc\\extra\\search.pyx -> build\\lib.win-amd64-cpython-312\\thinc\\extra\n",
      "            copying thinc\\layers\\sparselinear.pyx -> build\\lib.win-amd64-cpython-312\\thinc\\layers\n",
      "            copying thinc\\extra\\tests\\c_test_search.pyx -> build\\lib.win-amd64-cpython-312\\thinc\\extra\\tests\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\\configs\n",
      "            copying thinc\\tests\\mypy\\configs\\mypy-default.ini -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\\configs\n",
      "            copying thinc\\tests\\mypy\\configs\\mypy-plugin.ini -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\\configs\n",
      "            creating build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\\outputs\n",
      "            copying thinc\\tests\\mypy\\outputs\\fail-no-plugin.txt -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\\outputs\n",
      "            copying thinc\\tests\\mypy\\outputs\\fail-plugin.txt -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\\outputs\n",
      "            copying thinc\\tests\\mypy\\outputs\\success-no-plugin.txt -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\\outputs\n",
      "            copying thinc\\tests\\mypy\\outputs\\success-plugin.txt -> build\\lib.win-amd64-cpython-312\\thinc\\tests\\mypy\\outputs\n",
      "            running build_ext\n",
      "            building 'thinc.backends.linalg' extension\n",
      "            creating build\\temp.win-amd64-cpython-312\\Release\\thinc\\backends\n",
      "            \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.41.34120\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\kathi\\AppData\\Local\\Temp\\pip-build-env-vo68k0ec\\overlay\\Lib\\site-packages\\numpy\\_core\\include -IC:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include -IC:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include -IC:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.41.34120\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /EHsc /Tpthinc/backends/linalg.cpp /Fobuild\\temp.win-amd64-cpython-312\\Release\\thinc\\backends\\linalg.obj /Ox /EHsc\n",
      "            linalg.cpp\n",
      "            thinc/backends/linalg.cpp(2034): warning C4244: '=': conversion from 'double' to '__pyx_t_5thinc_8backends_6linalg_weight_t', possible loss of data\n",
      "            thinc/backends/linalg.cpp(2474): warning C4244: '=': conversion from 'double' to '__pyx_t_5thinc_8backends_6linalg_weight_t', possible loss of data\n",
      "            thinc/backends/linalg.cpp(2521): warning C4244: '=': conversion from 'double' to '__pyx_t_5thinc_8backends_6linalg_weight_t', possible loss of data\n",
      "            thinc/backends/linalg.cpp(2688): warning C4244: '=': conversion from 'double' to '__pyx_t_5thinc_8backends_6linalg_weight_t', possible loss of data\n",
      "            thinc/backends/linalg.cpp(3356): warning C4244: 'argument': conversion from 'double' to '__pyx_t_5thinc_8backends_6linalg_weight_t', possible loss of data\n",
      "            \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.41.34120\\bin\\HostX86\\x64\\link.exe\" /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\libs /LIBPATH:C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312 /LIBPATH:C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.41.34120\\lib\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.22621.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.22621.0\\\\um\\x64\" /EXPORT:PyInit_linalg build\\temp.win-amd64-cpython-312\\Release\\thinc\\backends\\linalg.obj /OUT:build\\lib.win-amd64-cpython-312\\thinc\\backends\\linalg.cp312-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-cpython-312\\Release\\thinc\\backends\\linalg.cp312-win_amd64.lib\n",
      "               Creating library build\\temp.win-amd64-cpython-312\\Release\\thinc\\backends\\linalg.cp312-win_amd64.lib and object build\\temp.win-amd64-cpython-312\\Release\\thinc\\backends\\linalg.cp312-win_amd64.exp\n",
      "            Generating code\n",
      "            Finished generating code\n",
      "            building 'thinc.backends.numpy_ops' extension\n",
      "            \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.41.34120\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\kathi\\AppData\\Local\\Temp\\pip-build-env-vo68k0ec\\overlay\\Lib\\site-packages\\numpy\\_core\\include -IC:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include -IC:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include -IC:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.41.34120\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /EHsc /Tpthinc/backends/numpy_ops.cpp /Fobuild\\temp.win-amd64-cpython-312\\Release\\thinc\\backends\\numpy_ops.obj /Ox /EHsc\n",
      "            numpy_ops.cpp\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Temp\\pip-build-env-vo68k0ec\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\npy_1_7_deprecated_api.h(14) : Warning Msg: Using deprecated NumPy API, disable it with #define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\n",
      "            thinc/backends/numpy_ops.cpp(4627): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(4720): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(4829): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(5067): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(5167): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(5217): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(5347): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(5694): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(5814): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(5946): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(6079): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(6220): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(6369): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(6557): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(6706): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(6854): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(6990): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(7143): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(7247): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(7268): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(7277): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(7286): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(7471): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(7594): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(7603): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(7612): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(7741): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(7870): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(8082): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(8224): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(8450): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(8473): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(8501): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(8622): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(8631): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(8640): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(8721): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(8876): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(8899): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(8927): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(9049): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(9058): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(9076): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(9157): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(9312): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(9425): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(9550): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(9662): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(9671): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(9680): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(9689): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(9834): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(9946): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(9955): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(9964): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(9973): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(10118): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(10234): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(10243): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(10252): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(10510): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(10626): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(10635): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(10644): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(10902): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(11017): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(11026): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(11035): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(11044): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(11246): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(11375): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(11384): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(11393): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(11667): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(11791): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(11987): warning C4244: 'argument': conversion from 'npy_intp' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(11987): warning C4244: 'argument': conversion from 'npy_intp' to 'int', possible loss of data\n",
      "            thinc/backends/numpy_ops.cpp(12087): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(12292): error C2039: 'use_tracing': is not a member of '_PyCFrame'\n",
      "            C:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/pystate.h(67): note: see declaration of '_PyCFrame'\n",
      "            thinc/backends/numpy_ops.cpp(12292): fatal error C1003: error count exceeds 100; stopping compilation\n",
      "            error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.41.34120\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "            [end of output]\n",
      "      \n",
      "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "        ERROR: Failed building wheel for thinc\n",
      "      Failed to build thinc\n",
      "      ERROR: Failed to build installable wheels for some pyproject.toml based projects (thinc)\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× pip subprocess to install build dependencies did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install scispacy\n",
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_sm-0.5.0.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a14173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Import all modules ===\n",
    "import pandas as pd\n",
    "import re, json, ast, torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from keybert import KeyBERT\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import openai\n",
    "import gradio as gr\n",
    "from fetch_papers import fetch_openalex_papers, save_to_csv  # Replace with your actual function\n",
    "\n",
    "# === Model/Loaders ===\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "kw_model = KeyBERT(model='bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model.eval()\n",
    "\n",
    "# === Groq API Setup ===\n",
    "openai.api_key = \"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\"  # Replace with your actual key\n",
    "openai.api_base = \"https://api.groq.com/openai/v1\"\n",
    "\n",
    "# === Neo4j Setup ===\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"qwertyuiop\"))\n",
    "\n",
    "\n",
    "# === Step 1: Fetch Papers ===\n",
    "def fetch_and_save_papers(query, max_results=50):\n",
    "    df = fetch_openalex_papers(query, max_results=max_results)\n",
    "    save_to_csv(df, \"papers.csv\")\n",
    "\n",
    "\n",
    "# === Step 2: Enrichment ===\n",
    "def enrich_papers():\n",
    "    df = pd.read_csv(\"papers.csv\")\n",
    "    def clean_text(text):\n",
    "        text = str(text).lower()\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', text).strip()\n",
    "    df[\"clean_abstract\"] = df[\"abstract\"].fillna(\"\").apply(clean_text)\n",
    "    df[\"keywords\"] = df[\"keywords\"].fillna(\"[]\").apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "    df[\"entities\"] = df[\"entities\"].fillna(\"[]\").apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "    df.to_csv(\"papers_enriched.csv\", index=False)\n",
    "\n",
    "\n",
    "# === Step 3: Build Knowledge Graph ===\n",
    "def build_knowledge_graph():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\")\n",
    "    graph.delete_all()\n",
    "    for _, row in df.iterrows():\n",
    "        paper_node = Node(\"Paper\", title=row[\"title\"], year=row[\"publication_year\"], doi=row[\"doi\"])\n",
    "        graph.create(paper_node)\n",
    "        for author in eval(str(row[\"authors\"])):\n",
    "            author_node = Node(\"Author\", name=author)\n",
    "            graph.merge(author_node, \"Author\", \"name\")\n",
    "            graph.create(Relationship(author_node, \"WROTE\", paper_node))\n",
    "        for keyword in row[\"keywords\"]:\n",
    "            keyword_node = Node(\"Keyword\", name=keyword)\n",
    "            graph.merge(keyword_node, \"Keyword\", \"name\")\n",
    "            graph.create(Relationship(paper_node, \"HAS_KEYWORD\", keyword_node))\n",
    "        for entity in row[\"entities\"]:\n",
    "            entity_node = Node(\"Entity\", name=entity)\n",
    "            graph.merge(entity_node, \"Entity\", \"name\")\n",
    "            graph.create(Relationship(paper_node, \"MENTIONS\", entity_node))\n",
    "\n",
    "\n",
    "# === Step 4: Cluster Abstracts ===\n",
    "def cluster_abstracts():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\").dropna(subset=[\"clean_abstract\"])\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No valid abstracts to cluster.\")\n",
    "    embeddings = model.encode(df[\"clean_abstract\"].tolist(), show_progress_bar=True)\n",
    "    gmm = GaussianMixture(n_components=5, covariance_type='full', random_state=42)\n",
    "    gmm.fit(embeddings)\n",
    "    df[\"gmm_cluster\"] = gmm.predict(embeddings)\n",
    "    df[\"gmm_probs\"] = gmm.predict_proba(embeddings).tolist()\n",
    "    df.to_csv(\"clustered_papers.csv\", index=False)\n",
    "\n",
    "\n",
    "# === Step 5: Summarization with Groq ===\n",
    "def summarize_clusters():\n",
    "    df = pd.read_csv(\"clustered_papers.csv\")\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if \"gmm_cluster\" not in df.columns:\n",
    "        raise ValueError(\"Missing 'gmm_cluster' column.\")\n",
    "    clusters = df.groupby(\"gmm_cluster\")[\"clean_abstract\"].apply(list).to_dict()\n",
    "\n",
    "    def embedding_to_keywords(texts):\n",
    "        combined = \" \".join(texts)\n",
    "        return [kw[0] for kw in kw_model.extract_keywords(combined, top_n=20)]\n",
    "\n",
    "    def query_groq(prompt):\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"llama3-70b-8192\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=800\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    summaries = {}\n",
    "    for cluster_id, texts in clusters.items():\n",
    "        try:\n",
    "            keywords = embedding_to_keywords(texts)\n",
    "            prompt = (\n",
    "                \"You are a research assistant. Generate a detailed research summary \"\n",
    "                \"focusing on research methodology and key findings for:\\n\\n\"\n",
    "                + \", \".join(keywords) + \"\\n\\nSummary:\"\n",
    "            )\n",
    "            summaries[cluster_id] = query_groq(prompt)\n",
    "        except Exception as e:\n",
    "            summaries[cluster_id] = f\"ERROR: {str(e)}\"\n",
    "\n",
    "    with open(\"cluster_summaries.json\", \"w\") as f:\n",
    "        json.dump(summaries, f, indent=4)\n",
    "\n",
    "\n",
    "# === Unified Runner ===\n",
    "def run_pipeline(query):\n",
    "    try:\n",
    "        fetch_and_save_papers(query)\n",
    "        enrich_papers()\n",
    "        build_knowledge_graph()\n",
    "        cluster_abstracts()\n",
    "        summarize_clusters()\n",
    "        return \"✅ Pipeline executed successfully!\"\n",
    "    except Exception as e:\n",
    "        return f\"❌ Pipeline failed: {e}\"\n",
    "\n",
    "\n",
    "# === UI Wrapper ===\n",
    "def run_pipeline_ui(query):\n",
    "    status = run_pipeline(query)\n",
    "\n",
    "    try:\n",
    "        df_enriched = pd.read_csv(\"papers_enriched.csv\")\n",
    "    except:\n",
    "        df_enriched = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        df_clustered = pd.read_csv(\"clustered_papers.csv\")\n",
    "    except:\n",
    "        df_clustered = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        with open(\"cluster_summaries.json\") as f:\n",
    "            summaries = json.load(f)\n",
    "        summaries_str = \"\\n\\n\".join([f\"🔹 Cluster {k}:\\n{v}\" for k, v in summaries.items()])\n",
    "    except:\n",
    "        summaries_str = \"No summary generated.\"\n",
    "\n",
    "    return (\n",
    "        status,\n",
    "        df_enriched.head(10) if not df_enriched.empty else \"No enriched data available.\",\n",
    "        df_clustered[[\"title\", \"gmm_cluster\"]].head(10) if not df_clustered.empty else \"No clustered data available.\",\n",
    "        summaries_str,\n",
    "        \"papers_enriched.csv\" if not df_enriched.empty else None,\n",
    "        \"clustered_papers.csv\" if not df_clustered.empty else None,\n",
    "        \"cluster_summaries.json\" if summaries_str else None\n",
    "    )\n",
    "\n",
    "\n",
    "# === GRADIO UI ===\n",
    "gr.Interface(\n",
    "    fn=run_pipeline_ui,\n",
    "    inputs=gr.Textbox(lines=2, label=\"Enter Research Topic\", placeholder=\"e.g., LLMs in medicine\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Pipeline Status\"),\n",
    "        gr.Dataframe(label=\"Enriched Papers Preview\"),\n",
    "        gr.Dataframe(label=\"Clustered Papers Preview\"),\n",
    "        gr.Textbox(label=\"Cluster Summaries\"),\n",
    "        gr.File(label=\"📄 Enriched CSV\"),\n",
    "        gr.File(label=\"📄 Clustered CSV\"),\n",
    "        gr.File(label=\"📄 Summary JSON\")\n",
    "    ],\n",
    "    title=\"Unified Hybrid NLP Research Assistant\",\n",
    "    description=\"End-to-end research pipeline: OpenAlex → Enrichment → Neo4j KG → Clustering → Groq Summarization\"\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbac5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bacaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching OpenAlex for: transformers\n",
      "Request failed: HTTPSConnectionPool(host='api.openalex.org', port=443): Max retries exceeded with url: /works?filter=title.search:transformers&per-page=25&cursor=* (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate is not yet valid (_ssl.c:1000)')))\n",
      "✅ Retrieved 0 papers.\n",
      "Saved metadata to papers.csv\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import re, json, ast, torch, os\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from keybert import KeyBERT\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import openai\n",
    "import gradio as gr\n",
    "from fetch_papers import fetch_openalex_papers, save_to_csv\n",
    "\n",
    "# === Model/Loaders ===\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "kw_model = KeyBERT(model='bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model.eval()\n",
    "\n",
    "# === Groq API Setup ===\n",
    "openai.api_key = \"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\"  # Replace with your actual key\n",
    "openai.api_base = \"https://api.groq.com/openai/v1\"\n",
    "\n",
    "# === Neo4j Setup ===\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"qwertyuiop\"))\n",
    "\n",
    "\n",
    "# === Step 1: Fetch Papers ===\n",
    "def fetch_and_save_papers(query, max_results=50):\n",
    "    df = fetch_openalex_papers(query, max_results=max_results)\n",
    "    save_to_csv(df, \"papers.csv\")\n",
    "\n",
    "\n",
    "# === Step 2: Enrichment ===\n",
    "def enrich_papers():\n",
    "    df = pd.read_csv(\"papers.csv\")\n",
    "    def clean_text(text):\n",
    "        text = str(text).lower()\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', text).strip()\n",
    "    df[\"clean_abstract\"] = df[\"abstract\"].fillna(\"\").apply(clean_text)\n",
    "    df[\"keywords\"] = df[\"keywords\"].fillna(\"[]\").apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "    df[\"entities\"] = df[\"entities\"].fillna(\"[]\").apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "    df.to_csv(\"papers_enriched.csv\", index=False)\n",
    "\n",
    "\n",
    "# === Step 3: Build Knowledge Graph ===\n",
    "def build_knowledge_graph():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\")\n",
    "    graph.delete_all()\n",
    "    for _, row in df.iterrows():\n",
    "        paper_node = Node(\"Paper\", title=row[\"title\"], year=row[\"publication_year\"], doi=row[\"doi\"])\n",
    "        graph.create(paper_node)\n",
    "        for author in eval(str(row[\"authors\"])):\n",
    "            author_node = Node(\"Author\", name=author)\n",
    "            graph.merge(author_node, \"Author\", \"name\")\n",
    "            graph.create(Relationship(author_node, \"WROTE\", paper_node))\n",
    "        for keyword in row[\"keywords\"]:\n",
    "            keyword_node = Node(\"Keyword\", name=keyword)\n",
    "            graph.merge(keyword_node, \"Keyword\", \"name\")\n",
    "            graph.create(Relationship(paper_node, \"HAS_KEYWORD\", keyword_node))\n",
    "        for entity in row[\"entities\"]:\n",
    "            entity_node = Node(\"Entity\", name=entity)\n",
    "            graph.merge(entity_node, \"Entity\", \"name\")\n",
    "            graph.create(Relationship(paper_node, \"MENTIONS\", entity_node))\n",
    "\n",
    "\n",
    "# === Step 4: Cluster Abstracts ===\n",
    "def cluster_abstracts():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\").dropna(subset=[\"clean_abstract\"])\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No valid abstracts to cluster.\")\n",
    "    embeddings = model.encode(df[\"clean_abstract\"].tolist(), show_progress_bar=True)\n",
    "    gmm = GaussianMixture(n_components=5, covariance_type='full', random_state=42)\n",
    "    gmm.fit(embeddings)\n",
    "    df[\"gmm_cluster\"] = gmm.predict(embeddings)\n",
    "    df[\"gmm_probs\"] = gmm.predict_proba(embeddings).tolist()\n",
    "    df.to_csv(\"clustered_papers.csv\", index=False)\n",
    "\n",
    "\n",
    "# === Step 5: Summarization with Groq ===\n",
    "def summarize_clusters():\n",
    "    df = pd.read_csv(\"clustered_papers.csv\")\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if \"gmm_cluster\" not in df.columns:\n",
    "        raise ValueError(\"Missing 'gmm_cluster' column.\")\n",
    "    clusters = df.groupby(\"gmm_cluster\")[\"clean_abstract\"].apply(list).to_dict()\n",
    "\n",
    "    def embedding_to_keywords(texts):\n",
    "        combined = \" \".join(texts)\n",
    "        return [kw[0] for kw in kw_model.extract_keywords(combined, top_n=20)]\n",
    "\n",
    "    def query_groq(prompt):\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"llama3-70b-8192\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=800\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    summaries = {}\n",
    "    for cluster_id, texts in clusters.items():\n",
    "        try:\n",
    "            keywords = embedding_to_keywords(texts)\n",
    "            prompt = (\n",
    "                \"You are a research assistant. Generate a detailed research summary \"\n",
    "                \"focusing on research methodology and key findings for:\\n\\n\"\n",
    "                + \", \".join(keywords) + \"\\n\\nSummary:\"\n",
    "            )\n",
    "            summaries[cluster_id] = query_groq(prompt)\n",
    "        except Exception as e:\n",
    "            summaries[cluster_id] = f\"ERROR: {str(e)}\"\n",
    "\n",
    "    with open(\"cluster_summaries.json\", \"w\") as f:\n",
    "        json.dump(summaries, f, indent=4)\n",
    "\n",
    "\n",
    "# === Visualize Neo4j Graph ===\n",
    "def visualize_neo4j_graph():\n",
    "    query = \"\"\"\n",
    "    MATCH (n)-[r]->(m)\n",
    "    RETURN n.name AS source, type(r) AS relation, m.name AS target\n",
    "    \"\"\"\n",
    "    result = graph.run(query).data()\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    for row in result:\n",
    "        G.add_edge(row[\"source\"], row[\"target\"], label=row[\"relation\"])\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    pos = nx.spring_layout(G, k=0.5)\n",
    "    nx.draw(G, pos, with_labels=True, node_size=800, node_color=\"skyblue\", font_size=10, font_weight='bold', edge_color=\"gray\")\n",
    "    edge_labels = nx.get_edge_attributes(G, 'label')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"graph.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# === Unified Runner ===\n",
    "def run_pipeline(query):\n",
    "    try:\n",
    "        fetch_and_save_papers(query)\n",
    "        enrich_papers()\n",
    "        build_knowledge_graph()\n",
    "        cluster_abstracts()\n",
    "        summarize_clusters()\n",
    "        visualize_neo4j_graph()\n",
    "        return \"✅ Pipeline executed successfully!\"\n",
    "    except Exception as e:\n",
    "        return f\"❌ Pipeline failed: {e}\"\n",
    "\n",
    "\n",
    "# === UI Wrapper ===\n",
    "def run_pipeline_ui(query):\n",
    "    status = run_pipeline(query)\n",
    "\n",
    "    try:\n",
    "        df_enriched = pd.read_csv(\"papers_enriched.csv\")\n",
    "    except:\n",
    "        df_enriched = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        df_clustered = pd.read_csv(\"clustered_papers.csv\")\n",
    "    except:\n",
    "        df_clustered = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        with open(\"cluster_summaries.json\") as f:\n",
    "            summaries = json.load(f)\n",
    "        summaries_str = \"\\n\\n\".join([f\"🔹 Cluster {k}:\\n{v}\" for k, v in summaries.items()])\n",
    "    except:\n",
    "        summaries_str = \"No summary generated.\"\n",
    "\n",
    "    graph_file = \"graph.png\" if os.path.exists(\"graph.png\") else None\n",
    "\n",
    "    return (\n",
    "        status,\n",
    "        df_enriched.head(10) if not df_enriched.empty else \"No enriched data available.\",\n",
    "        df_clustered[[\"title\", \"gmm_cluster\"]].head(10) if not df_clustered.empty else \"No clustered data available.\",\n",
    "        summaries_str,\n",
    "        \"papers_enriched.csv\" if not df_enriched.empty else None,\n",
    "        \"clustered_papers.csv\" if not df_clustered.empty else None,\n",
    "        \"cluster_summaries.json\" if summaries_str else None,\n",
    "        graph_file,   # for Image (display)\n",
    "        graph_file    # for File (download)\n",
    "    )\n",
    "\n",
    "\n",
    "# === GRADIO UI ===\n",
    "gr.Interface(\n",
    "    fn=run_pipeline_ui,\n",
    "    inputs=gr.Textbox(lines=2, label=\"Enter Research Topic\", placeholder=\"e.g., LLMs in medicine\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Pipeline Status\"),\n",
    "        gr.Dataframe(label=\"Enriched Papers Preview\"),\n",
    "        gr.Dataframe(label=\"Clustered Papers Preview\"),\n",
    "        gr.Textbox(label=\"Cluster Summaries\"),\n",
    "        gr.File(label=\"📄 Enriched CSV\"),\n",
    "        gr.File(label=\"📄 Clustered CSV\"),\n",
    "        gr.File(label=\"📄 Summary JSON\"),\n",
    "        gr.Image(label=\"📷 Graph Preview\"),    # Show graph inline\n",
    "        gr.File(label=\"📥 Download Graph PNG\")  # Allow file download\n",
    "    ],\n",
    "    title=\"Unified Hybrid NLP Research Assistant\",\n",
    "    description=\"End-to-end research pipeline: OpenAlex → Enrichment → Neo4j KG → Clustering → Groq Summarization → Graph Visualization\"\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39119cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name allenai/scibert_scivocab_uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Import all modules ===\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import ast\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from keybert import KeyBERT\n",
    "from py2neo import Graph, Node, Relationship\n",
    "import openai\n",
    "import gradio as gr\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# === Model/Loaders ===\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "kw_model = KeyBERT(model='allenai/scibert_scivocab_uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "bert_model.eval()\n",
    "\n",
    "# === Groq API Setup ===\n",
    "openai.api_key = \"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\"  # Replace with your actual key\n",
    "openai.api_base = \"https://api.groq.com/openai/v1\"\n",
    "\n",
    "# === Neo4j Setup ===\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"qwertyuiop\"))  # Replace with your credentials\n",
    "\n",
    "# === Step 1: Fetch Papers from CORE API ===\n",
    "def fetch_core_papers(query, max_results=10):\n",
    "    headers = {\n",
    "        \"Authorization\": \"ZLQojgG1uJDYRdprWS8UhEzsIPM03cNi\",  # Replace with your CORE API key\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"page\": 1,\n",
    "        \"pageSize\": max_results\n",
    "    }\n",
    "    response = requests.get(\"https://api.core.ac.uk/v3/search/works\", headers=headers, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"CORE API request failed with status code {response.status_code}\")\n",
    "    data = response.json()\n",
    "    papers = []\n",
    "    for item in data.get(\"results\", []):\n",
    "        paper = {\n",
    "            \"title\": item.get(\"title\"),\n",
    "            \"authors\": [author.get(\"name\") for author in item.get(\"authors\", [])],\n",
    "            \"year\": item.get(\"publishedDate\", \"\")[:4],\n",
    "            \"doi\": item.get(\"doi\"),\n",
    "            \"pdf_url\": item.get(\"downloadUrl\")\n",
    "        }\n",
    "        papers.append(paper)\n",
    "    return pd.DataFrame(papers)\n",
    "\n",
    "# === Step 2: Download and Extract Full Text from PDFs ===\n",
    "def extract_full_text(pdf_url):\n",
    "    try:\n",
    "        response = requests.get(pdf_url)\n",
    "        if response.status_code != 200:\n",
    "            return \"\"\n",
    "        with BytesIO(response.content) as f:\n",
    "            doc = fitz.open(stream=f, filetype=\"pdf\")\n",
    "            text = \"\"\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        return \"\"\n",
    "\n",
    "# === Step 3: Enrichment ===\n",
    "def enrich_papers(df):\n",
    "    df[\"full_text\"] = df[\"pdf_url\"].apply(lambda url: extract_full_text(url) if pd.notnull(url) else \"\")\n",
    "    df[\"clean_text\"] = df[\"full_text\"].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x.lower()).strip())\n",
    "    df[\"keywords\"] = df[\"clean_text\"].apply(lambda x: [kw[0] for kw in kw_model.extract_keywords(x, top_n=10)] if x else [])\n",
    "    df.to_csv(\"papers_enriched.csv\", index=False)\n",
    "\n",
    "# === Step 4: Build Knowledge Graph ===\n",
    "def build_knowledge_graph():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\")\n",
    "    graph.delete_all()\n",
    "    for _, row in df.iterrows():\n",
    "        paper_node = Node(\"Paper\", title=row[\"title\"], year=row[\"year\"], doi=row[\"doi\"])\n",
    "        graph.create(paper_node)\n",
    "        for author in ast.literal_eval(row[\"authors\"]):\n",
    "            author_node = Node(\"Author\", name=author)\n",
    "            graph.merge(author_node, \"Author\", \"name\")\n",
    "            graph.create(Relationship(author_node, \"WROTE\", paper_node))\n",
    "        for keyword in ast.literal_eval(row[\"keywords\"]):\n",
    "            keyword_node = Node(\"Keyword\", name=keyword)\n",
    "            graph.merge(keyword_node, \"Keyword\", \"name\")\n",
    "            graph.create(Relationship(paper_node, \"HAS_KEYWORD\", keyword_node))\n",
    "\n",
    "# === Step 5: Cluster Papers ===\n",
    "def cluster_papers():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\")\n",
    "    texts = df[\"clean_text\"].tolist()\n",
    "    embeddings = model.encode(texts, show_progress_bar=True)\n",
    "    gmm = GaussianMixture(n_components=5, covariance_type='full', random_state=42)\n",
    "    gmm.fit(embeddings)\n",
    "    df[\"cluster\"] = gmm.predict(embeddings)\n",
    "    df.to_csv(\"clustered_papers.csv\", index=False)\n",
    "\n",
    "# === Step 6: Summarize Clusters ===\n",
    "def summarize_clusters():\n",
    "    df = pd.read_csv(\"clustered_papers.csv\")\n",
    "    summaries = {}\n",
    "    for cluster_id in df[\"cluster\"].unique():\n",
    "        cluster_texts = df[df[\"cluster\"] == cluster_id][\"clean_text\"].tolist()\n",
    "        combined_text = \" \".join(cluster_texts)\n",
    "        prompt = f\"Summarize the following research papers:\\n\\n{combined_text}\\n\\nSummary:\"\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"llama3-70b-8192\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_tokens=800\n",
    "            )\n",
    "            summaries[cluster_id] = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except Exception as e:\n",
    "            summaries[cluster_id] = f\"Error: {str(e)}\"\n",
    "    with open(\"cluster_summaries.json\", \"w\") as f:\n",
    "        json.dump(summaries, f, indent=4)\n",
    "\n",
    "# === Unified Runner ===\n",
    "def run_pipeline(query):\n",
    "    try:\n",
    "        df = fetch_core_papers(query)\n",
    "        df.to_csv(\"papers.csv\", index=False)\n",
    "        enrich_papers(df)\n",
    "        build_knowledge_graph()\n",
    "        cluster_papers()\n",
    "        summarize_clusters()\n",
    "        return \"✅ Pipeline executed successfully!\"\n",
    "    except Exception as e:\n",
    "        return f\"❌ Pipeline failed: {e}\"\n",
    "\n",
    "# === UI Wrapper ===\n",
    "def run_pipeline_ui(query):\n",
    "    status = run_pipeline(query)\n",
    "    try:\n",
    "        df_enriched = pd.read_csv(\"papers_enriched.csv\")\n",
    "    except:\n",
    "        df_enriched = pd.DataFrame()\n",
    "    try:\n",
    "        df_clustered = pd.read_csv(\"clustered_papers.csv\")\n",
    "    except:\n",
    "        df_clustered = pd.DataFrame()\n",
    "    try:\n",
    "        with open(\"cluster_summaries.json\") as f:\n",
    "            summaries = json.load(f)\n",
    "        summaries_str = \"\\n\\n\".join([f\"🔹 Cluster {k}:\\n{v}\" for k, v in summaries.items()])\n",
    "    except:\n",
    "        summaries_str = \"No summary generated.\"\n",
    "    return (\n",
    "        status,\n",
    "        df_enriched.head(10) if not df_enriched.empty else \"No enriched data available.\",\n",
    "        df_clustered[[\"title\", \"cluster\"]].head(10) if not df_clustered.empty else \"No clustered data available.\",\n",
    "        summaries_str,\n",
    "        \"papers_enriched.csv\" if not df_enriched.empty else None,\n",
    "        \"clustered_papers.csv\" if not df_clustered.empty else None,\n",
    "        \"cluster_summaries.json\" if summaries_str else None\n",
    "    )\n",
    "\n",
    "# === GRADIO UI ===\n",
    "gr.Interface(\n",
    "    fn=run_pipeline_ui,\n",
    "    inputs=gr.Textbox(lines=2, label=\"Enter Research Topic\", placeholder=\"e.g., Deep Learning in Medicine\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Pipeline Status\"),\n",
    "        gr.Dataframe(label=\"Enriched Papers Preview\"),\n",
    "        gr.Dataframe(label=\"Clustered Papers Preview\"),\n",
    "        gr.Textbox(label=\"Cluster Summaries\"),\n",
    "        gr.File(label=\"📄 Enriched CSV\"),\n",
    "        gr.File(label=\"📄 Clustered CSV\"),\n",
    "        gr.File(label=\"📄 Summary JSON\")\n",
    "    ],\n",
    "    title=\"Unified Hybrid NLP Research Assistant\",\n",
    "    description=\"End-to-end research pipeline: CORE API → Full-Text Extraction → Neo4j KG → Clustering → Groq Summarization\"\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a08285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py\", line 974, in json\n",
      "    return complexjson.loads(self.text, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\simplejson\\__init__.py\", line 514, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\simplejson\\decoder.py\", line 386, in decode\n",
      "    obj, end = self.raw_decode(s)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\simplejson\\decoder.py\", line 416, in raw_decode\n",
      "    return self.scan_once(s, idx=_w(s, idx).end())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "simplejson.errors.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 2146, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 1664, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kathi\\AppData\\Local\\Temp\\ipykernel_9164\\2333368451.py\", line 108, in run_all\n",
      "    fetch_and_save_papers(query)\n",
      "  File \"C:\\Users\\kathi\\AppData\\Local\\Temp\\ipykernel_9164\\2333368451.py\", line 29, in fetch_and_save_papers\n",
      "    df = fetch_core_papers(query, max_results)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\ML_MINI\\unified_hybrid_bert_gpt_for_bibliometric\\fetchpaper.py\", line 19, in fetch_core_papers\n",
      "    \"\"\"\n",
      "        \n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py\", line 978, in json\n",
      "    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n",
      "requests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re, json, ast, torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from keybert import KeyBERT\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import openai\n",
    "from pyvis.network import Network\n",
    "import gradio as gr\n",
    "from fetchpaper import fetch_core_papers, save_to_csv\n",
    "\n",
    "# === Models ===\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "kw_model = KeyBERT(model='bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model.eval()\n",
    "\n",
    "# === Groq API ===\n",
    "openai.api_key = \"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\"\n",
    "openai.api_base = \"https://api.groq.com/openai/v1\"\n",
    "\n",
    "# === Neo4j ===\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"qwertyuiop\"))\n",
    "\n",
    "# === Step 1: Fetch Papers ===\n",
    "def fetch_and_save_papers(query, max_results=10):\n",
    "    df = fetch_core_papers(query, max_results)\n",
    "    save_to_csv(df, \"papers.csv\")\n",
    "\n",
    "# === Step 2: Enrichment ===\n",
    "def enrich_papers():\n",
    "    df = pd.read_csv(\"papers.csv\")\n",
    "    def clean_text(text):\n",
    "        text = str(text).lower()\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', text).strip()\n",
    "    df[\"clean_text\"] = df[\"full_text\"].fillna(\"\").apply(clean_text)\n",
    "    df[\"keywords\"] = df[\"clean_text\"].apply(lambda x: [kw[0] for kw in kw_model.extract_keywords(x, top_n=10)] if x else [])\n",
    "    df.to_csv(\"papers_enriched.csv\", index=False)\n",
    "\n",
    "# === Step 3: Build Graph ===\n",
    "def build_knowledge_graph():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\")\n",
    "    graph.delete_all()\n",
    "    for _, row in df.iterrows():\n",
    "        paper_node = Node(\"Paper\", title=row[\"title\"], year=row[\"year\"], doi=row[\"doi\"])\n",
    "        graph.create(paper_node)\n",
    "        for author in ast.literal_eval(row[\"authors\"]):\n",
    "            author_node = Node(\"Author\", name=author)\n",
    "            graph.merge(author_node, \"Author\", \"name\")\n",
    "            graph.create(Relationship(author_node, \"WROTE\", paper_node))\n",
    "        for keyword in ast.literal_eval(row[\"keywords\"]):\n",
    "            keyword_node = Node(\"Keyword\", name=keyword)\n",
    "            graph.merge(keyword_node, \"Keyword\", \"name\")\n",
    "            graph.create(Relationship(paper_node, \"HAS_KEYWORD\", keyword_node))\n",
    "\n",
    "# === Step 4: Clustering ===\n",
    "def cluster_texts():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\").dropna(subset=[\"clean_text\"])\n",
    "    embeddings = model.encode(df[\"clean_text\"].tolist(), show_progress_bar=True)\n",
    "    gmm = GaussianMixture(n_components=5, random_state=42)\n",
    "    df[\"cluster\"] = gmm.fit_predict(embeddings)\n",
    "    df.to_csv(\"clustered_papers.csv\", index=False)\n",
    "\n",
    "# === Step 5: Summarization ===\n",
    "def summarize_clusters():\n",
    "    df = pd.read_csv(\"clustered_papers.csv\")\n",
    "    grouped = df.groupby(\"cluster\")[\"clean_text\"].apply(list).to_dict()\n",
    "\n",
    "    def query_groq(prompt):\n",
    "        res = openai.ChatCompletion.create(\n",
    "            model=\"llama3-70b-8192\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a research assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=800\n",
    "        )\n",
    "        return res['choices'][0]['message']['content']\n",
    "\n",
    "    summaries = {}\n",
    "    for cluster, texts in grouped.items():\n",
    "        text_blob = \" \".join(texts)[:4000]  # avoid overload\n",
    "        prompt = f\"Summarize the following research papers focusing on methodology and key findings:\\n{text_blob}\"\n",
    "        summaries[cluster] = query_groq(prompt)\n",
    "\n",
    "    with open(\"cluster_summaries.json\", \"w\") as f:\n",
    "        json.dump(summaries, f, indent=2)\n",
    "\n",
    "# === Visualization ===\n",
    "def visualize_graph():\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Paper)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "    RETURN p.title AS title, k.name AS keyword LIMIT 100\n",
    "    \"\"\"\n",
    "    results = graph.run(query).data()\n",
    "    net = Network(notebook=True)\n",
    "    for record in results:\n",
    "        net.add_node(record[\"title\"], label=record[\"title\"], shape=\"box\", color=\"lightblue\")\n",
    "        net.add_node(record[\"keyword\"], label=record[\"keyword\"], shape=\"dot\", color=\"orange\")\n",
    "        net.add_edge(record[\"title\"], record[\"keyword\"])\n",
    "    net.show(\"graph.html\")\n",
    "\n",
    "# === Run Everything ===\n",
    "def run_all(query):\n",
    "    fetch_and_save_papers(query)\n",
    "    enrich_papers()\n",
    "    build_knowledge_graph()\n",
    "    cluster_texts()\n",
    "    summarize_clusters()\n",
    "    visualize_graph()\n",
    "    return \"✅ Pipeline complete!\"\n",
    "\n",
    "# === Gradio UI ===\n",
    "gr.Interface(\n",
    "    fn=run_all,\n",
    "    inputs=gr.Textbox(lines=2, label=\"Research Topic\"),\n",
    "    outputs=gr.Textbox(label=\"Status\"),\n",
    "    title=\"CORE Full-Text NLP Pipeline\",\n",
    "    description=\"End-to-end full-paper analysis using BERT, Groq, Neo4j, and PyVis.\"\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5402264b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d601bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'run_all' from 'pipeline' (e:\\ML_MINI\\unified_hybrid_bert_gpt_for_bibliometric\\pipeline.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 164\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    163\u001b[0m     user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔍 Enter your research topic: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 164\u001b[0m     \u001b[43mrun_all_and_display\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 151\u001b[0m, in \u001b[0;36mrun_all_and_display\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_all_and_display\u001b[39m(query):\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_all  \u001b[38;5;66;03m# your main logic module\u001b[39;00m\n\u001b[0;32m    152\u001b[0m     run_all(query)\n\u001b[0;32m    154\u001b[0m     print_enriched_papers()\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'run_all' from 'pipeline' (e:\\ML_MINI\\unified_hybrid_bert_gpt_for_bibliometric\\pipeline.py)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching OpenAlex for: natural language processing\n",
      "✅ Retrieved 50 papers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 2146, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 1664, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\ML_MINI\\unified_hybrid_bert_gpt_for_bibliometric\\pipeline.py\", line 265, in run_pipeline\n",
      "    df_enriched = preprocess_data(df)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\ML_MINI\\unified_hybrid_bert_gpt_for_bibliometric\\pipeline.py\", line 89, in preprocess_data\n",
      "    nlp = spacy.load(\"en_core_sci_sm\")  # SciSpacy for scientific NER\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\spacy\\__init__.py\", line 51, in load\n",
      "    return util.load_model(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\spacy\\util.py\", line 472, in load_model\n",
      "    raise IOError(Errors.E050.format(name=name))\n",
      "OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a Python package or a valid path to a data directory.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re, json, ast, torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from keybert import KeyBERT\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import openai\n",
    "from pyvis.network import Network\n",
    "from fetch_arxiv import fetch_arxiv_papers, save_to_csv\n",
    "\n",
    "# === Models ===\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "kw_model = KeyBERT(model='bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model.eval()\n",
    "\n",
    "# === Groq API ===\n",
    "openai.api_key = \"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\"\n",
    "openai.api_base = \"https://api.groq.com/openai/v1\"\n",
    "\n",
    "# === Neo4j ===\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"qwertyuiop\"))\n",
    "\n",
    "# === Step 1: Fetch and Save ===\n",
    "def fetch_and_save_papers(query, max_results=10):\n",
    "    df = fetch_arxiv_papers(query, max_results)\n",
    "    save_to_csv(df)\n",
    "\n",
    "# === Step 2: Enrichment ===\n",
    "def enrich_papers():\n",
    "    df = pd.read_csv(\"papers3.csv\")\n",
    "    def clean_text(text):\n",
    "        text = str(text).lower()\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', text).strip()\n",
    "    df[\"clean_text\"] = df[\"full_text\"].fillna(\"\").apply(clean_text)\n",
    "    df[\"keywords\"] = df[\"clean_text\"].apply(lambda x: [kw[0] for kw in kw_model.extract_keywords(x, top_n=10)] if x else [])\n",
    "    df.to_csv(\"papers_enriched.csv\", index=False)\n",
    "\n",
    "# === Step 3: Build Graph ===\n",
    "def build_knowledge_graph():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\")\n",
    "    graph.delete_all()\n",
    "    for _, row in df.iterrows():\n",
    "        paper_node = Node(\"Paper\", title=row[\"title\"], year=row[\"year\"], doi=row[\"doi\"])\n",
    "        graph.create(paper_node)\n",
    "        for author in ast.literal_eval(row[\"authors\"]):\n",
    "            author_node = Node(\"Author\", name=author)\n",
    "            graph.merge(author_node, \"Author\", \"name\")\n",
    "            graph.create(Relationship(author_node, \"WROTE\", paper_node))\n",
    "        for keyword in ast.literal_eval(row[\"keywords\"]):\n",
    "            keyword_node = Node(\"Keyword\", name=keyword)\n",
    "            graph.merge(keyword_node, \"Keyword\", \"name\")\n",
    "            graph.create(Relationship(paper_node, \"HAS_KEYWORD\", keyword_node))\n",
    "\n",
    "# === Step 4: Clustering ===\n",
    "def cluster_texts():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\").dropna(subset=[\"clean_text\"])\n",
    "    embeddings = model.encode(df[\"clean_text\"].tolist(), show_progress_bar=True)\n",
    "    gmm = GaussianMixture(n_components=5, random_state=42)\n",
    "    df[\"cluster\"] = gmm.fit_predict(embeddings)\n",
    "    df.to_csv(\"clustered_papers.csv\", index=False)\n",
    "\n",
    "# === Step 5: Summarization ===\n",
    "def summarize_clusters():\n",
    "    df = pd.read_csv(\"clustered_papers.csv\")\n",
    "    grouped = df.groupby(\"cluster\")[\"clean_text\"].apply(list).to_dict()\n",
    "\n",
    "    def query_groq(prompt):\n",
    "        res = openai.ChatCompletion.create(\n",
    "            model=\"llama3-70b-8192\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a research assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=800\n",
    "        )\n",
    "        return res['choices'][0]['message']['content']\n",
    "\n",
    "    summaries = {}\n",
    "    for cluster, texts in grouped.items():\n",
    "        text_blob = \" \".join(texts)[:4000]\n",
    "        prompt = f\"Summarize the following research papers focusing on methodology and key findings:\\n{text_blob}\"\n",
    "        summaries[cluster] = query_groq(prompt)\n",
    "\n",
    "    with open(\"cluster_summaries.json\", \"w\") as f:\n",
    "        json.dump(summaries, f, indent=2)\n",
    "\n",
    "# === Step 6: Visualization ===\n",
    "def visualize_graph():\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Paper)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "    RETURN p.title AS title, k.name AS keyword LIMIT 100\n",
    "    \"\"\"\n",
    "    results = graph.run(query).data()\n",
    "    net = Network(notebook=True, cdn_resources='in_line')  # inline CDN to display in notebooks\n",
    "    for record in results:\n",
    "        net.add_node(record[\"title\"], label=record[\"title\"], shape=\"box\", color=\"lightblue\")\n",
    "        net.add_node(record[\"keyword\"], label=record[\"keyword\"], shape=\"dot\", color=\"orange\")\n",
    "        net.add_edge(record[\"title\"], record[\"keyword\"])\n",
    "    \n",
    "    # Write the HTML file with UTF-8 encoding to avoid Unicode errors\n",
    "    html_content = net.generate_html()\n",
    "    with open(\"graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_content)\n",
    "    print(\"graph.html\")\n",
    "\n",
    "\n",
    "# === Run Full Pipeline ===\n",
    "def run_all(query):\n",
    "    fetch_and_save_papers(query)\n",
    "    enrich_papers()\n",
    "    build_knowledge_graph()\n",
    "    cluster_texts()\n",
    "    summarize_clusters()\n",
    "    visualize_graph()\n",
    "    print(\"✅ Pipeline complete!\")\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import webbrowser\n",
    "\n",
    "def print_enriched_papers():\n",
    "    print(\"\\n📄 Top Enriched Papers with Keywords:\")\n",
    "    df = pd.read_csv(\"papers_enriched.csv\")\n",
    "    for idx, row in df.head(5).iterrows():\n",
    "        print(f\"\\n📘 {row['title']}\\n🗓️  Year: {row['year']}\")\n",
    "        keywords = eval(row[\"keywords\"]) if isinstance(row[\"keywords\"], str) else row[\"keywords\"]\n",
    "        print(f\"🔑 Keywords: {', '.join(keywords)}\")\n",
    "\n",
    "def print_clusters():\n",
    "    print(\"\\n🧠 Papers by Cluster:\")\n",
    "    df = pd.read_csv(\"clustered_papers.csv\")\n",
    "    for cluster in sorted(df['cluster'].unique()):\n",
    "        print(f\"\\n--- Cluster {cluster} ---\")\n",
    "        papers = df[df['cluster'] == cluster].head(3)\n",
    "        for _, row in papers.iterrows():\n",
    "            print(f\"• {row['title']}\")\n",
    "\n",
    "def print_summaries():\n",
    "    print(\"\\n📝 Cluster Summaries:\")\n",
    "    with open(\"cluster_summaries.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        summaries = json.load(f)\n",
    "    for cid, summary in summaries.items():\n",
    "        print(f\"\\n--- 🧩 Cluster {cid} Summary ---\\n{summary.strip()}\\n\")\n",
    "\n",
    "def run_all_and_display(query):\n",
    "    from pipeline import run_all  # your main logic module\n",
    "    run_all(query)\n",
    "\n",
    "    print_enriched_papers()\n",
    "    print_clusters()\n",
    "    print_summaries()\n",
    "\n",
    "    print(\"\\n🌐 Opening interactive graph...\")\n",
    "    webbrowser.open(\"graph.html\")\n",
    "\n",
    "# === ENTRY POINT ===\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"🔍 Enter your research topic: \")\n",
    "    run_all_and_display(user_query)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcbce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    query = input(\"🔍 Enter your research topic: \")\n",
    "    run_all(query)\n",
    "\n",
    "    # === Preview Results ===\n",
    "    import pandas as pd\n",
    "    import json\n",
    "\n",
    "    print(\"\\n📄 Enriched Papers:\")\n",
    "    enriched = pd.read_csv(\"papers_enriched.csv\")\n",
    "    print(enriched[[\"title\", \"keywords\", \"year\"]].head(5))\n",
    "\n",
    "    print(\"\\n🧠 Cluster Assignments:\")\n",
    "    clustered = pd.read_csv(\"clustered_papers.csv\")\n",
    "    print(clustered[[\"title\", \"cluster\"]].head(5))\n",
    "\n",
    "    print(\"\\n📝 Summaries:\")\n",
    "    with open(\"cluster_summaries.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        summaries = json.load(f)\n",
    "    for cid, summary in summaries.items():\n",
    "        print(f\"\\n--- Cluster {cid} ---\\n{summary[:500]}...\\n\")  # First 500 chars only\n",
    "\n",
    "    print(\"\\n🌐 Graph saved as 'graph.html'. Open it in your browser to explore.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319a7942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n",
      "c:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc187fd2b5b4c5aa28e02b80c95e49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 165\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    164\u001b[0m     user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔍 Enter your research topic: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 165\u001b[0m     \u001b[43mrun_all_and_display\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 156\u001b[0m, in \u001b[0;36mrun_all_and_display\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_all_and_display\u001b[39m(query):\n\u001b[1;32m--> 156\u001b[0m     \u001b[43mrun_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     print_enriched_papers()\n\u001b[0;32m    158\u001b[0m     print_clusters()\n",
      "Cell \u001b[1;32mIn[2], line 150\u001b[0m, in \u001b[0;36mrun_all\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m    148\u001b[0m build_knowledge_graph()\n\u001b[0;32m    149\u001b[0m cluster_texts()\n\u001b[1;32m--> 150\u001b[0m \u001b[43msummarize_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m visualize_graph()\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Pipeline complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 88\u001b[0m, in \u001b[0;36msummarize_clusters\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m     text_blob \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(texts)[:\u001b[38;5;241m4000\u001b[39m]  \u001b[38;5;66;03m# truncate to fit token limits\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead the following full research texts and provide a scholarly summary of their bibliometric insights including methods, findings, and trends:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext_blob\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 88\u001b[0m     summaries[cluster] \u001b[38;5;241m=\u001b[39m \u001b[43mquery_groq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster_summaries.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     91\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(summaries, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 73\u001b[0m, in \u001b[0;36msummarize_clusters.<locals>.query_groq\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_groq\u001b[39m(prompt):\n\u001b[1;32m---> 73\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemma2-9b-it\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a bibliometric research assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\kathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re, json, ast, torch, os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from keybert import KeyBERT\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import openai\n",
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "\n",
    "# === MODEL SETUP ===\n",
    "bert_encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "kw_model = KeyBERT(model='bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model.eval()\n",
    "\n",
    "# === GROQ API ===\n",
    "openai.api_key = \"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\"  # Replace with your actual Groq key\n",
    "openai.api_base = \"https://api.groq.com/openai/v1\"\n",
    "\n",
    "# === NEO4J SETUP ===\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"qwertyuiop\"))\n",
    "\n",
    "# === FETCHING ===\n",
    "def fetch_and_save_papers(query, max_results=10):\n",
    "    from fetch_arxiv import fetch_arxiv_papers\n",
    "    df = fetch_arxiv_papers(query, max_results=max_results)\n",
    "    df = df.dropna(subset=[\"full_text\"])\n",
    "    df.to_csv(\"papers3.csv\", index=False)\n",
    "\n",
    "# === ENRICH ===\n",
    "def enrich_papers():\n",
    "    df = pd.read_csv(\"papers3.csv\")\n",
    "    def clean_text(text):\n",
    "        text = str(text).lower()\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', text).strip()\n",
    "    df[\"clean_text\"] = df[\"full_text\"].fillna(\"\").apply(clean_text)\n",
    "    df[\"keywords\"] = df[\"clean_text\"].apply(lambda x: [kw[0] for kw in kw_model.extract_keywords(x, top_n=10)] if x else [])\n",
    "    df.to_csv(\"papers_enriched.csv\", index=False)\n",
    "\n",
    "# === GRAPH ===\n",
    "def build_knowledge_graph():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\")\n",
    "    graph.delete_all()\n",
    "    for _, row in df.iterrows():\n",
    "        paper_node = Node(\"Paper\", title=row[\"title\"], year=row[\"year\"], doi=row[\"doi\"])\n",
    "        graph.create(paper_node)\n",
    "        for author in ast.literal_eval(row[\"authors\"]):\n",
    "            author_node = Node(\"Author\", name=author)\n",
    "            graph.merge(author_node, \"Author\", \"name\")\n",
    "            graph.create(Relationship(author_node, \"WROTE\", paper_node))\n",
    "        for keyword in ast.literal_eval(row[\"keywords\"]):\n",
    "            keyword_node = Node(\"Keyword\", name=keyword)\n",
    "            graph.merge(keyword_node, \"Keyword\", \"name\")\n",
    "            graph.create(Relationship(paper_node, \"HAS_KEYWORD\", keyword_node))\n",
    "\n",
    "# === CLUSTER ===\n",
    "def cluster_texts():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\").dropna(subset=[\"clean_text\"])\n",
    "    embeddings = bert_encoder.encode(df[\"clean_text\"].tolist(), show_progress_bar=True)\n",
    "    gmm = GaussianMixture(n_components=5, random_state=42)\n",
    "    df[\"cluster\"] = gmm.fit_predict(embeddings)\n",
    "    df.to_csv(\"clustered_papers.csv\", index=False)\n",
    "\n",
    "# === SUMMARIZE ===\n",
    "def summarize_clusters():\n",
    "    df = pd.read_csv(\"clustered_papers.csv\")\n",
    "    grouped = df.groupby(\"cluster\")[\"clean_text\"].apply(list).to_dict()\n",
    "\n",
    "    def query_groq(prompt):\n",
    "        res = openai.ChatCompletion.create(\n",
    "            model=\"gemma2-9b-it\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a bibliometric research assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=800\n",
    "        )\n",
    "        return res['choices'][0]['message']['content']\n",
    "\n",
    "    summaries = {}\n",
    "    for cluster, texts in grouped.items():\n",
    "        text_blob = \" \".join(texts)[:4000]  # truncate to fit token limits\n",
    "        prompt = f\"Read the following full research texts and provide a scholarly summary of their bibliometric insights including methods, findings, and trends:\\n{text_blob}\"\n",
    "        summaries[cluster] = query_groq(prompt)\n",
    "\n",
    "    with open(\"cluster_summaries.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summaries, f, indent=2)\n",
    "\n",
    "# === VISUALIZE ===\n",
    "def visualize_graph():\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Paper)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "    RETURN p.title AS title, k.name AS keyword LIMIT 100\n",
    "    \"\"\"\n",
    "    results = graph.run(query).data()\n",
    "    net = Network(notebook=False, cdn_resources='in_line')\n",
    "    for record in results:\n",
    "        net.add_node(record[\"title\"], label=record[\"title\"], shape=\"box\", color=\"lightblue\")\n",
    "        net.add_node(record[\"keyword\"], label=record[\"keyword\"], shape=\"dot\", color=\"orange\")\n",
    "        net.add_edge(record[\"title\"], record[\"keyword\"])\n",
    "\n",
    "    html_content = net.generate_html()\n",
    "    with open(\"graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_content)\n",
    "    print(\"\\n✅ Interactive graph saved as 'graph.html'.\")\n",
    "\n",
    "# === FINAL DISPLAY ===\n",
    "def print_enriched_papers():\n",
    "    print(\"\\n📄 Top Enriched Papers with Keywords:\")\n",
    "    df = pd.read_csv(\"papers_enriched.csv\")\n",
    "    for idx, row in df.head(5).iterrows():\n",
    "        print(f\"\\n📘 {row['title']}\\n🗓️ Year: {row['year']}\")\n",
    "        keywords = eval(row[\"keywords\"]) if isinstance(row[\"keywords\"], str) else row[\"keywords\"]\n",
    "        print(f\"🔑 Keywords: {', '.join(keywords)}\")\n",
    "\n",
    "def print_clusters():\n",
    "    print(\"\\n🧠 Papers by Cluster:\")\n",
    "    df = pd.read_csv(\"clustered_papers.csv\")\n",
    "    for cluster in sorted(df['cluster'].unique()):\n",
    "        print(f\"\\n--- Cluster {cluster} ---\")\n",
    "        papers = df[df['cluster'] == cluster].head(3)\n",
    "        for _, row in papers.iterrows():\n",
    "            print(f\"• {row['title']}\")\n",
    "\n",
    "def print_summaries():\n",
    "    print(\"\\n📝 Cluster Summaries:\")\n",
    "    with open(\"cluster_summaries.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        summaries = json.load(f)\n",
    "    for cid, summary in summaries.items():\n",
    "        print(f\"\\n--- 🧩 Cluster {cid} Summary ---\\n{summary.strip()}\\n\")\n",
    "\n",
    "def print_cluster_summaries():\n",
    "    print(\"\\n📚 Bibliometric Summaries by Cluster:\")\n",
    "    with open(\"cluster_summaries.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        summaries = json.load(f)\n",
    "        for cluster, summary in summaries.items():\n",
    "            print(f\"\\n🧠 Cluster {cluster}:\")\n",
    "            print(summary)\n",
    "\n",
    "# === PIPELINE ===\n",
    "def run_all(query):\n",
    "    fetch_and_save_papers(query)\n",
    "    enrich_papers()\n",
    "    build_knowledge_graph()\n",
    "    cluster_texts()\n",
    "    summarize_clusters()\n",
    "    visualize_graph()\n",
    "    print(\"✅ Pipeline complete.\")\n",
    "\n",
    "# === MAIN RUNNER ===\n",
    "def run_all_and_display(query):\n",
    "    run_all(query)\n",
    "    print_enriched_papers()\n",
    "    print_clusters()\n",
    "    print_summaries()\n",
    "    print_cluster_summaries() \n",
    "    webbrowser.open(\"graph.html\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"🔍 Enter your research topic: \")\n",
    "    run_all_and_display(user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ee44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⌛ Running full pipeline in background; showing cached preview immediately...\n",
      "\n",
      "\n",
      "⏳ Quick Preview - Sample Papers with Keywords:\n",
      "• Implications of Computer Vision Driven Assistive Technologies Towards\n",
      "  Individuals with Visual Impairment | Keywords: 1arxiv190507844v1, abs180907842, abs181110670, underrepresentation, obtrusiveness, homemonitoring, preprocessing, caregivers, eavesdropping, mitigating\n",
      "• Second Croatian Computer Vision Workshop (CCVW 2013) | Keywords: \n",
      "• Multiband NFC for High-Throughput Wireless Computer Vision Sensor\n",
      "  Network | Keywords: arxiv160302345, arxiv170505983, 09212020027fudaneducn, httpswwwfccgov, floifloqmixerbuffer, bluetoothwifi, supercomputing, energyefficient, connectioncoupling, highthroughput\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a4dffd11b14c9390438eeeddf7ce87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Interactive graph saved as 'graph.html'.\n",
      "✅ Pipeline complete.\n",
      "\n",
      "📄 Top Enriched Papers with Keywords:\n",
      "\n",
      "📘 The Xi-transform for conformally flat space-time\n",
      "🗓️ Year: 2006\n",
      "🔑 Keywords: letfghdenoteasmoothfunctionofvariables, sectioneighteenweusetwistorvariables, herejcdjdcandjcdjdcgeneratetheindependentfactorsof, gissymmetricandinvertibleandleftandrightinvariant, multiplyingbyasuitablepositiveconstantdependingonl, cauchyriemannstructureofthenulltwistorspace8, weidentifythecommutativesubalgebra, applicationsofthegeometryofso8spinorstolaplaces, niangr2tofalltwodimensionalcomplexsubspacesof, theliealgebracommutatorsareeasilycom\n",
      "\n",
      "📘 Multiple basic hypergeometric transformation formulas arising from the\n",
      "  balanced duality transformation\n",
      "🗓️ Year: 2013\n",
      "🔑 Keywords: xinvextendsinglevextendsinglevextendsingleabcdqnfaq1nefqparenrightbigg, xinvextendsinglevextendsinglevextendsingleacdeffqnqnqqparenrightbigg, xinvextendsinglevextendsinglevextendsingleacdbeqa2qm2, xinvextendsinglevextendsinglevextendsingleacqnqaqn1, xinvextendsinglevextendsinglevextendsingleacdeqnqa2qn2, xinvextendsinglevextendsinglevextendsinglesukmvkmqzparenrightbigg, xinvextendsinglevextendsinglevextendsingleacdqneqa2qn2, de2q1abceadeq1abcebecqnqdqnbracketrightbig, 2n6w2n5bracketleftbig, bq1man2n1bracketleftbiggqmbcaixin\n",
      "\n",
      "📘 The Fourier and Hilbert transforms under the Bargmann transform\n",
      "🗓️ Year: 2016\n",
      "🔑 Keywords: 0xzexz2dx2eiintegraldisplay0, rxzeaibxz2dxeaibxz2vextendsinglevextendsinglevextendsinglevextendsingle, fractionalhilberttransformwavelettransform, cfwee2iw22dwintegraldisplay, bargmanntransformfockspacefractionalfouriertransf, l2rxkbetheorthogonalprojection, hatwidestabez2dzvextendsinglevextendsinglevextendsinglevextendsinglemax, primary30h20secondary42a3844a15, moregenerallythenotionoffractionalfouriertransform, 2parenrightbiggvextendsinglevextendsinglevextendsinglevextendsingle2\n",
      "\n",
      "📘 Identities for the Ln-transform, the L2n-transform and the P2n transform\n",
      "  and their applications\n",
      "🗓️ Year: 2014\n",
      "🔑 Keywords: l2transformwiththefollowingformulas, lntransformprovidedthattheintegralsinvolved, wededucetheassertion223ofexample22, l2ntransformandthe, p4transformandtheirapplicationsintegraltrans, widderdvatransformrelatedtothepoissonintegra, p2ntransformandthe, l2nlnfxuyintegraldisplay, 0x2n1fxp2nguxdxintegraldisplay, lnl2nfxuyintegraldisplay\n",
      "\n",
      "📘 Towards Lightweight Transformer via Group-wise Transformation for\n",
      "  Vision-and-Language Tasks\n",
      "🗓️ Year: 2022\n",
      "🔑 Keywords: lwtransformer1, httpsgithubcomluogen1996lwtransformerfor, transformerbased, swintransformer, lwtransformer, visionandlanguage, garyhuangtencentcom, luogenstuxmueducn, xssunxmueducn, zhouyiyixmueducn\n",
      "\n",
      "🧠 Papers by Cluster:\n",
      "\n",
      "--- Cluster 0 ---\n",
      "• Multiple basic hypergeometric transformation formulas arising from the\n",
      "  balanced duality transformation\n",
      "• Identities for the Ln-transform, the L2n-transform and the P2n transform\n",
      "  and their applications\n",
      "• Towards Lightweight Transformer via Group-wise Transformation for\n",
      "  Vision-and-Language Tasks\n",
      "\n",
      "--- Cluster 1 ---\n",
      "• The Fourier and Hilbert transforms under the Bargmann transform\n",
      "• Quantum Time-Frequency Transforms\n",
      "• A mathematical survey on Fourier type integral transform and their\n",
      "  offshoots: windowed Fourier transform, wavelet transform and Stockwell\n",
      "  transform\n",
      "\n",
      "--- Cluster 2 ---\n",
      "• The Xi-transform for conformally flat space-time\n",
      "\n",
      "--- Cluster 3 ---\n",
      "• The typical measure preserving transformation is not an interval\n",
      "  exchange transformation\n",
      "\n",
      "--- Cluster 4 ---\n",
      "• The nonlocal Darboux transformation of the stationary axially symmetric\n",
      "  Schrödinger equation and generalized Moutard transformation\n",
      "\n",
      "📝 Cluster Summaries:\n",
      "\n",
      "--- 🧩 Cluster 0 Summary ---\n",
      "This research paper explores multiple basic hypergeometric transformation formulas derived from the balanced duality transformation. \n",
      "\n",
      "**Methods:**\n",
      "\n",
      "The authors leverage the symmetry inherent in the balanced duality transformation to derive new formulas with varying dimensions. They achieve this by:\n",
      "\n",
      "* Taking specific limits of the balanced duality transformation.\n",
      "* Combining existing transformations through strategic manipulations.\n",
      "\n",
      "They also utilize techniques from the theory of Macdonald polynomials and Macdonald's q-difference operators.\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "The paper presents several key findings:\n",
      "\n",
      "* **New Transformation Formulas:**  The authors derive new transformation formulas for an-basic hypergeometric series. These formulas generalize existing transformations like Watson-Sears and the 8w7 transformation.\n",
      "* **Generalizations of Bailey's Transformation:** The balanced duality transformation formula is shown to generalize Bailey's transformation for terminating balanced and very well-poised 9f8 series.\n",
      "* **Multiple Hypergeometric Summations and Transformations:**  The research builds upon previous work (Kajihara, 2013) by exploring multiple hypergeometric summations and transformations derived from the multiple Euler transformation formula.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "The paper highlights several key trends in the field of hypergeometric series research:\n",
      "\n",
      "* **Emphasis on Symmetry:** Researchers are increasingly utilizing symmetry properties of transformation formulas to derive new identities.\n",
      "* **Generalizations and Extensions:**  There is a strong focus on generalizing existing transformations to encompass a wider range of parameters and series types.\n",
      "* **Interplay with Other Fields:** Techniques from areas like Macdonald polynomials and q-difference operators are being applied to advance the understanding of hypergeometric series.\n",
      "\n",
      "\n",
      "**Overall, this paper makes significant contributions to the field of hypergeometric series by deriving new transformation formulas, providing generalizations of existing results, and showcasing the power of symmetry and advanced mathematical techniques in this area.**\n",
      "\n",
      "\n",
      "--- 🧩 Cluster 1 Summary ---\n",
      "This research paper, \"The Fourier and Hilbert Transforms Under the Bargmann Transform,\" by Xingtang Dong and Ke Zhu, explores the action of the Bargmann transform on several classical integral operators defined on the Hilbert space L₂(ℝ). \n",
      "\n",
      "**Methods:**\n",
      "\n",
      "The authors primarily utilize the Bargmann transform, a unitary operator mapping L₂(ℝ) onto the Fock space F₂. They analyze its effect on three specific integral operators:\n",
      "\n",
      "* **Fractional Fourier Transform:**  A generalization of the standard Fourier Transform.\n",
      "* **Fractional Hilbert Transform:** A generalization of the Hilbert Transform.\n",
      "* **Wavelet Transform:** A multi-resolution analysis tool.\n",
      "\n",
      "The core of their approach involves expressing these operators in their unitarily equivalent forms within F₂. This often leads to simpler representations, revealing interesting properties and potential new research directions.\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "While the paper doesn't explicitly state concrete findings, it highlights the following:\n",
      "\n",
      "* **Simplicity Through Transformation:** The Bargmann transform can simplify the representation of classical integral operators in the Fock space. This suggests that studying these operators within this framework might offer new insights.\n",
      "* **Revealing Properties:** The transformed forms of the operators might reveal hidden properties or relationships that are not readily apparent in their original L₂(ℝ) representations.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "The paper indicates a growing interest in exploring the interplay between the Bargmann transform and classical integral operators.  \n",
      "\n",
      "* **Unitary Equivalence:** The focus on unitary equivalence suggests a trend towards using the Fock space as a platform for investigating and comparing different integral operators.\n",
      "* **New Perspectives:** The authors aim to generate new interest in the Bargmann transform and its applications, potentially leading to further research exploring its potential in diverse areas like function analysis, mathematical physics, and engineering.\n",
      "\n",
      "\n",
      "\n",
      "Overall, the paper emphasizes the value of the Bargmann transform as a tool for revealing new perspectives and properties of classical integral operators within the context of the Fock space. It encourages further exploration of this approach for gaining deeper understanding in related fields.\n",
      "\n",
      "\n",
      "--- 🧩 Cluster 2 Summary ---\n",
      "This research paper, \"The Transform for Conformal At Spacetime,\" explores a novel spinor transform naturally arising in Einstein's General Relativity. \n",
      "\n",
      "**Methods:**\n",
      "\n",
      "The authors primarily employ mathematical techniques from differential geometry and Lie theory. They leverage the concept of twistor functions, which are functions on the cospin bundle of a spacetime, and analyze the transform's action on these functions.  The paper also utilizes the triality theory of Elie Cartan, specifically focusing on its application to spinors associated with the group O(4,4).\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "The key finding is the identification of three distinct versions of the transform, denoted as 1, 2, and 3, each operating on twistor functions in different ways. \n",
      "\n",
      "* **Transform 1:** A two-variable transform defined on the Lie group SU(2,C).\n",
      "* **Transform 2:** A transform operating on the space of null split octaves.\n",
      "* **Transform 3:**  A transform linked to the triality theory, involving three eight-dimensional real vector spaces with a specific dot product structure.\n",
      "\n",
      "The paper demonstrates that these seemingly disparate transformations are interconnected, highlighting the deep underlying symmetries within General Relativity.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "The research suggests a trend towards a more unified understanding of spinor transforms in General Relativity. The paper's exploration of the triality theory and its application to spinors points towards a potential for further connections and insights into the geometric structure of spacetime.\n",
      "\n",
      "**Limitations:**\n",
      "\n",
      "The paper focuses primarily on the mathematical properties of the transform and its relation to other known transformations. It does not explicitly discuss the physical implications or applications of this transform in understanding gravitational phenomena.\n",
      "\n",
      "\n",
      "Further research could explore the physical consequences of this transform and its potential role in areas such as black hole physics or quantum gravity.\n",
      "\n",
      "\n",
      "--- 🧩 Cluster 3 Summary ---\n",
      "Unfortunately, I cannot provide a scholarly summary of the bibliometric insights from the provided text. \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **Lack of Bibliometric Data:** The text you provided focuses on mathematical definitions and concepts related to measure-preserving dynamical systems and transformations. It does not contain any bibliometric data such as citation counts, author co-occurrences, keyword analysis, or other metrics used in bibliometric research.\n",
      "* **Focus on Mathematical Concepts:** The excerpt delves into the theoretical aspects of measure-preserving transformations, exploring the notion of isomorphism and its implications. This is a purely mathematical discussion and does not involve the analysis of research literature.\n",
      "\n",
      "**To perform bibliometric analysis, I would need data about:**\n",
      "\n",
      "* **Publications:** A list of research articles, books, or other relevant publications related to the topic.\n",
      "* **Bibliographic Information:** Details such as author names, publication dates, titles, journals, and keywords.\n",
      "* **Citation Data:** Information about how often each publication is cited by other works.\n",
      "\n",
      "With this data, I could then apply various bibliometric methods to uncover trends, influential authors, key concepts, and other insights within the field.\n",
      "\n",
      "\n",
      "Let me know if you have access to bibliometric data on measure-preserving transformations, and I'd be happy to help you analyze it!\n",
      "\n",
      "\n",
      "--- 🧩 Cluster 4 Summary ---\n",
      "This paper explores the nonlocal Darboux transformation of the stationary axially symmetric Schrödinger equation and its connection to the generalized Moutard transformation. \n",
      "\n",
      "**Methods:**\n",
      "\n",
      "* **Mathematical Formulation:** The authors start by expressing the stationary Schrödinger equation in cylindrical coordinates and then utilize a substitution to relate it to the Fokker-Planck equation. This allows them to derive a conservation law form of the equation.\n",
      "* **Darboux Transformation:** They apply the Darboux transformation to the resulting system of equations, aiming to find new solutions to the Schrödinger equation with modified potentials. \n",
      "* **Generalized Moutard Transformation:** The paper focuses on a specific case of the Darboux transformation that leads to a generalization of the Moutard transformation, a known technique for finding solutions to the two-dimensional Schrödinger equation.\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "* **Connection between Darboux and Moutard Transformations:** The authors demonstrate a relationship between the nonlocal Darboux transformation and the generalized Moutard transformation for the axially symmetric Schrödinger equation.\n",
      "* **New Solutions:** By applying the generalized Moutard transformation, they obtain new exact solutions for the stationary axially symmetric Schrödinger equation with various two-dimensional potentials.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "* **Nonlocal Transformations:** The paper highlights the importance of nonlocal transformations in finding solutions to partial differential equations like the Schrödinger equation.\n",
      "* **Applications in Physics:** The authors emphasize the potential applications of these findings in areas like acoustic tomography and multidimensional inverse scattering theory.\n",
      "\n",
      "\n",
      "**Overall:** The paper presents a novel approach to finding solutions to the stationary axially symmetric Schrödinger equation by leveraging the connection between the nonlocal Darboux transformation and the generalized Moutard transformation. It contributes to the understanding of these transformations and their potential applications in various physical problems.\n",
      "\n",
      "\n",
      "📚 Bibliometric Summaries by Cluster:\n",
      "\n",
      "🧠 Cluster 0:\n",
      "This research paper explores multiple basic hypergeometric transformation formulas derived from the balanced duality transformation. \n",
      "\n",
      "**Methods:**\n",
      "\n",
      "The authors leverage the symmetry inherent in the balanced duality transformation to derive new formulas with varying dimensions. They achieve this by:\n",
      "\n",
      "* Taking specific limits of the balanced duality transformation.\n",
      "* Combining existing transformations through strategic manipulations.\n",
      "\n",
      "They also utilize techniques from the theory of Macdonald polynomials and Macdonald's q-difference operators.\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "The paper presents several key findings:\n",
      "\n",
      "* **New Transformation Formulas:**  The authors derive new transformation formulas for an-basic hypergeometric series. These formulas generalize existing transformations like Watson-Sears and the 8w7 transformation.\n",
      "* **Generalizations of Bailey's Transformation:** The balanced duality transformation formula is shown to generalize Bailey's transformation for terminating balanced and very well-poised 9f8 series.\n",
      "* **Multiple Hypergeometric Summations and Transformations:**  The research builds upon previous work (Kajihara, 2013) by exploring multiple hypergeometric summations and transformations derived from the multiple Euler transformation formula.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "The paper highlights several key trends in the field of hypergeometric series research:\n",
      "\n",
      "* **Emphasis on Symmetry:** Researchers are increasingly utilizing symmetry properties of transformation formulas to derive new identities.\n",
      "* **Generalizations and Extensions:**  There is a strong focus on generalizing existing transformations to encompass a wider range of parameters and series types.\n",
      "* **Interplay with Other Fields:** Techniques from areas like Macdonald polynomials and q-difference operators are being applied to advance the understanding of hypergeometric series.\n",
      "\n",
      "\n",
      "**Overall, this paper makes significant contributions to the field of hypergeometric series by deriving new transformation formulas, providing generalizations of existing results, and showcasing the power of symmetry and advanced mathematical techniques in this area.**\n",
      "\n",
      "\n",
      "🧠 Cluster 1:\n",
      "This research paper, \"The Fourier and Hilbert Transforms Under the Bargmann Transform,\" by Xingtang Dong and Ke Zhu, explores the action of the Bargmann transform on several classical integral operators defined on the Hilbert space L₂(ℝ). \n",
      "\n",
      "**Methods:**\n",
      "\n",
      "The authors primarily utilize the Bargmann transform, a unitary operator mapping L₂(ℝ) onto the Fock space F₂. They analyze its effect on three specific integral operators:\n",
      "\n",
      "* **Fractional Fourier Transform:**  A generalization of the standard Fourier Transform.\n",
      "* **Fractional Hilbert Transform:** A generalization of the Hilbert Transform.\n",
      "* **Wavelet Transform:** A multi-resolution analysis tool.\n",
      "\n",
      "The core of their approach involves expressing these operators in their unitarily equivalent forms within F₂. This often leads to simpler representations, revealing interesting properties and potential new research directions.\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "While the paper doesn't explicitly state concrete findings, it highlights the following:\n",
      "\n",
      "* **Simplicity Through Transformation:** The Bargmann transform can simplify the representation of classical integral operators in the Fock space. This suggests that studying these operators within this framework might offer new insights.\n",
      "* **Revealing Properties:** The transformed forms of the operators might reveal hidden properties or relationships that are not readily apparent in their original L₂(ℝ) representations.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "The paper indicates a growing interest in exploring the interplay between the Bargmann transform and classical integral operators.  \n",
      "\n",
      "* **Unitary Equivalence:** The focus on unitary equivalence suggests a trend towards using the Fock space as a platform for investigating and comparing different integral operators.\n",
      "* **New Perspectives:** The authors aim to generate new interest in the Bargmann transform and its applications, potentially leading to further research exploring its potential in diverse areas like function analysis, mathematical physics, and engineering.\n",
      "\n",
      "\n",
      "\n",
      "Overall, the paper emphasizes the value of the Bargmann transform as a tool for revealing new perspectives and properties of classical integral operators within the context of the Fock space. It encourages further exploration of this approach for gaining deeper understanding in related fields.\n",
      "\n",
      "\n",
      "🧠 Cluster 2:\n",
      "This research paper, \"The Transform for Conformal At Spacetime,\" explores a novel spinor transform naturally arising in Einstein's General Relativity. \n",
      "\n",
      "**Methods:**\n",
      "\n",
      "The authors primarily employ mathematical techniques from differential geometry and Lie theory. They leverage the concept of twistor functions, which are functions on the cospin bundle of a spacetime, and analyze the transform's action on these functions.  The paper also utilizes the triality theory of Elie Cartan, specifically focusing on its application to spinors associated with the group O(4,4).\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "The key finding is the identification of three distinct versions of the transform, denoted as 1, 2, and 3, each operating on twistor functions in different ways. \n",
      "\n",
      "* **Transform 1:** A two-variable transform defined on the Lie group SU(2,C).\n",
      "* **Transform 2:** A transform operating on the space of null split octaves.\n",
      "* **Transform 3:**  A transform linked to the triality theory, involving three eight-dimensional real vector spaces with a specific dot product structure.\n",
      "\n",
      "The paper demonstrates that these seemingly disparate transformations are interconnected, highlighting the deep underlying symmetries within General Relativity.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "The research suggests a trend towards a more unified understanding of spinor transforms in General Relativity. The paper's exploration of the triality theory and its application to spinors points towards a potential for further connections and insights into the geometric structure of spacetime.\n",
      "\n",
      "**Limitations:**\n",
      "\n",
      "The paper focuses primarily on the mathematical properties of the transform and its relation to other known transformations. It does not explicitly discuss the physical implications or applications of this transform in understanding gravitational phenomena.\n",
      "\n",
      "\n",
      "Further research could explore the physical consequences of this transform and its potential role in areas such as black hole physics or quantum gravity. \n",
      "\n",
      "\n",
      "🧠 Cluster 3:\n",
      "Unfortunately, I cannot provide a scholarly summary of the bibliometric insights from the provided text. \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **Lack of Bibliometric Data:** The text you provided focuses on mathematical definitions and concepts related to measure-preserving dynamical systems and transformations. It does not contain any bibliometric data such as citation counts, author co-occurrences, keyword analysis, or other metrics used in bibliometric research.\n",
      "* **Focus on Mathematical Concepts:** The excerpt delves into the theoretical aspects of measure-preserving transformations, exploring the notion of isomorphism and its implications. This is a purely mathematical discussion and does not involve the analysis of research literature.\n",
      "\n",
      "**To perform bibliometric analysis, I would need data about:**\n",
      "\n",
      "* **Publications:** A list of research articles, books, or other relevant publications related to the topic.\n",
      "* **Bibliographic Information:** Details such as author names, publication dates, titles, journals, and keywords.\n",
      "* **Citation Data:** Information about how often each publication is cited by other works.\n",
      "\n",
      "With this data, I could then apply various bibliometric methods to uncover trends, influential authors, key concepts, and other insights within the field.\n",
      "\n",
      "\n",
      "Let me know if you have access to bibliometric data on measure-preserving transformations, and I'd be happy to help you analyze it! \n",
      "\n",
      "\n",
      "🧠 Cluster 4:\n",
      "This paper explores the nonlocal Darboux transformation of the stationary axially symmetric Schrödinger equation and its connection to the generalized Moutard transformation. \n",
      "\n",
      "**Methods:**\n",
      "\n",
      "* **Mathematical Formulation:** The authors start by expressing the stationary Schrödinger equation in cylindrical coordinates and then utilize a substitution to relate it to the Fokker-Planck equation. This allows them to derive a conservation law form of the equation.\n",
      "* **Darboux Transformation:** They apply the Darboux transformation to the resulting system of equations, aiming to find new solutions to the Schrödinger equation with modified potentials. \n",
      "* **Generalized Moutard Transformation:** The paper focuses on a specific case of the Darboux transformation that leads to a generalization of the Moutard transformation, a known technique for finding solutions to the two-dimensional Schrödinger equation.\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "* **Connection between Darboux and Moutard Transformations:** The authors demonstrate a relationship between the nonlocal Darboux transformation and the generalized Moutard transformation for the axially symmetric Schrödinger equation.\n",
      "* **New Solutions:** By applying the generalized Moutard transformation, they obtain new exact solutions for the stationary axially symmetric Schrödinger equation with various two-dimensional potentials.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "* **Nonlocal Transformations:** The paper highlights the importance of nonlocal transformations in finding solutions to partial differential equations like the Schrödinger equation.\n",
      "* **Applications in Physics:** The authors emphasize the potential applications of these findings in areas like acoustic tomography and multidimensional inverse scattering theory.\n",
      "\n",
      "\n",
      "**Overall:** The paper presents a novel approach to finding solutions to the stationary axially symmetric Schrödinger equation by leveraging the connection between the nonlocal Darboux transformation and the generalized Moutard transformation. It contributes to the understanding of these transformations and their potential applications in various physical problems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re, json, ast, torch, os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from keybert import KeyBERT\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import openai\n",
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# === MODEL SETUP ===\n",
    "bert_encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "kw_model = KeyBERT(model='bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model.eval()\n",
    "\n",
    "# === GROQ API ===\n",
    "openai.api_key = \"\"  # Replace with your actual Groq key\n",
    "openai.api_base = \"https://api.groq.com/openai/v1\"\n",
    "\n",
    "# === NEO4J SETUP ===\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"qwertyuiop\"))\n",
    "\n",
    "# === FETCHING ===\n",
    "def fetch_and_save_papers(query, max_results=10):\n",
    "    from fetch_arxiv import fetch_arxiv_papers\n",
    "    df = fetch_arxiv_papers(query, max_results=max_results)\n",
    "    df = df.dropna(subset=[\"full_text\"])\n",
    "    df.to_csv(\"papers3.csv\", index=False)\n",
    "\n",
    "# === ENRICH ===\n",
    "def enrich_papers():\n",
    "    df = pd.read_csv(\"papers3.csv\")\n",
    "    def clean_text(text):\n",
    "        text = str(text).lower()\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', text).strip()\n",
    "    df[\"clean_text\"] = df[\"full_text\"].fillna(\"\").apply(clean_text)\n",
    "    df[\"keywords\"] = df[\"clean_text\"].apply(lambda x: [kw[0] for kw in kw_model.extract_keywords(x, top_n=10)] if x else [])\n",
    "    df.to_csv(\"papers_enriched.csv\", index=False)\n",
    "\n",
    "# === GRAPH ===\n",
    "def build_knowledge_graph():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\")\n",
    "    graph.delete_all()\n",
    "    for _, row in df.iterrows():\n",
    "        paper_node = Node(\"Paper\", title=row[\"title\"], year=row[\"year\"], doi=row[\"doi\"])\n",
    "        graph.create(paper_node)\n",
    "        for author in ast.literal_eval(row[\"authors\"]):\n",
    "            author_node = Node(\"Author\", name=author)\n",
    "            graph.merge(author_node, \"Author\", \"name\")\n",
    "            graph.create(Relationship(author_node, \"WROTE\", paper_node))\n",
    "        for keyword in ast.literal_eval(row[\"keywords\"]):\n",
    "            keyword_node = Node(\"Keyword\", name=keyword)\n",
    "            graph.merge(keyword_node, \"Keyword\", \"name\")\n",
    "            graph.create(Relationship(paper_node, \"HAS_KEYWORD\", keyword_node))\n",
    "\n",
    "# === CLUSTER ===\n",
    "def cluster_texts():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\").dropna(subset=[\"clean_text\"])\n",
    "    embeddings = bert_encoder.encode(df[\"clean_text\"].tolist(), show_progress_bar=True)\n",
    "    gmm = GaussianMixture(n_components=5, random_state=42)\n",
    "    df[\"cluster\"] = gmm.fit_predict(embeddings)\n",
    "    df.to_csv(\"clustered_papers.csv\", index=False)\n",
    "\n",
    "# === SUMMARIZE ===\n",
    "def summarize_clusters():\n",
    "    df = pd.read_csv(\"clustered_papers.csv\")\n",
    "    grouped = df.groupby(\"cluster\")[\"clean_text\"].apply(list).to_dict()\n",
    "\n",
    "    def query_groq(prompt):\n",
    "        res = openai.ChatCompletion.create(\n",
    "            model=\"gemma2-9b-it\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a bibliometric research assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=800\n",
    "        )\n",
    "        return res['choices'][0]['message']['content']\n",
    "\n",
    "    summaries = {}\n",
    "    for cluster, texts in grouped.items():\n",
    "        text_blob = \" \".join(texts)[:4000]  # truncate to fit token limits\n",
    "        prompt = f\"Read the following full research texts and provide a scholarly summary of their bibliometric insights including methods, findings, and trends:\\n{text_blob}\"\n",
    "        summaries[cluster] = query_groq(prompt)\n",
    "\n",
    "    with open(\"cluster_summaries.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summaries, f, indent=2)\n",
    "\n",
    "# === VISUALIZE ===\n",
    "def visualize_graph():\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Paper)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "    RETURN p.title AS title, k.name AS keyword LIMIT 100\n",
    "    \"\"\"\n",
    "    results = graph.run(query).data()\n",
    "    net = Network(notebook=False, cdn_resources='in_line')\n",
    "    for record in results:\n",
    "        net.add_node(record[\"title\"], label=record[\"title\"], shape=\"box\", color=\"lightblue\")\n",
    "        net.add_node(record[\"keyword\"], label=record[\"keyword\"], shape=\"dot\", color=\"orange\")\n",
    "        net.add_edge(record[\"title\"], record[\"keyword\"])\n",
    "\n",
    "    html_content = net.generate_html()\n",
    "    with open(\"graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_content)\n",
    "    print(\"\\n✅ Interactive graph saved as 'graph.html'.\")\n",
    "\n",
    "# === PRINT FUNCTIONS ===\n",
    "def print_enriched_papers():\n",
    "    print(\"\\n📄 Top Enriched Papers with Keywords:\")\n",
    "    try:\n",
    "        df = pd.read_csv(\"papers_enriched.csv\")\n",
    "        for idx, row in df.head(5).iterrows():\n",
    "            print(f\"\\n📘 {row['title']}\\n🗓️ Year: {row['year']}\")\n",
    "            keywords = eval(row[\"keywords\"]) if isinstance(row[\"keywords\"], str) else row[\"keywords\"]\n",
    "            print(f\"🔑 Keywords: {', '.join(keywords)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No enriched papers found yet.\")\n",
    "\n",
    "def print_clusters():\n",
    "    print(\"\\n🧠 Papers by Cluster:\")\n",
    "    try:\n",
    "        df = pd.read_csv(\"clustered_papers.csv\")\n",
    "        for cluster in sorted(df['cluster'].unique()):\n",
    "            print(f\"\\n--- Cluster {cluster} ---\")\n",
    "            papers = df[df['cluster'] == cluster].head(3)\n",
    "            for _, row in papers.iterrows():\n",
    "                print(f\"• {row['title']}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No clustered papers found yet.\")\n",
    "\n",
    "def print_summaries():\n",
    "    print(\"\\n📝 Cluster Summaries:\")\n",
    "    try:\n",
    "        with open(\"cluster_summaries.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            summaries = json.load(f)\n",
    "        for cid, summary in summaries.items():\n",
    "            print(f\"\\n--- 🧩 Cluster {cid} Summary ---\\n{summary.strip()}\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No cluster summaries found yet.\")\n",
    "\n",
    "def print_cluster_summaries():\n",
    "    print(\"\\n📚 Bibliometric Summaries by Cluster:\")\n",
    "    try:\n",
    "        with open(\"cluster_summaries.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            summaries = json.load(f)\n",
    "            for cluster, summary in summaries.items():\n",
    "                print(f\"\\n🧠 Cluster {cluster}:\")\n",
    "                print(summary)\n",
    "    except FileNotFoundError:\n",
    "        print(\"No cluster summaries found yet.\")\n",
    "\n",
    "# === QUICK PREVIEW FUNCTION ===\n",
    "def quick_preview():\n",
    "    print(\"\\n⏳ Quick Preview - Sample Papers with Keywords:\")\n",
    "    try:\n",
    "        df = pd.read_csv(\"papers_enriched.csv\").head(3)\n",
    "        for _, row in df.iterrows():\n",
    "            keywords = eval(row[\"keywords\"]) if isinstance(row[\"keywords\"], str) else row[\"keywords\"]\n",
    "            print(f\"• {row['title']} | Keywords: {', '.join(keywords)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No cached enriched papers available yet. Running full pipeline...\")\n",
    "\n",
    "# === PIPELINE ===\n",
    "def run_all(query):\n",
    "    fetch_and_save_papers(query)\n",
    "    enrich_papers()\n",
    "    build_knowledge_graph()\n",
    "    cluster_texts()\n",
    "    summarize_clusters()\n",
    "    visualize_graph()\n",
    "    print(\"✅ Pipeline complete.\")\n",
    "\n",
    "def run_all_and_display(query):\n",
    "    run_all(query)\n",
    "    print_enriched_papers()\n",
    "    print_clusters()\n",
    "    print_summaries()\n",
    "    print_cluster_summaries() \n",
    "    webbrowser.open(\"graph.html\")\n",
    "\n",
    "# === ASYNC RUNNER ===\n",
    "def run_pipeline_async(query):\n",
    "    thread = threading.Thread(target=run_all_and_display, args=(query,), daemon=True)\n",
    "    thread.start()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"🔍 Enter your research topic: \")\n",
    "    print(\"\\n⌛ Running full pipeline in background; showing cached preview immediately...\\n\")\n",
    "    quick_preview()\n",
    "    run_pipeline_async(user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1edfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c41cfaca1e4c68a6d7821b11665475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Interactive graph saved as 'graph.html'.\n",
      "✅ Pipeline complete.\n",
      "\n",
      "📄 Top Enriched Papers with Keywords:\n",
      "\n",
      "📘 Implications of Computer Vision Driven Assistive Technologies Towards\n",
      "  Individuals with Visual Impairment\n",
      "🗓️ Year: 2019\n",
      "🔑 Keywords: 1arxiv190507844v1, abs180907842, abs181110670, underrepresentation, obtrusiveness, homemonitoring, preprocessing, caregivers, eavesdropping, mitigating\n",
      "\n",
      "📘 Second Croatian Computer Vision Workshop (CCVW 2013)\n",
      "🗓️ Year: 2013\n",
      "🔑 Keywords: \n",
      "\n",
      "📘 Multiband NFC for High-Throughput Wireless Computer Vision Sensor\n",
      "  Network\n",
      "🗓️ Year: 2017\n",
      "🔑 Keywords: arxiv160302345, arxiv170505983, 09212020027fudaneducn, httpswwwfccgov, floifloqmixerbuffer, bluetoothwifi, supercomputing, energyefficient, connectioncoupling, highthroughput\n",
      "\n",
      "📘 Deep Learning vs. Traditional Computer Vision\n",
      "🗓️ Year: 2019\n",
      "🔑 Keywords: arxiv160307285v2, httpsdoiorg101214009053604000000760, arxiv170602413v1, httpsdoiorg10115520187068349, httpsdoiorg101038s41529, httpsdoiorg103390s17061341, httpsdoiorg101007s11704, httpsdoiorg1010800143116120181519277, httpsdoiorg101007s11263, httpswwwmovidiuscomsolutionsvision\n",
      "\n",
      "📘 Enhancing camera surveillance using computer vision: a research note\n",
      "🗓️ Year: 2018\n",
      "🔑 Keywords: httpjournalsplosorgplosonearticleid101371journalpone0086157, 101016jconcog200601001, nij2015r2cxk025, 1298069316545012993283qr1, tpamonlinetrborgtrb60693201612807374t0011282343625412823593165450, httplinkspringercomarticle1010572fsj201417, unanticipated, unrecognizable, httpswwwyoutubecomwatchvvjg698u2mvo, 427436\n",
      "\n",
      "🧠 Papers by Cluster:\n",
      "\n",
      "--- Cluster 0 ---\n",
      "• Implications of Computer Vision Driven Assistive Technologies Towards\n",
      "  Individuals with Visual Impairment\n",
      "• Deep Learning vs. Traditional Computer Vision\n",
      "• Are object detection assessment criteria ready for maritime computer\n",
      "  vision?\n",
      "\n",
      "--- Cluster 1 ---\n",
      "• Enhancing camera surveillance using computer vision: a research note\n",
      "• Adapting Computer Vision Algorithms for Omnidirectional Video\n",
      "\n",
      "--- Cluster 2 ---\n",
      "• Multiband NFC for High-Throughput Wireless Computer Vision Sensor\n",
      "  Network\n",
      "\n",
      "--- Cluster 3 ---\n",
      "• SPARK: Multi-Vision Sensor Perception and Reasoning Benchmark for\n",
      "  Large-scale Vision-Language Models\n",
      "\n",
      "--- Cluster 4 ---\n",
      "• Vision Transformers in Medical Computer Vision -- A Contemplative\n",
      "  Retrospection\n",
      "\n",
      "📝 Cluster Summaries:\n",
      "\n",
      "--- 🧩 Cluster 0 Summary ---\n",
      "**Bibliometric Insights:**\n",
      "\n",
      "**Title:** Implications of Computer Vision Driven Assistive Technologies towards Individuals with Visual Impairment\n",
      "\n",
      "**Authors:** Linda Wang and Alexander Wong\n",
      "\n",
      "**Institution:** Waterloo Artificial Intelligence Institute, University of Waterloo\n",
      "\n",
      "**Methods:** The authors conducted a literature review to identify the positive and negative implications of computer vision-based assistive technologies on individuals with visual impairment.\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "1. **Positive Implications:** Computer vision-based devices can allow blind individuals to navigate independently, recognize faces, and read text, which helps them overcome social barriers.\n",
      "2. **Negative Implications:** The use of computer vision-based assistive technologies raises concerns about fairness and bias, privacy protection, and the exclusion of certain groups during the development process.\n",
      "3. **Bias:** The authors identify several types of bias, including gender, age, race/ethnicity, and exploitation of personal information.\n",
      "4. **Privacy:** The use of cameras raises concerns about privacy, and there is a trade-off between autonomy and privacy costs.\n",
      "5. **Device Evaluation:** The authors highlight the importance of evaluating devices to ensure they meet the needs of individuals with visual impairment.\n",
      "6. **Exclusion:** The development process may exclude certain groups, leading to age and condition-dependent exclusion.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "1. **Growing Concerns:** As AI becomes more ubiquitous, there is a growing need to address the implications of AI, specifically computer vision-driven assistive technology, on individuals with visual impairment.\n",
      "2. **Balancing Autonomy and Privacy:** The authors emphasize the importance of balancing autonomy and privacy costs in the development of computer vision-based assistive technologies.\n",
      "3. **Inclusive Development:** The authors stress the need for inclusive development processes that consider the needs of all individuals, including those with visual impairment.\n",
      "\n",
      "**Conclusion:** This paper highlights the positive and negative implications of computer vision-based assistive technologies on individuals with visual impairment. The authors emphasize the need for researchers to consider the potential biases and privacy concerns when developing these technologies.\n",
      "\n",
      "\n",
      "--- 🧩 Cluster 1 Summary ---\n",
      "Here is a scholarly summary of the bibliometric insights from the research note \"Enhancing Camera Surveillance using Computer Vision: A Research Note\":\n",
      "\n",
      "**Methodology:**\n",
      "\n",
      "The research note does not provide a specific methodology for the analysis, but it appears to be a literature review and analysis of existing research on camera surveillance and human monitoring.\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "The main findings of the research note are:\n",
      "\n",
      "1. The rapid adoption of surveillance cameras has outpaced the capacity to monitor them effectively, leading to a weak link in the information chain from camera to police response.\n",
      "2. Human monitors are not well-suited for camera monitoring tasks, as they are prone to inattention, image swamping, and missing important visual cues.\n",
      "3. The lack of visual change in long video stretches can lead to perception failure, causing monitors to shift their attention away from visual review and towards other non-visual tasks.\n",
      "4. The current state of camera surveillance projects aims to provide a combination of retrospective crime scene analysis, deterrence of future crimes, and facilitation of real-time intervention and force deployment.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "The research note identifies several trends in camera surveillance and human monitoring:\n",
      "\n",
      "1. The increasing use of surveillance cameras by law enforcement agencies, with an estimated 30 million cameras in the US alone.\n",
      "2. The limitations of human monitoring, including inattention, image swamping, and perception failure.\n",
      "3. The need for technological solutions to enhance camera surveillance, such as computer vision and artificial intelligence.\n",
      "\n",
      "**Citation Analysis:**\n",
      "\n",
      "A citation analysis of the research note reveals that the authors have drawn on a range of existing research in the fields of computer vision, surveillance, and law enforcement. The most frequently cited authors are:\n",
      "\n",
      "1. Norris, Armstrong (1999a)\n",
      "2. Buckland (2001)\n",
      "3. Marx (1988)\n",
      "4. Kroener (2014)\n",
      "5. Haggerty, Gozso (2005)\n",
      "\n",
      "The most frequently cited journals are:\n",
      "\n",
      "1. Police Quarterly\n",
      "2. Journal of Research in Crime and Delinquency\n",
      "3. Journal of Forensic Science\n",
      "\n",
      "The most frequently cited keywords are:\n",
      "\n",
      "1. Camera surveillance\n",
      "2. Computer vision\n",
      "3. Human monitoring\n",
      "4. Law enforcement\n",
      "5. Surveillance cameras\n",
      "\n",
      "\n",
      "--- 🧩 Cluster 2 Summary ---\n",
      "Based on the provided research text, here is a scholarly summary of the bibliometric insights:\n",
      "\n",
      "**Methodology:**\n",
      "\n",
      "The research proposes a novel Near Field Communication (NFC) system that utilizes multiple frequency bands to achieve high throughput for wireless computer vision sensor networks. The system is designed to address the limitations of conventional NFC systems, which have low data rates and limited communication ranges.\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "The study highlights the importance of high-throughput wireless communication in computer vision applications, particularly in emerging machine learning algorithms. The authors argue that large amounts of data are required to feed into algorithms, necessitating energy-efficient computation and data transfer. The proposed multiband NFC system is designed to address these issues by utilizing multiple frequency bands to achieve high data rates.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "The research identifies several trends in the field of computer vision and sensor networks:\n",
      "\n",
      "1. Increasing reliance on machine learning algorithms in computer vision tasks, such as face recognition, object detection, and simultaneous localization and mapping (SLAM).\n",
      "2. Growing need for energy-efficient computation and data transfer in computer vision applications.\n",
      "3. Rise of smart devices with high-definition photovideo capture capabilities, leading to the need for high-speed point-to-point file exchange.\n",
      "4. Growing demand for wireless connection-coupling between sensors and processors in computer vision applications, particularly in embedded systems and military applications.\n",
      "\n",
      "**Key contributions:**\n",
      "\n",
      "The research makes several key contributions to the field of computer vision and sensor networks:\n",
      "\n",
      "1. Proposes a novel multiband NFC system that utilizes multiple frequency bands to achieve high throughput.\n",
      "2. Highlights the importance of high-throughput wireless communication in computer vision applications.\n",
      "3. Identifies the limitations of conventional NFC systems and proposes a solution to address these limitations.\n",
      "\n",
      "**Future directions:**\n",
      "\n",
      "The research suggests several future directions for further investigation:\n",
      "\n",
      "1. Development of more advanced multiband NFC systems that can achieve even higher data rates and longer communication ranges.\n",
      "2. Exploration of new frequency bands for NFC communication to further enhance data rates and communication ranges.\n",
      "3. Investigation of the potential applications of multiband NFC systems in other fields beyond computer vision and sensor networks.\n",
      "\n",
      "**Bibliometric insights:**\n",
      "\n",
      "The research provides several bibliometric insights, including:\n",
      "\n",
      "1. The importance of high-throughput wireless communication in computer vision applications.\n",
      "2. The limitations of conventional NFC systems and the need for more advanced solutions.\n",
      "3. The growing demand for energy-efficient computation and data transfer in computer vision applications.\n",
      "4. The increasing reliance on machine learning algorithms in computer vision tasks.\n",
      "\n",
      "Overall, the research provides a comprehensive overview of the current state of the art in computer vision and sensor networks, highlighting the importance of high-throughput wireless communication and the limitations of conventional NFC systems. The proposed multiband NFC system offers a promising solution to address these limitations and enhance the performance of computer vision applications.\n",
      "\n",
      "\n",
      "--- 🧩 Cluster 3 Summary ---\n",
      "Here is a scholarly summary of the bibliometric insights from the research text:\n",
      "\n",
      "**Title:** btspark Multivision Sensor Perception and Reasoning Benchmark for Large-Scale Vision-Language Models\n",
      "\n",
      "**Authors:** Youngjoon Yu, Sangyun Chung, Byungkwan Lee, and Yong Man Ro\n",
      "\n",
      "**Institution:** Integrated Vision Language Lab, KAIST, South Korea\n",
      "\n",
      "**Methodology:** The authors generated 6248 vision-language test samples to investigate multivision sensory perception and reasoning on physical sensor knowledge proficiency across different formats, covering different types of sensor-related questions. They utilized these samples to assess ten leading large-scale vision-language models (LVMs).\n",
      "\n",
      "**Findings:** The results showed that most models displayed deficiencies in multivision sensory reasoning to varying extents. The authors observed that current LVMs view images taken from multivision sensors as if they were in the same RGB domain without considering the physical characteristics of multivision sensors, failing to convey the fundamental multivision sensor information from the dataset and the corresponding contextual knowledge properly.\n",
      "\n",
      "**Trends:** The paper highlights the importance of addressing the fundamental multivision sensor information gap between images and multivision sensors to achieve accurate sensory reasoning. The authors propose a multivision sensor perception and reasoning benchmark, called Spark, to reduce this gap and improve the performance of LVMs in processing multivision sensor data.\n",
      "\n",
      "**Key Insights:**\n",
      "\n",
      "1. Current LVMs struggle to process multivision sensor data, leading to deficiencies in multivision sensory reasoning.\n",
      "2. The authors propose a benchmark, Spark, to address the fundamental multivision sensor information gap and improve the performance of LVMs.\n",
      "3. The study highlights the importance of considering the physical characteristics of multivision sensors in processing multivision sensor data.\n",
      "4. The authors demonstrate the potential of LVMs in processing multivision sensor data, including thermal sensors, depth sensors, and medical imaging.\n",
      "\n",
      "**Bibliometric Analysis:**\n",
      "\n",
      "* The paper cites recent research on large-scale vision-language models, including OpenAI's GPT-4 and other notable studies in the field.\n",
      "* The authors mention the importance of addressing the multivision sensor information gap, which is a critical issue in the development of LVMs.\n",
      "* The study's methodology and findings contribute to the growing body of research on LVMs and their applications in various domains.\n",
      "\n",
      "**Conclusion:** The paper proposes a benchmark, Spark, to address the fundamental multivision sensor information gap and improve the performance of LVMs in processing multivision sensor data. The study highlights the importance of considering the physical characteristics of multivision sensors and demonstrates the potential of LVMs in processing multivision sensor data.\n",
      "\n",
      "\n",
      "--- 🧩 Cluster 4 Summary ---\n",
      "Here is a scholarly summary of the bibliometric insights from the research text:\n",
      "\n",
      "**Methods:**\n",
      "\n",
      "The authors conducted a literature survey to investigate the intersection of Vision Transformers (ViTs) and medical images in the field of medical computer vision. They surveyed various ViTs-based frameworks used by researchers in different areas of medical computer vision, including image-based disease classification, anatomical structure segmentation, registration, region-based lesion detection, captioning, report generation, and reconstruction using multiple medical imaging modalities.\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "The authors found that Vision Transformers (ViTs) are being increasingly used in medical computer vision due to their ability to process long-range dependencies in images and their potential to unravel the information contained within images. They identified several applications of ViTs in medical computer vision, including image-based disease classification, anatomical structure segmentation, registration, region-based lesion detection, captioning, report generation, and reconstruction using multiple medical imaging modalities.\n",
      "\n",
      "The authors also highlighted several challenges associated with medical imaging modalities, including expensive data acquisition, dense pixel resolution, lack of standard image acquisition techniques, modality-specific artifacts, imbalanced data, and sparse and noisy annotated datasets. They noted that these challenges hinder the translation of AI-based diagnosis into clinical practice.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "The authors observed a trend towards the increasing use of deep learning algorithms, particularly Convolutional Neural Networks (CNNs), in medical imaging applications. They noted that CNNs have achieved notable accomplishments in medical imaging applications, including determining the presence and type of malignancy, classification, lesion detection, and segmentation.\n",
      "\n",
      "The authors also identified a trend towards the use of Vision Transformers (ViTs) in medical computer vision, which have the potential to process long-range dependencies in images and unravel the information contained within images. They noted that ViTs are being used to improve the performance of various medical computer vision tasks, including image-based disease classification, anatomical structure segmentation, registration, region-based lesion detection, captioning, report generation, and reconstruction using multiple medical imaging modalities.\n",
      "\n",
      "**Key Takeaways:**\n",
      "\n",
      "1. Vision Transformers (ViTs) are being increasingly used in medical computer vision due to their ability to process long-range dependencies in images and their potential to unravel the information contained within images.\n",
      "2. ViTs have been applied to various medical computer vision tasks, including image-based disease classification, anatomical structure segmentation, registration, region-based lesion detection, captioning, report generation, and reconstruction using multiple medical imaging modalities.\n",
      "3. Medical imaging modalities pose several challenges, including expensive data acquisition, dense pixel resolution, lack of standard image acquisition techniques, modality-specific artifacts, imbalanced data, and sparse and noisy annotated datasets.\n",
      "4. Deep learning algorithms, particularly Convolutional Neural Networks (CNNs), have achieved notable accomplishments in medical imaging applications.\n",
      "5. The use of Vision Transformers (ViTs) in medical computer vision has the potential to improve the performance of various medical computer vision tasks and to unravel the information contained within images.\n",
      "\n",
      "**Limitations:**\n",
      "\n",
      "1. The authors' literature survey was limited to a specific set of medical computer vision tasks and may not be exhaustive.\n",
      "2. The authors did not provide a comprehensive evaluation of the performance of ViTs in medical computer vision tasks.\n",
      "3. The authors did not discuss the potential limitations and challenges associated with the use of ViTs in medical computer vision.\n",
      "\n",
      "**Future Directions:**\n",
      "\n",
      "1. Further research is needed to evaluate the performance of ViTs in various medical computer vision tasks and to identify the potential limitations and challenges associated with their use.\n",
      "2. The development of new ViTs-based frameworks and architectures is needed to improve the performance of medical computer vision tasks and to unravel the information contained within images.\n",
      "3. The use of ViTs in medical computer vision has the potential to improve the diagnosis and treatment of various medical conditions, and further research is needed to explore this potential.\n",
      "\n",
      "\n",
      "📚 Bibliometric Summaries by Cluster:\n",
      "\n",
      "🧠 Cluster 0:\n",
      "**Bibliometric Insights:**\n",
      "\n",
      "**Title:** Implications of Computer Vision Driven Assistive Technologies towards Individuals with Visual Impairment\n",
      "\n",
      "**Authors:** Linda Wang and Alexander Wong\n",
      "\n",
      "**Institution:** Waterloo Artificial Intelligence Institute, University of Waterloo\n",
      "\n",
      "**Methods:** The authors conducted a literature review to identify the positive and negative implications of computer vision-based assistive technologies on individuals with visual impairment.\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "1. **Positive Implications:** Computer vision-based devices can allow blind individuals to navigate independently, recognize faces, and read text, which helps them overcome social barriers.\n",
      "2. **Negative Implications:** The use of computer vision-based assistive technologies raises concerns about fairness and bias, privacy protection, and the exclusion of certain groups during the development process.\n",
      "3. **Bias:** The authors identify several types of bias, including gender, age, race/ethnicity, and exploitation of personal information.\n",
      "4. **Privacy:** The use of cameras raises concerns about privacy, and there is a trade-off between autonomy and privacy costs.\n",
      "5. **Device Evaluation:** The authors highlight the importance of evaluating devices to ensure they meet the needs of individuals with visual impairment.\n",
      "6. **Exclusion:** The development process may exclude certain groups, leading to age and condition-dependent exclusion.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "1. **Growing Concerns:** As AI becomes more ubiquitous, there is a growing need to address the implications of AI, specifically computer vision-driven assistive technology, on individuals with visual impairment.\n",
      "2. **Balancing Autonomy and Privacy:** The authors emphasize the importance of balancing autonomy and privacy costs in the development of computer vision-based assistive technologies.\n",
      "3. **Inclusive Development:** The authors stress the need for inclusive development processes that consider the needs of all individuals, including those with visual impairment.\n",
      "\n",
      "**Conclusion:** This paper highlights the positive and negative implications of computer vision-based assistive technologies on individuals with visual impairment. The authors emphasize the need for researchers to consider the potential biases and privacy concerns when developing these technologies.\n",
      "\n",
      "🧠 Cluster 1:\n",
      "Here is a scholarly summary of the bibliometric insights from the research note \"Enhancing Camera Surveillance using Computer Vision: A Research Note\":\n",
      "\n",
      "**Methodology:**\n",
      "\n",
      "The research note does not provide a specific methodology for the analysis, but it appears to be a literature review and analysis of existing research on camera surveillance and human monitoring.\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "The main findings of the research note are:\n",
      "\n",
      "1. The rapid adoption of surveillance cameras has outpaced the capacity to monitor them effectively, leading to a weak link in the information chain from camera to police response.\n",
      "2. Human monitors are not well-suited for camera monitoring tasks, as they are prone to inattention, image swamping, and missing important visual cues.\n",
      "3. The lack of visual change in long video stretches can lead to perception failure, causing monitors to shift their attention away from visual review and towards other non-visual tasks.\n",
      "4. The current state of camera surveillance projects aims to provide a combination of retrospective crime scene analysis, deterrence of future crimes, and facilitation of real-time intervention and force deployment.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "The research note identifies several trends in camera surveillance and human monitoring:\n",
      "\n",
      "1. The increasing use of surveillance cameras by law enforcement agencies, with an estimated 30 million cameras in the US alone.\n",
      "2. The limitations of human monitoring, including inattention, image swamping, and perception failure.\n",
      "3. The need for technological solutions to enhance camera surveillance, such as computer vision and artificial intelligence.\n",
      "\n",
      "**Citation Analysis:**\n",
      "\n",
      "A citation analysis of the research note reveals that the authors have drawn on a range of existing research in the fields of computer vision, surveillance, and law enforcement. The most frequently cited authors are:\n",
      "\n",
      "1. Norris, Armstrong (1999a)\n",
      "2. Buckland (2001)\n",
      "3. Marx (1988)\n",
      "4. Kroener (2014)\n",
      "5. Haggerty, Gozso (2005)\n",
      "\n",
      "The most frequently cited journals are:\n",
      "\n",
      "1. Police Quarterly\n",
      "2. Journal of Research in Crime and Delinquency\n",
      "3. Journal of Forensic Science\n",
      "\n",
      "The most frequently cited keywords are:\n",
      "\n",
      "1. Camera surveillance\n",
      "2. Computer vision\n",
      "3. Human monitoring\n",
      "4. Law enforcement\n",
      "5. Surveillance cameras\n",
      "\n",
      "🧠 Cluster 2:\n",
      "Based on the provided research text, here is a scholarly summary of the bibliometric insights:\n",
      "\n",
      "**Methodology:**\n",
      "\n",
      "The research proposes a novel Near Field Communication (NFC) system that utilizes multiple frequency bands to achieve high throughput for wireless computer vision sensor networks. The system is designed to address the limitations of conventional NFC systems, which have low data rates and limited communication ranges.\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "The study highlights the importance of high-throughput wireless communication in computer vision applications, particularly in emerging machine learning algorithms. The authors argue that large amounts of data are required to feed into algorithms, necessitating energy-efficient computation and data transfer. The proposed multiband NFC system is designed to address these issues by utilizing multiple frequency bands to achieve high data rates.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "The research identifies several trends in the field of computer vision and sensor networks:\n",
      "\n",
      "1. Increasing reliance on machine learning algorithms in computer vision tasks, such as face recognition, object detection, and simultaneous localization and mapping (SLAM).\n",
      "2. Growing need for energy-efficient computation and data transfer in computer vision applications.\n",
      "3. Rise of smart devices with high-definition photovideo capture capabilities, leading to the need for high-speed point-to-point file exchange.\n",
      "4. Growing demand for wireless connection-coupling between sensors and processors in computer vision applications, particularly in embedded systems and military applications.\n",
      "\n",
      "**Key contributions:**\n",
      "\n",
      "The research makes several key contributions to the field of computer vision and sensor networks:\n",
      "\n",
      "1. Proposes a novel multiband NFC system that utilizes multiple frequency bands to achieve high throughput.\n",
      "2. Highlights the importance of high-throughput wireless communication in computer vision applications.\n",
      "3. Identifies the limitations of conventional NFC systems and proposes a solution to address these limitations.\n",
      "\n",
      "**Future directions:**\n",
      "\n",
      "The research suggests several future directions for further investigation:\n",
      "\n",
      "1. Development of more advanced multiband NFC systems that can achieve even higher data rates and longer communication ranges.\n",
      "2. Exploration of new frequency bands for NFC communication to further enhance data rates and communication ranges.\n",
      "3. Investigation of the potential applications of multiband NFC systems in other fields beyond computer vision and sensor networks.\n",
      "\n",
      "**Bibliometric insights:**\n",
      "\n",
      "The research provides several bibliometric insights, including:\n",
      "\n",
      "1. The importance of high-throughput wireless communication in computer vision applications.\n",
      "2. The limitations of conventional NFC systems and the need for more advanced solutions.\n",
      "3. The growing demand for energy-efficient computation and data transfer in computer vision applications.\n",
      "4. The increasing reliance on machine learning algorithms in computer vision tasks.\n",
      "\n",
      "Overall, the research provides a comprehensive overview of the current state of the art in computer vision and sensor networks, highlighting the importance of high-throughput wireless communication and the limitations of conventional NFC systems. The proposed multiband NFC system offers a promising solution to address these limitations and enhance the performance of computer vision applications.\n",
      "\n",
      "🧠 Cluster 3:\n",
      "Here is a scholarly summary of the bibliometric insights from the research text:\n",
      "\n",
      "**Title:** btspark Multivision Sensor Perception and Reasoning Benchmark for Large-Scale Vision-Language Models\n",
      "\n",
      "**Authors:** Youngjoon Yu, Sangyun Chung, Byungkwan Lee, and Yong Man Ro\n",
      "\n",
      "**Institution:** Integrated Vision Language Lab, KAIST, South Korea\n",
      "\n",
      "**Methodology:** The authors generated 6248 vision-language test samples to investigate multivision sensory perception and reasoning on physical sensor knowledge proficiency across different formats, covering different types of sensor-related questions. They utilized these samples to assess ten leading large-scale vision-language models (LVMs).\n",
      "\n",
      "**Findings:** The results showed that most models displayed deficiencies in multivision sensory reasoning to varying extents. The authors observed that current LVMs view images taken from multivision sensors as if they were in the same RGB domain without considering the physical characteristics of multivision sensors, failing to convey the fundamental multivision sensor information from the dataset and the corresponding contextual knowledge properly.\n",
      "\n",
      "**Trends:** The paper highlights the importance of addressing the fundamental multivision sensor information gap between images and multivision sensors to achieve accurate sensory reasoning. The authors propose a multivision sensor perception and reasoning benchmark, called Spark, to reduce this gap and improve the performance of LVMs in processing multivision sensor data.\n",
      "\n",
      "**Key Insights:**\n",
      "\n",
      "1. Current LVMs struggle to process multivision sensor data, leading to deficiencies in multivision sensory reasoning.\n",
      "2. The authors propose a benchmark, Spark, to address the fundamental multivision sensor information gap and improve the performance of LVMs.\n",
      "3. The study highlights the importance of considering the physical characteristics of multivision sensors in processing multivision sensor data.\n",
      "4. The authors demonstrate the potential of LVMs in processing multivision sensor data, including thermal sensors, depth sensors, and medical imaging.\n",
      "\n",
      "**Bibliometric Analysis:**\n",
      "\n",
      "* The paper cites recent research on large-scale vision-language models, including OpenAI's GPT-4 and other notable studies in the field.\n",
      "* The authors mention the importance of addressing the multivision sensor information gap, which is a critical issue in the development of LVMs.\n",
      "* The study's methodology and findings contribute to the growing body of research on LVMs and their applications in various domains.\n",
      "\n",
      "**Conclusion:** The paper proposes a benchmark, Spark, to address the fundamental multivision sensor information gap and improve the performance of LVMs in processing multivision sensor data. The study highlights the importance of considering the physical characteristics of multivision sensors and demonstrates the potential of LVMs in processing multivision sensor data.\n",
      "\n",
      "🧠 Cluster 4:\n",
      "Here is a scholarly summary of the bibliometric insights from the research text:\n",
      "\n",
      "**Methods:**\n",
      "\n",
      "The authors conducted a literature survey to investigate the intersection of Vision Transformers (ViTs) and medical images in the field of medical computer vision. They surveyed various ViTs-based frameworks used by researchers in different areas of medical computer vision, including image-based disease classification, anatomical structure segmentation, registration, region-based lesion detection, captioning, report generation, and reconstruction using multiple medical imaging modalities.\n",
      "\n",
      "**Findings:**\n",
      "\n",
      "The authors found that Vision Transformers (ViTs) are being increasingly used in medical computer vision due to their ability to process long-range dependencies in images and their potential to unravel the information contained within images. They identified several applications of ViTs in medical computer vision, including image-based disease classification, anatomical structure segmentation, registration, region-based lesion detection, captioning, report generation, and reconstruction using multiple medical imaging modalities.\n",
      "\n",
      "The authors also highlighted several challenges associated with medical imaging modalities, including expensive data acquisition, dense pixel resolution, lack of standard image acquisition techniques, modality-specific artifacts, imbalanced data, and sparse and noisy annotated datasets. They noted that these challenges hinder the translation of AI-based diagnosis into clinical practice.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "The authors observed a trend towards the increasing use of deep learning algorithms, particularly Convolutional Neural Networks (CNNs), in medical imaging applications. They noted that CNNs have achieved notable accomplishments in medical imaging applications, including determining the presence and type of malignancy, classification, lesion detection, and segmentation.\n",
      "\n",
      "The authors also identified a trend towards the use of Vision Transformers (ViTs) in medical computer vision, which have the potential to process long-range dependencies in images and unravel the information contained within images. They noted that ViTs are being used to improve the performance of various medical computer vision tasks, including image-based disease classification, anatomical structure segmentation, registration, region-based lesion detection, captioning, report generation, and reconstruction using multiple medical imaging modalities.\n",
      "\n",
      "**Key Takeaways:**\n",
      "\n",
      "1. Vision Transformers (ViTs) are being increasingly used in medical computer vision due to their ability to process long-range dependencies in images and their potential to unravel the information contained within images.\n",
      "2. ViTs have been applied to various medical computer vision tasks, including image-based disease classification, anatomical structure segmentation, registration, region-based lesion detection, captioning, report generation, and reconstruction using multiple medical imaging modalities.\n",
      "3. Medical imaging modalities pose several challenges, including expensive data acquisition, dense pixel resolution, lack of standard image acquisition techniques, modality-specific artifacts, imbalanced data, and sparse and noisy annotated datasets.\n",
      "4. Deep learning algorithms, particularly Convolutional Neural Networks (CNNs), have achieved notable accomplishments in medical imaging applications.\n",
      "5. The use of Vision Transformers (ViTs) in medical computer vision has the potential to improve the performance of various medical computer vision tasks and to unravel the information contained within images.\n",
      "\n",
      "**Limitations:**\n",
      "\n",
      "1. The authors' literature survey was limited to a specific set of medical computer vision tasks and may not be exhaustive.\n",
      "2. The authors did not provide a comprehensive evaluation of the performance of ViTs in medical computer vision tasks.\n",
      "3. The authors did not discuss the potential limitations and challenges associated with the use of ViTs in medical computer vision.\n",
      "\n",
      "**Future Directions:**\n",
      "\n",
      "1. Further research is needed to evaluate the performance of ViTs in various medical computer vision tasks and to identify the potential limitations and challenges associated with their use.\n",
      "2. The development of new ViTs-based frameworks and architectures is needed to improve the performance of medical computer vision tasks and to unravel the information contained within images.\n",
      "3. The use of ViTs in medical computer vision has the potential to improve the diagnosis and treatment of various medical conditions, and further research is needed to explore this potential.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re, json, ast, torch, os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from keybert import KeyBERT\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "from openai import OpenAI  # ✅ Modern OpenAI client\n",
    "\n",
    "# === MODEL SETUP ===\n",
    "bert_encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "kw_model = KeyBERT(model='bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model.eval()\n",
    "\n",
    "# === GROQ API SETUP ===\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",  \n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")\n",
    "\n",
    "# === NEO4J SETUP ===\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"qwertyuiop\"))\n",
    "\n",
    "# === FETCHING ===\n",
    "def fetch_and_save_papers(query, max_results=10):\n",
    "    from fetch_arxiv import fetch_arxiv_papers\n",
    "    df = fetch_arxiv_papers(query, max_results=max_results)\n",
    "    df = df.dropna(subset=[\"full_text\"])\n",
    "    df.to_csv(\"papers3.csv\", index=False)\n",
    "\n",
    "# === ENRICH ===\n",
    "def enrich_papers():\n",
    "    df = pd.read_csv(\"papers3.csv\")\n",
    "\n",
    "    def clean_text(text):\n",
    "        text = str(text).lower()\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', text).strip()\n",
    "\n",
    "    df[\"clean_text\"] = df[\"full_text\"].fillna(\"\").apply(clean_text)\n",
    "    df[\"keywords\"] = df[\"clean_text\"].apply(\n",
    "        lambda x: [kw[0] for kw in kw_model.extract_keywords(x, top_n=10)] if x else []\n",
    "    )\n",
    "    df.to_csv(\"papers_enriched.csv\", index=False)\n",
    "\n",
    "# === GRAPH ===\n",
    "def build_knowledge_graph():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\")\n",
    "    graph.delete_all()\n",
    "    for _, row in df.iterrows():\n",
    "        paper_node = Node(\"Paper\", title=row[\"title\"], year=row[\"year\"], doi=row[\"doi\"])\n",
    "        graph.create(paper_node)\n",
    "\n",
    "        for author in ast.literal_eval(row[\"authors\"]):\n",
    "            author_node = Node(\"Author\", name=author)\n",
    "            graph.merge(author_node, \"Author\", \"name\")\n",
    "            graph.create(Relationship(author_node, \"WROTE\", paper_node))\n",
    "\n",
    "        for keyword in ast.literal_eval(row[\"keywords\"]):\n",
    "            keyword_node = Node(\"Keyword\", name=keyword)\n",
    "            graph.merge(keyword_node, \"Keyword\", \"name\")\n",
    "            graph.create(Relationship(paper_node, \"HAS_KEYWORD\", keyword_node))\n",
    "\n",
    "# === CLUSTER ===\n",
    "def cluster_texts():\n",
    "    df = pd.read_csv(\"papers_enriched.csv\").dropna(subset=[\"clean_text\"])\n",
    "    embeddings = bert_encoder.encode(df[\"clean_text\"].tolist(), show_progress_bar=True)\n",
    "    gmm = GaussianMixture(n_components=5, random_state=42)\n",
    "    df[\"cluster\"] = gmm.fit_predict(embeddings)\n",
    "    df.to_csv(\"clustered_papers.csv\", index=False)\n",
    "\n",
    "# === SUMMARIZE ===\n",
    "def summarize_clusters():\n",
    "    df = pd.read_csv(\"clustered_papers.csv\")\n",
    "    grouped = df.groupby(\"cluster\")[\"clean_text\"].apply(list).to_dict()\n",
    "\n",
    "    def query_groq(prompt):\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama3-8b-8192\",  # or \"llama3-8b-8192\"\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a bibliometric research assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=800\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    summaries = {}\n",
    "    for cluster, texts in grouped.items():\n",
    "        text_blob = \" \".join(texts)[:4000]  # truncate to fit token limits\n",
    "        prompt = (\n",
    "            \"Read the following full research texts and provide a scholarly summary of their bibliometric insights \"\n",
    "            \"including methods, findings, and trends:\\n\" + text_blob\n",
    "        )\n",
    "        summaries[cluster] = query_groq(prompt)\n",
    "\n",
    "    with open(\"cluster_summaries.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summaries, f, indent=2)\n",
    "\n",
    "# === VISUALIZE ===\n",
    "def visualize_graph():\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Paper)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "    RETURN p.title AS title, k.name AS keyword LIMIT 100\n",
    "    \"\"\"\n",
    "    results = graph.run(query).data()\n",
    "    net = Network(notebook=False, cdn_resources='in_line')\n",
    "    for record in results:\n",
    "        net.add_node(record[\"title\"], label=record[\"title\"], shape=\"box\", color=\"lightblue\")\n",
    "        net.add_node(record[\"keyword\"], label=record[\"keyword\"], shape=\"dot\", color=\"orange\")\n",
    "        net.add_edge(record[\"title\"], record[\"keyword\"])\n",
    "\n",
    "    html_content = net.generate_html()\n",
    "    with open(\"graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_content)\n",
    "    print(\"\\n✅ Interactive graph saved as 'graph.html'.\")\n",
    "\n",
    "# === DISPLAY ===\n",
    "def print_enriched_papers():\n",
    "    print(\"\\n📄 Top Enriched Papers with Keywords:\")\n",
    "    df = pd.read_csv(\"papers_enriched.csv\")\n",
    "    for idx, row in df.head(5).iterrows():\n",
    "        print(f\"\\n📘 {row['title']}\\n🗓️ Year: {row['year']}\")\n",
    "        keywords = eval(row[\"keywords\"]) if isinstance(row[\"keywords\"], str) else row[\"keywords\"]\n",
    "        print(f\"🔑 Keywords: {', '.join(keywords)}\")\n",
    "\n",
    "def print_clusters():\n",
    "    print(\"\\n🧠 Papers by Cluster:\")\n",
    "    df = pd.read_csv(\"clustered_papers.csv\")\n",
    "    for cluster in sorted(df['cluster'].unique()):\n",
    "        print(f\"\\n--- Cluster {cluster} ---\")\n",
    "        papers = df[df['cluster'] == cluster].head(3)\n",
    "        for _, row in papers.iterrows():\n",
    "            print(f\"• {row['title']}\")\n",
    "\n",
    "def print_summaries():\n",
    "    print(\"\\n📝 Cluster Summaries:\")\n",
    "    with open(\"cluster_summaries.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        summaries = json.load(f)\n",
    "    for cid, summary in summaries.items():\n",
    "        print(f\"\\n--- 🧩 Cluster {cid} Summary ---\\n{summary.strip()}\\n\")\n",
    "\n",
    "def print_cluster_summaries():\n",
    "    print(\"\\n📚 Bibliometric Summaries by Cluster:\")\n",
    "    with open(\"cluster_summaries.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        summaries = json.load(f)\n",
    "        for cluster, summary in summaries.items():\n",
    "            print(f\"\\n🧠 Cluster {cluster}:\\n{summary}\")\n",
    "\n",
    "# === PIPELINE ===\n",
    "def run_all(query):\n",
    "    fetch_and_save_papers(query)\n",
    "    enrich_papers()\n",
    "    build_knowledge_graph()\n",
    "    cluster_texts()\n",
    "    summarize_clusters()\n",
    "    visualize_graph()\n",
    "    print(\"✅ Pipeline complete.\")\n",
    "\n",
    "def run_all_and_display(query):\n",
    "    run_all(query)\n",
    "    print_enriched_papers()\n",
    "    print_clusters()\n",
    "    print_summaries()\n",
    "    print_cluster_summaries()\n",
    "    webbrowser.open(\"graph.html\")\n",
    "\n",
    "# === MAIN ===\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"🔍 Enter your research topic: \")\n",
    "    run_all_and_display(user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc32854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
